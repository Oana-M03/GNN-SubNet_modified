{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Explanations vs Global Explanations\n",
    "\n",
    "This notebook runs GNN-SubNet and its modified version to generate a global node mask. The loss function values for both Gradient Descent procedures are plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph is connected  False\n",
      "Calculate subgraph ...\n",
      "Number of subgraphs:  118\n",
      "Size of subgraph:  2049\n",
      "Graph is connected  True\n",
      "##################\n",
      "# DATASET LOADED #\n",
      "##################\n",
      "\n",
      "Number of nodes: 2049\n",
      "Number of edges: 13588\n",
      "Number of modalities: 2\n",
      "graphcnn for training ...\n",
      "Graphs class 0: 200, Graphs class 1: 306\n",
      "Length of balanced dataset list: 400\n",
      "Train graph class 0: 158, train graph class 1: 162\n",
      "Validation graph class 0: 42, validation graph class 1: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:07<00:00,  4.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 2339.3231\n",
      "Train Acc 0.4938\n",
      "Epoch 0, val_loss 21.2403\n",
      "Saving best model with validation loss 21.24030113220215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 347.2952\n",
      "Train Acc 0.5062\n",
      "Epoch 1, val_loss 30.6838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss 51.2827\n",
      "Train Acc 0.5219\n",
      "Epoch 2, val_loss 14.7407\n",
      "Saving best model with validation loss 14.740737915039062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss 39.0734\n",
      "Train Acc 0.5062\n",
      "Epoch 3, val_loss 30.3594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss 49.4919\n",
      "Train Acc 0.5125\n",
      "Epoch 4, val_loss 23.7290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss 49.2698\n",
      "Train Acc 0.5062\n",
      "Epoch 5, val_loss 94.6865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss 42.3393\n",
      "Train Acc 0.5062\n",
      "Epoch 6, val_loss 38.2733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, loss 27.5766\n",
      "Train Acc 0.6469\n",
      "Epoch 7, val_loss 9.1306\n",
      "Saving best model with validation loss 9.13060188293457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, loss 19.2986\n",
      "Train Acc 0.6188\n",
      "Epoch 8, val_loss 5.7151\n",
      "Saving best model with validation loss 5.715149879455566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, loss 34.9581\n",
      "Train Acc 0.4938\n",
      "Epoch 9, val_loss 31.9622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss 27.2833\n",
      "Train Acc 0.5062\n",
      "Epoch 10, val_loss 84.0414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, loss 27.3348\n",
      "Train Acc 0.5813\n",
      "Epoch 11, val_loss 12.0798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, loss 23.2633\n",
      "Train Acc 0.5031\n",
      "Epoch 12, val_loss 23.2802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:09<00:00,  3.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, loss 43.2664\n",
      "Train Acc 0.5062\n",
      "Epoch 13, val_loss 67.7786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, loss 35.9618\n",
      "Train Acc 0.5938\n",
      "Epoch 14, val_loss 12.1805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, loss 17.3940\n",
      "Train Acc 0.5125\n",
      "Epoch 15, val_loss 33.6349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, loss 16.6277\n",
      "Train Acc 0.5719\n",
      "Epoch 16, val_loss 13.5300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, loss 14.5258\n",
      "Train Acc 0.5062\n",
      "Epoch 17, val_loss 38.4899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:14<00:00,  2.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, loss 36.5862\n",
      "Train Acc 0.4938\n",
      "Epoch 18, val_loss 72.8406\n",
      "Early stopping!\n",
      "\n",
      "Confusion matrix (Validation set):\n",
      "\n",
      "[[36  6]\n",
      " [27 11]]\n",
      "Validation accuracy: 58.75%\n",
      "Validation loss 5.715149879455566\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from GNNSubNet import GNNSubNet as gnn\n",
    "\n",
    "# Synthetic data set  ------------------------- #\n",
    "# loc   = \"../GNNSubNet/datasets/synthetic\"\n",
    "# ppi   = f'{loc}/NETWORK_synthetic.txt'\n",
    "# feats = [f'{loc}/FEATURES_synthetic.txt']\n",
    "# targ  = f'{loc}/TARGET_synthetic.txt'\n",
    "\n",
    "# TCGA data set\n",
    "loc   = \"../TCGA\"\n",
    "ppi   = f'{loc}/KIDNEY_RANDOM_PPI.txt'\n",
    "feats = [f'{loc}/KIDNEY_RANDOM_Methy_FEATURES.txt', f'{loc}/KIDNEY_RANDOM_mRNA_FEATURES.txt']\n",
    "targ  = f'{loc}/KIDNEY_RANDOM_TARGET.txt'\n",
    "\n",
    "# Read in the synthetic data\n",
    "g = gnn.GNNSubNet(loc, ppi, feats, targ, normalize=False)\n",
    "\n",
    "# Get some general information about the data dimension\n",
    "g.summary()\n",
    "\n",
    "# Train the GNN classifier and validate performance on a test set\n",
    "g.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2049, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.s2v_test_dataset[0].node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g.s2v_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells train an explainer for 300 epochs to obtain the aggregation of local explanations. This corresponds to RQs 1 and 2 of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GNNSubNet import gnn_explainer as gnne\n",
    "import torch\n",
    "\n",
    "exp = gnne.GNNExplainer(g.model, epochs=300, lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2049"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.s2v_test_dataset[0].node_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.0535],\n",
       "        [-0.6496],\n",
       "        [ 4.9781],\n",
       "        ...,\n",
       "        [-4.0656],\n",
       "        [-5.9072],\n",
       "        [ 6.2704]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_mask = exp.explain_graph_modified_s2v(g.s2v_test_dataset, 0.1, False)\n",
    "node_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1: How can GNN-SubNet be modified to obtain a local-level explanation?\n",
    "\n",
    "The following code cells retrieve the loss function values generated by a run of the explainer. For each sample of the test dataset, the loss for each epoch was stored. Thus, we can now plot the losses for all of the node mask optimization processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch 0</th>\n",
       "      <th>Epoch 1</th>\n",
       "      <th>Epoch 2</th>\n",
       "      <th>Epoch 3</th>\n",
       "      <th>Epoch 4</th>\n",
       "      <th>Epoch 5</th>\n",
       "      <th>Epoch 6</th>\n",
       "      <th>Epoch 7</th>\n",
       "      <th>Epoch 8</th>\n",
       "      <th>Epoch 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Epoch 290</th>\n",
       "      <th>Epoch 291</th>\n",
       "      <th>Epoch 292</th>\n",
       "      <th>Epoch 293</th>\n",
       "      <th>Epoch 294</th>\n",
       "      <th>Epoch 295</th>\n",
       "      <th>Epoch 296</th>\n",
       "      <th>Epoch 297</th>\n",
       "      <th>Epoch 298</th>\n",
       "      <th>Epoch 299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.013641</td>\n",
       "      <td>45.113831</td>\n",
       "      <td>30.240103</td>\n",
       "      <td>15.510781</td>\n",
       "      <td>0.871271</td>\n",
       "      <td>-13.579669</td>\n",
       "      <td>-27.765417</td>\n",
       "      <td>-41.555523</td>\n",
       "      <td>-54.932510</td>\n",
       "      <td>-67.826195</td>\n",
       "      <td>...</td>\n",
       "      <td>-256.144714</td>\n",
       "      <td>-256.152954</td>\n",
       "      <td>-256.160889</td>\n",
       "      <td>-256.168732</td>\n",
       "      <td>-256.176880</td>\n",
       "      <td>-256.184143</td>\n",
       "      <td>-256.191925</td>\n",
       "      <td>-256.199646</td>\n",
       "      <td>-256.206909</td>\n",
       "      <td>-256.214630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138.830170</td>\n",
       "      <td>124.140038</td>\n",
       "      <td>109.522308</td>\n",
       "      <td>95.059288</td>\n",
       "      <td>80.825348</td>\n",
       "      <td>66.878387</td>\n",
       "      <td>53.333473</td>\n",
       "      <td>40.209572</td>\n",
       "      <td>27.568638</td>\n",
       "      <td>15.472967</td>\n",
       "      <td>...</td>\n",
       "      <td>-159.921555</td>\n",
       "      <td>-159.928574</td>\n",
       "      <td>-159.936081</td>\n",
       "      <td>-159.943130</td>\n",
       "      <td>-159.950943</td>\n",
       "      <td>-159.957993</td>\n",
       "      <td>-159.965134</td>\n",
       "      <td>-159.972076</td>\n",
       "      <td>-159.979126</td>\n",
       "      <td>-159.986496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74.946045</td>\n",
       "      <td>59.763832</td>\n",
       "      <td>44.567360</td>\n",
       "      <td>29.477379</td>\n",
       "      <td>14.491062</td>\n",
       "      <td>-0.244627</td>\n",
       "      <td>-14.588010</td>\n",
       "      <td>-28.570496</td>\n",
       "      <td>-42.162807</td>\n",
       "      <td>-55.241070</td>\n",
       "      <td>...</td>\n",
       "      <td>-247.620636</td>\n",
       "      <td>-247.628815</td>\n",
       "      <td>-247.636398</td>\n",
       "      <td>-247.644547</td>\n",
       "      <td>-247.652267</td>\n",
       "      <td>-247.659576</td>\n",
       "      <td>-247.667328</td>\n",
       "      <td>-247.674713</td>\n",
       "      <td>-247.682556</td>\n",
       "      <td>-247.689850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131.091187</td>\n",
       "      <td>114.506767</td>\n",
       "      <td>97.994209</td>\n",
       "      <td>81.718834</td>\n",
       "      <td>65.624809</td>\n",
       "      <td>49.863319</td>\n",
       "      <td>34.485912</td>\n",
       "      <td>19.567410</td>\n",
       "      <td>5.198513</td>\n",
       "      <td>-8.577172</td>\n",
       "      <td>...</td>\n",
       "      <td>-206.796844</td>\n",
       "      <td>-206.805573</td>\n",
       "      <td>-206.813461</td>\n",
       "      <td>-206.822006</td>\n",
       "      <td>-206.830276</td>\n",
       "      <td>-206.838623</td>\n",
       "      <td>-206.846649</td>\n",
       "      <td>-206.854324</td>\n",
       "      <td>-206.861984</td>\n",
       "      <td>-206.870132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144.557327</td>\n",
       "      <td>129.511520</td>\n",
       "      <td>114.542923</td>\n",
       "      <td>99.689247</td>\n",
       "      <td>85.061264</td>\n",
       "      <td>70.748360</td>\n",
       "      <td>56.908318</td>\n",
       "      <td>43.545422</td>\n",
       "      <td>30.683086</td>\n",
       "      <td>18.367674</td>\n",
       "      <td>...</td>\n",
       "      <td>-158.709152</td>\n",
       "      <td>-158.717407</td>\n",
       "      <td>-158.725220</td>\n",
       "      <td>-158.732773</td>\n",
       "      <td>-158.739853</td>\n",
       "      <td>-158.746811</td>\n",
       "      <td>-158.754715</td>\n",
       "      <td>-158.763031</td>\n",
       "      <td>-158.769882</td>\n",
       "      <td>-158.776566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>102.765213</td>\n",
       "      <td>87.058205</td>\n",
       "      <td>71.474144</td>\n",
       "      <td>55.949997</td>\n",
       "      <td>40.569897</td>\n",
       "      <td>25.471621</td>\n",
       "      <td>10.636740</td>\n",
       "      <td>-3.806469</td>\n",
       "      <td>-17.715929</td>\n",
       "      <td>-31.091206</td>\n",
       "      <td>...</td>\n",
       "      <td>-228.247391</td>\n",
       "      <td>-228.255707</td>\n",
       "      <td>-228.264206</td>\n",
       "      <td>-228.272186</td>\n",
       "      <td>-228.279602</td>\n",
       "      <td>-228.288055</td>\n",
       "      <td>-228.296341</td>\n",
       "      <td>-228.304047</td>\n",
       "      <td>-228.311752</td>\n",
       "      <td>-228.319290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>129.711349</td>\n",
       "      <td>113.371330</td>\n",
       "      <td>97.130341</td>\n",
       "      <td>81.091248</td>\n",
       "      <td>65.264069</td>\n",
       "      <td>49.638180</td>\n",
       "      <td>34.382851</td>\n",
       "      <td>19.612770</td>\n",
       "      <td>5.367459</td>\n",
       "      <td>-8.306925</td>\n",
       "      <td>...</td>\n",
       "      <td>-202.757538</td>\n",
       "      <td>-202.765671</td>\n",
       "      <td>-202.773834</td>\n",
       "      <td>-202.781876</td>\n",
       "      <td>-202.790344</td>\n",
       "      <td>-202.798065</td>\n",
       "      <td>-202.805679</td>\n",
       "      <td>-202.813599</td>\n",
       "      <td>-202.821884</td>\n",
       "      <td>-202.829285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>134.573547</td>\n",
       "      <td>117.452049</td>\n",
       "      <td>100.462822</td>\n",
       "      <td>83.660248</td>\n",
       "      <td>67.132217</td>\n",
       "      <td>50.977245</td>\n",
       "      <td>35.155102</td>\n",
       "      <td>19.808838</td>\n",
       "      <td>5.034503</td>\n",
       "      <td>-9.120975</td>\n",
       "      <td>...</td>\n",
       "      <td>-210.267151</td>\n",
       "      <td>-210.276184</td>\n",
       "      <td>-210.284500</td>\n",
       "      <td>-210.293320</td>\n",
       "      <td>-210.301392</td>\n",
       "      <td>-210.309799</td>\n",
       "      <td>-210.317764</td>\n",
       "      <td>-210.325775</td>\n",
       "      <td>-210.333649</td>\n",
       "      <td>-210.342300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>95.458328</td>\n",
       "      <td>80.229073</td>\n",
       "      <td>65.020866</td>\n",
       "      <td>49.996422</td>\n",
       "      <td>35.190071</td>\n",
       "      <td>20.612331</td>\n",
       "      <td>6.282259</td>\n",
       "      <td>-7.701098</td>\n",
       "      <td>-21.178017</td>\n",
       "      <td>-34.122578</td>\n",
       "      <td>...</td>\n",
       "      <td>-221.484940</td>\n",
       "      <td>-221.492783</td>\n",
       "      <td>-221.501190</td>\n",
       "      <td>-221.509415</td>\n",
       "      <td>-221.517029</td>\n",
       "      <td>-221.524811</td>\n",
       "      <td>-221.532791</td>\n",
       "      <td>-221.540939</td>\n",
       "      <td>-221.548691</td>\n",
       "      <td>-221.556442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>116.898064</td>\n",
       "      <td>100.823685</td>\n",
       "      <td>84.843681</td>\n",
       "      <td>69.028542</td>\n",
       "      <td>53.489079</td>\n",
       "      <td>38.257980</td>\n",
       "      <td>23.336206</td>\n",
       "      <td>8.838475</td>\n",
       "      <td>-5.135342</td>\n",
       "      <td>-18.592413</td>\n",
       "      <td>...</td>\n",
       "      <td>-210.887543</td>\n",
       "      <td>-210.895981</td>\n",
       "      <td>-210.904297</td>\n",
       "      <td>-210.912476</td>\n",
       "      <td>-210.920364</td>\n",
       "      <td>-210.928223</td>\n",
       "      <td>-210.936356</td>\n",
       "      <td>-210.944000</td>\n",
       "      <td>-210.951935</td>\n",
       "      <td>-210.959396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Epoch 0     Epoch 1     Epoch 2    Epoch 3    Epoch 4    Epoch 5   \n",
       "0    60.013641   45.113831   30.240103  15.510781   0.871271 -13.579669  \\\n",
       "1   138.830170  124.140038  109.522308  95.059288  80.825348  66.878387   \n",
       "2    74.946045   59.763832   44.567360  29.477379  14.491062  -0.244627   \n",
       "3   131.091187  114.506767   97.994209  81.718834  65.624809  49.863319   \n",
       "4   144.557327  129.511520  114.542923  99.689247  85.061264  70.748360   \n",
       "..         ...         ...         ...        ...        ...        ...   \n",
       "75  102.765213   87.058205   71.474144  55.949997  40.569897  25.471621   \n",
       "76  129.711349  113.371330   97.130341  81.091248  65.264069  49.638180   \n",
       "77  134.573547  117.452049  100.462822  83.660248  67.132217  50.977245   \n",
       "78   95.458328   80.229073   65.020866  49.996422  35.190071  20.612331   \n",
       "79  116.898064  100.823685   84.843681  69.028542  53.489079  38.257980   \n",
       "\n",
       "      Epoch 6    Epoch 7    Epoch 8    Epoch 9  ...   Epoch 290   Epoch 291   \n",
       "0  -27.765417 -41.555523 -54.932510 -67.826195  ... -256.144714 -256.152954  \\\n",
       "1   53.333473  40.209572  27.568638  15.472967  ... -159.921555 -159.928574   \n",
       "2  -14.588010 -28.570496 -42.162807 -55.241070  ... -247.620636 -247.628815   \n",
       "3   34.485912  19.567410   5.198513  -8.577172  ... -206.796844 -206.805573   \n",
       "4   56.908318  43.545422  30.683086  18.367674  ... -158.709152 -158.717407   \n",
       "..        ...        ...        ...        ...  ...         ...         ...   \n",
       "75  10.636740  -3.806469 -17.715929 -31.091206  ... -228.247391 -228.255707   \n",
       "76  34.382851  19.612770   5.367459  -8.306925  ... -202.757538 -202.765671   \n",
       "77  35.155102  19.808838   5.034503  -9.120975  ... -210.267151 -210.276184   \n",
       "78   6.282259  -7.701098 -21.178017 -34.122578  ... -221.484940 -221.492783   \n",
       "79  23.336206   8.838475  -5.135342 -18.592413  ... -210.887543 -210.895981   \n",
       "\n",
       "     Epoch 292   Epoch 293   Epoch 294   Epoch 295   Epoch 296   Epoch 297   \n",
       "0  -256.160889 -256.168732 -256.176880 -256.184143 -256.191925 -256.199646  \\\n",
       "1  -159.936081 -159.943130 -159.950943 -159.957993 -159.965134 -159.972076   \n",
       "2  -247.636398 -247.644547 -247.652267 -247.659576 -247.667328 -247.674713   \n",
       "3  -206.813461 -206.822006 -206.830276 -206.838623 -206.846649 -206.854324   \n",
       "4  -158.725220 -158.732773 -158.739853 -158.746811 -158.754715 -158.763031   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "75 -228.264206 -228.272186 -228.279602 -228.288055 -228.296341 -228.304047   \n",
       "76 -202.773834 -202.781876 -202.790344 -202.798065 -202.805679 -202.813599   \n",
       "77 -210.284500 -210.293320 -210.301392 -210.309799 -210.317764 -210.325775   \n",
       "78 -221.501190 -221.509415 -221.517029 -221.524811 -221.532791 -221.540939   \n",
       "79 -210.904297 -210.912476 -210.920364 -210.928223 -210.936356 -210.944000   \n",
       "\n",
       "     Epoch 298   Epoch 299  \n",
       "0  -256.206909 -256.214630  \n",
       "1  -159.979126 -159.986496  \n",
       "2  -247.682556 -247.689850  \n",
       "3  -206.861984 -206.870132  \n",
       "4  -158.769882 -158.776566  \n",
       "..         ...         ...  \n",
       "75 -228.311752 -228.319290  \n",
       "76 -202.821884 -202.829285  \n",
       "77 -210.333649 -210.342300  \n",
       "78 -221.548691 -221.556442  \n",
       "79 -210.951935 -210.959396  \n",
       "\n",
       "[80 rows x 300 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "losses = pd.read_csv(\"../GNNSubNet/saved_values/loss_values_modified_alg.csv\")\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 113.50397491,   97.1993866 ,   80.97582245,   64.94180298,\n",
       "         49.18170547,   33.66921234,   18.46888733,    3.73113251,\n",
       "        -10.48859024,  -24.15829659,  -37.21005249,  -49.65138626,\n",
       "        -61.39247131,  -72.46907806,  -82.87525177,  -92.5872345 ,\n",
       "       -101.63672638, -110.00443268, -117.76338196, -124.95198059,\n",
       "       -131.60723877, -137.74526978, -143.3966217 , -148.58843994,\n",
       "       -153.33633423, -157.67796326, -161.6509552 , -165.28764343,\n",
       "       -168.61489868, -171.66299438, -174.45762634, -177.01968384,\n",
       "       -179.37542725, -181.54402161, -183.54248047, -185.38423157,\n",
       "       -187.07865906, -188.64060974, -190.08673096, -191.42433167,\n",
       "       -192.66455078, -193.81504822, -194.88899231, -195.88792419,\n",
       "       -196.81835938, -197.68933105, -198.50610352, -199.27171326,\n",
       "       -199.9919281 , -200.67030334, -201.31001282, -201.91389465,\n",
       "       -202.48809814, -203.03477478, -203.5549469 , -204.04911804,\n",
       "       -204.52099609, -204.97113037, -205.3994751 , -205.81044006,\n",
       "       -206.20701599, -206.58796692, -206.9551239 , -207.3110199 ,\n",
       "       -207.65522766, -207.98501587, -208.29934692, -208.59838867,\n",
       "       -208.88534546, -209.16162109, -209.42637634, -209.6786499 ,\n",
       "       -209.92132568, -210.15104675, -210.37330627, -210.5894928 ,\n",
       "       -210.79747009, -210.99662781, -211.18887329, -211.37605286,\n",
       "       -211.55593872, -211.73091125, -211.90139771, -212.06752014,\n",
       "       -212.22962952, -212.38963318, -212.54605103, -212.69793701,\n",
       "       -212.84562683, -212.98849487, -213.12785339, -213.26304626,\n",
       "       -213.39601135, -213.52825928, -213.65844727, -213.78768921,\n",
       "       -213.91513062, -214.03919983, -214.16020203, -214.27798462,\n",
       "       -214.39311218, -214.50421143, -214.61010742, -214.71282959,\n",
       "       -214.81417847, -214.91288757, -215.00894165, -215.10240173,\n",
       "       -215.19271851, -215.28027344, -215.36520386, -215.44837952,\n",
       "       -215.52935791, -215.6088562 , -215.68669128, -215.76416016,\n",
       "       -215.83998108, -215.91340637, -215.98405457, -216.05213928,\n",
       "       -216.11872864, -216.18460083, -216.2492218 , -216.31278992,\n",
       "       -216.37573242, -216.43717957, -216.49769592, -216.55792236,\n",
       "       -216.61645508, -216.67352295, -216.7293396 , -216.78421021,\n",
       "       -216.83868408, -216.89245605, -216.94543457, -216.99699402,\n",
       "       -217.04779053, -217.09793091, -217.14781189, -217.19726562,\n",
       "       -217.24673462, -217.29595947, -217.3447876 , -217.39279175,\n",
       "       -217.44062805, -217.48735046, -217.53327942, -217.57814026,\n",
       "       -217.62236023, -217.66647339, -217.70916748, -217.75007629,\n",
       "       -217.79127502, -217.83132935, -217.8704071 , -217.90861511,\n",
       "       -217.94648743, -217.9833374 , -218.01904297, -218.05407715,\n",
       "       -218.08865356, -218.12271118, -218.15579224, -218.18893433,\n",
       "       -218.22077942, -218.2518158 , -218.28323364, -218.31384277,\n",
       "       -218.34371948, -218.37338257, -218.40246582, -218.43171692,\n",
       "       -218.4599762 , -218.48825073, -218.51663208, -218.54421997,\n",
       "       -218.57107544, -218.59840393, -218.62521362, -218.6522522 ,\n",
       "       -218.67982483, -218.70620728, -218.73320007, -218.75938416,\n",
       "       -218.78590393, -218.81187439, -218.83888245, -218.86599731,\n",
       "       -218.89363098, -218.91957092, -218.94444275, -218.96882629,\n",
       "       -218.99363708, -219.01693726, -219.04045105, -219.06300354,\n",
       "       -219.08532715, -219.10694885, -219.12837219, -219.14949036,\n",
       "       -219.16993713, -219.1907196 , -219.21115112, -219.23095703,\n",
       "       -219.25032043, -219.26976013, -219.28868103, -219.30725098,\n",
       "       -219.32591248, -219.3442688 , -219.36225891, -219.37986755,\n",
       "       -219.39704895, -219.41467285, -219.43170166, -219.44889832,\n",
       "       -219.46551514, -219.48207092, -219.49824524, -219.51486206,\n",
       "       -219.53094482, -219.54631042, -219.56202698, -219.57788086,\n",
       "       -219.59336853, -219.60810852, -219.62329102, -219.63807678,\n",
       "       -219.65272522, -219.66760254, -219.68200684, -219.69581604,\n",
       "       -219.71014404, -219.72419739, -219.7381897 , -219.75161743,\n",
       "       -219.76538086, -219.77839661, -219.79162598, -219.80499268,\n",
       "       -219.81799316, -219.83061218, -219.84364319, -219.85650635,\n",
       "       -219.86883545, -219.88150024, -219.89367676, -219.90620422,\n",
       "       -219.9178772 , -219.92948914, -219.94178772, -219.95347595,\n",
       "       -219.96473694, -219.97640991, -219.98814392, -219.99908447,\n",
       "       -220.01068115, -220.02163696, -220.03283691, -220.04368591,\n",
       "       -220.05465698, -220.06500244, -220.07572937, -220.08628845,\n",
       "       -220.09671021, -220.10673523, -220.11738586, -220.12765503,\n",
       "       -220.13789368, -220.14797974, -220.15794373, -220.16738892,\n",
       "       -220.17726135, -220.18695068, -220.19644165, -220.20596313,\n",
       "       -220.2155304 , -220.22480774, -220.23469543, -220.2436676 ,\n",
       "       -220.25253296, -220.26196289, -220.27111816, -220.2797699 ,\n",
       "       -220.28863525, -220.2975769 , -220.30662537, -220.31510925,\n",
       "       -220.32365417, -220.33230591, -220.34051514, -220.34922791,\n",
       "       -220.35780334, -220.36579895, -220.37428284, -220.38240051,\n",
       "       -220.39083862, -220.39892578, -220.40711975, -220.4151001 ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "single_loss = losses.iloc[30].values\n",
    "\n",
    "single_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(single_loss)\n",
    "plt.ylabel('Loss function value')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison purposes, the following code cells run the original explainer on the same test dataset and plot the loss function values for GNN-SubNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.9795],\n",
       "        [-5.8355],\n",
       "        [ 6.0718],\n",
       "        ...,\n",
       "        [-5.4347],\n",
       "        [-5.8461],\n",
       "        [ 6.5332]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_mask_gnn_subnet = exp.explain_graph_modified_s2v(g.s2v_test_dataset, 0.1, True)\n",
    "node_mask_gnn_subnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch 0</th>\n",
       "      <th>Epoch 1</th>\n",
       "      <th>Epoch 2</th>\n",
       "      <th>Epoch 3</th>\n",
       "      <th>Epoch 4</th>\n",
       "      <th>Epoch 5</th>\n",
       "      <th>Epoch 6</th>\n",
       "      <th>Epoch 7</th>\n",
       "      <th>Epoch 8</th>\n",
       "      <th>Epoch 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Epoch 290</th>\n",
       "      <th>Epoch 291</th>\n",
       "      <th>Epoch 292</th>\n",
       "      <th>Epoch 293</th>\n",
       "      <th>Epoch 294</th>\n",
       "      <th>Epoch 295</th>\n",
       "      <th>Epoch 296</th>\n",
       "      <th>Epoch 297</th>\n",
       "      <th>Epoch 298</th>\n",
       "      <th>Epoch 299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>841.733643</td>\n",
       "      <td>721.626953</td>\n",
       "      <td>602.04834</td>\n",
       "      <td>483.306183</td>\n",
       "      <td>365.789673</td>\n",
       "      <td>250.307663</td>\n",
       "      <td>137.504059</td>\n",
       "      <td>28.103294</td>\n",
       "      <td>-77.536491</td>\n",
       "      <td>-178.99942</td>\n",
       "      <td>...</td>\n",
       "      <td>-1638.181641</td>\n",
       "      <td>-1638.277588</td>\n",
       "      <td>-1638.369263</td>\n",
       "      <td>-1638.46167</td>\n",
       "      <td>-1638.557861</td>\n",
       "      <td>-1638.657104</td>\n",
       "      <td>-1638.762939</td>\n",
       "      <td>-1638.872925</td>\n",
       "      <td>-1638.98938</td>\n",
       "      <td>-1639.114502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Epoch 0     Epoch 1    Epoch 2     Epoch 3     Epoch 4     Epoch 5   \n",
       "0  841.733643  721.626953  602.04834  483.306183  365.789673  250.307663  \\\n",
       "\n",
       "      Epoch 6    Epoch 7    Epoch 8    Epoch 9  ...    Epoch 290    Epoch 291   \n",
       "0  137.504059  28.103294 -77.536491 -178.99942  ... -1638.181641 -1638.277588  \\\n",
       "\n",
       "     Epoch 292   Epoch 293    Epoch 294    Epoch 295    Epoch 296   \n",
       "0 -1638.369263 -1638.46167 -1638.557861 -1638.657104 -1638.762939  \\\n",
       "\n",
       "     Epoch 297   Epoch 298    Epoch 299  \n",
       "0 -1638.872925 -1638.98938 -1639.114502  \n",
       "\n",
       "[1 rows x 300 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_gnn_subnet = pd.read_csv(\"../GNNSubNet/saved_values/loss_values_gnn-subnet.csv\")\n",
    "losses_gnn_subnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses_gnn_subnet.iloc[0].values)\n",
    "plt.ylabel('Loss function value')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ2: How can multiple local explanations be aggregated to obtain a global explanation?\n",
    "\n",
    "To verify the correctness of the mask aggregation, we use both methods in the task of disease subnetwork detection and obtain the accuracy of the two explainers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3.0346899557500002,\n",
       " -0.5078569104999999,\n",
       " 6.0254092785,\n",
       " -0.3570356859999999,\n",
       " -0.1517176115,\n",
       " -2.2598742017200006,\n",
       " 6.036233232,\n",
       " -2.2528973422000003,\n",
       " -0.6884245924999999,\n",
       " -2.8732688249000002,\n",
       " -2.3612033642999997,\n",
       " -2.5944220288500004,\n",
       " -2.6588298639229997,\n",
       " -2.7130762876999994,\n",
       " 0.1748628175000001,\n",
       " -2.5913167479499997,\n",
       " -0.05771814000000001,\n",
       " -2.34047323846,\n",
       " -3.875944284395,\n",
       " 0.18429285500000006,\n",
       " -0.7798533915,\n",
       " -2.26924792726,\n",
       " -2.810678845615,\n",
       " -2.3942571201750003,\n",
       " -2.21588612475,\n",
       " -2.60803866305,\n",
       " -0.7724600359999999,\n",
       " -2.5150072153200003,\n",
       " -2.6827661701500007,\n",
       " -2.7635420563000004]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_mask = exp.aggregate_masks_from_file(\"GNNSubNet/saved_values/node_mask_values.csv\", np.mean)\n",
    "node_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(arr):\n",
    "\n",
    "    new_arr = []\n",
    "\n",
    "    minimum = min(arr)\n",
    "    maximum = max(arr)\n",
    "\n",
    "    for entry in arr:\n",
    "        new_entry = (entry - minimum) / (maximum - minimum)\n",
    "        new_arr.append(new_entry)\n",
    "\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.035974299210022154,\n",
       " 0.07889420226356529,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.8892814176094395,\n",
       " 0.09026474137513367,\n",
       " 0.997877620760268,\n",
       " 0.11195174744929895,\n",
       " 0.107592133944588,\n",
       " 0.15309546215707565,\n",
       " 0.9453786135029406,\n",
       " 0.0489842050314305,\n",
       " 0.12388481966659093,\n",
       " 0.1333719748174486,\n",
       " 0.21917977037015654,\n",
       " 0.03134143985569093,\n",
       " 0.17246155852163408,\n",
       " 0.11543876624820153,\n",
       " 0.1790915007245188,\n",
       " 0.059785816152258385,\n",
       " 0.11236983563808722,\n",
       " 0.1377337922090863,\n",
       " 0.0032581397221678977,\n",
       " 0.107772130086702,\n",
       " 0.03854811397679437,\n",
       " 0.11220656735904003,\n",
       " 0.1135562132612501,\n",
       " 0.20881727468715555,\n",
       " 0.13926957623337008,\n",
       " 0.000688732729249131]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_gnnsubnet = min_max([tensor.item() for tensor in node_mask_gnn_subnet])\n",
    "minmax_gnnsubnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08487078921392835,\n",
       " 0.3397928828780655,\n",
       " 0.9989080145626835,\n",
       " 0.3550086338319339,\n",
       " 0.37572235431972767,\n",
       " 0.1630388559932444,\n",
       " 1.0,\n",
       " 0.16374272348436436,\n",
       " 0.32157613063555,\n",
       " 0.10115592238300299,\n",
       " 0.15281616149323188,\n",
       " 0.12928766191135385,\n",
       " 0.12278981267827997,\n",
       " 0.11731710764578084,\n",
       " 0.40866974942638584,\n",
       " 0.12960094129874017,\n",
       " 0.3852055855617552,\n",
       " 0.15490754109228683,\n",
       " 0.0,\n",
       " 0.4096211082458181,\n",
       " 0.31235224427467984,\n",
       " 0.1620931782625445,\n",
       " 0.10747037540621354,\n",
       " 0.14948150008101152,\n",
       " 0.16747663738862836,\n",
       " 0.1279139340722915,\n",
       " 0.3130981303817205,\n",
       " 0.13729950526248894,\n",
       " 0.12037497434559175,\n",
       " 0.11222581781400277]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_new_alg = min_max(node_mask)\n",
    "minmax_new_alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04889649, 0.26089868, 0.00109199, 0.35500863, 0.51355906,\n",
       "       0.07277411, 0.00212238, 0.05179098, 0.213984  , 0.05193954,\n",
       "       0.79256245, 0.08030346, 0.00109501, 0.01605487, 0.18948998,\n",
       "       0.0982595 , 0.21274403, 0.03946877, 0.1790915 , 0.34983529,\n",
       "       0.19998241, 0.02435939, 0.10421224, 0.04170937, 0.12892852,\n",
       "       0.01570737, 0.19954192, 0.07151777, 0.0188946 , 0.11153709])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(np.subtract(minmax_gnnsubnet, minmax_new_alg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disease Subnetwork Detection\n",
    "\n",
    "The following code cells run both GNN-SubNet and the modified algorithm to detect disease subnetworks, then compares the obtained modules and the module importances. The algorithms are run on the TCGA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph is connected  False\n",
      "Calculate subgraph ...\n",
      "Number of subgraphs:  118\n",
      "Size of subgraph:  2049\n",
      "Graph is connected  True\n",
      "##################\n",
      "# DATASET LOADED #\n",
      "##################\n",
      "graphcnn for training ...\n",
      "Graphs class 0: 200, Graphs class 1: 306\n",
      "Length of balanced dataset list: 400\n",
      "Train graph class 0: 159, train graph class 1: 161\n",
      "Validation graph class 0: 41, validation graph class 1: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35 [00:00<?, ?batch/s]C:\\Users\\elena\\DELFT\\assignments\\RP\\GNN-SubNet_modified\\GNNSubNet\\graphcnn.py:134: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:623.)\n",
      "  graph_pool = torch.sparse.FloatTensor(idx, elem, torch.Size([len(batch_graph), start_idx[-1]]))\n",
      "100%|██████████| 35/35 [00:04<00:00,  7.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 227.9876\n",
      "Train Acc 0.5031\n",
      "Epoch 0, val_loss 34.8610\n",
      "Saving best model with validation loss 34.8609504699707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 32/35 [00:04<00:00,  7.81batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 18\u001B[0m\n\u001B[0;32m     15\u001B[0m g \u001B[38;5;241m=\u001B[39m gnn\u001B[38;5;241m.\u001B[39mGNNSubNet(loc, ppi, feats, targ)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Train the GNN classifier and validate performance on a test set\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m \u001B[43mg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\DELFT\\assignments\\RP\\GNN-SubNet_modified\\GNNSubNet\\GNNSubNet.py:117\u001B[0m, in \u001B[0;36mGNNSubNet.train\u001B[1;34m(self, epoch_nr, method, learning_rate)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m method\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraphcnn\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraphcnn for training ...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_graphcnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch_nr\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mepoch_nr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlearning_rate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    118\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraphcnn\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m method\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraphcheb\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\DELFT\\assignments\\RP\\GNN-SubNet_modified\\GNNSubNet\\GNNSubNet.py:979\u001B[0m, in \u001B[0;36mGNNSubNet.train_graphcnn\u001B[1;34m(self, num_layers, num_mlp_layers, epoch_nr, shuffle, weights, graph_pooling_type, neighbor_pooling_type, learning_rate)\u001B[0m\n\u001B[0;32m    976\u001B[0m     loss \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()(logits,labels)\n\u001B[0;32m    978\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m--> 979\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    980\u001B[0m opt\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    982\u001B[0m epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    524\u001B[0m     )\n\u001B[1;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    745\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    746\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from GNNSubNet import GNNSubNet as gnn\n",
    "\n",
    "# location of the files\n",
    "loc   = \"../TCGA\"\n",
    "# PPI network\n",
    "ppi   = f'{loc}/KIDNEY_RANDOM_PPI.txt'\n",
    "# single-omic features\n",
    "#feats = [f'{loc}/KIDNEY_RANDOM_Methy_FEATURES.txt']\n",
    "# multi-omic features\n",
    "feats = [f'{loc}/KIDNEY_RANDOM_mRNA_FEATURES.txt', f'{loc}/KIDNEY_RANDOM_Methy_FEATURES.txt']\n",
    "# outcome class\n",
    "targ  = f'{loc}/KIDNEY_RANDOM_TARGET.txt'\n",
    "\n",
    "# Load the multi-omics data\n",
    "g = gnn.GNNSubNet(loc, ppi, feats, targ)\n",
    "\n",
    "# Train the GNN classifier and validate performance on a test set\n",
    "g.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g.s2v_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph is connected  False\n",
      "Calculate subgraph ...\n",
      "Number of subgraphs:  118\n",
      "Size of subgraph:  2049\n",
      "Graph is connected  True\n",
      "##################\n",
      "# DATASET LOADED #\n",
      "##################\n"
     ]
    }
   ],
   "source": [
    "from GNNSubNet import GNNSubNet as gnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# location of the files\n",
    "loc   = \"../TCGA\"\n",
    "# PPI network\n",
    "ppi   = f'{loc}/KIDNEY_RANDOM_PPI.txt'\n",
    "# single-omic features\n",
    "#feats = [f'{loc}/KIDNEY_RANDOM_Methy_FEATURES.txt']\n",
    "# multi-omic features\n",
    "feats = [f'{loc}/KIDNEY_RANDOM_mRNA_FEATURES.txt', f'{loc}/KIDNEY_RANDOM_Methy_FEATURES.txt']\n",
    "# outcome class\n",
    "targ  = f'{loc}/KIDNEY_RANDOM_TARGET.txt'\n",
    "\n",
    "# Load the multi-omics data\n",
    "g = gnn.GNNSubNet(loc, ppi, feats, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GNNSubNet import GNNSubNet as gnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_communities(file_path):\n",
    "    communities = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            community = [int(num) for num in line.strip().split(',') if num]\n",
    "            communities.append(community)\n",
    "\n",
    "    return communities\n",
    "\n",
    "def read_community_importances(file_path):\n",
    "    community_importances = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "          community_importances.append(float(line.strip()))\n",
    "\n",
    "    return community_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def obtain_most_relevant_subnetworks(no_of_iterations=10, gnn_subnet=False, quantile_aggregation=False, quantile=0.5):\n",
    "\n",
    "    # location of the files\n",
    "    loc   = \"../TCGA\"\n",
    "    # PPI network\n",
    "    ppi   = f'{loc}/KIDNEY_RANDOM_PPI.txt'\n",
    "    # multi-omic features\n",
    "    feats = [f'{loc}/KIDNEY_RANDOM_mRNA_FEATURES.txt', f'{loc}/KIDNEY_RANDOM_Methy_FEATURES.txt']\n",
    "    # outcome class\n",
    "    targ  = f'{loc}/KIDNEY_RANDOM_TARGET.txt'\n",
    "\n",
    "    g = gnn.GNNSubNet(loc, ppi, feats, targ)\n",
    "\n",
    "    for i in range(5, no_of_iterations):\n",
    "\n",
    "        g.train()\n",
    "\n",
    "        # Run GNN-SubNet with 10 iterations\n",
    "        g.explain(10, gnn_subnet=gnn_subnet, quantile_aggregation=quantile_aggregation, quantile=quantile)\n",
    "\n",
    "        if(gnn_subnet):\n",
    "            community_file = \"../TCGA/communities_gnn_subnet.txt\"\n",
    "            community_importance_file = \"../TCGA/communities_scores_gnn_subnet.txt\"\n",
    "        else:\n",
    "            community_file = \"../TCGA/communities.txt\"\n",
    "            community_importance_file = \"../TCGA/communities_scores.txt\"\n",
    "\n",
    "        communities = read_communities(community_file)\n",
    "        community_importances = read_community_importances(community_importance_file)\n",
    "\n",
    "        sorted_indices = np.argsort(community_importances)[::-1]\n",
    "\n",
    "        sorted_communities = []\n",
    "\n",
    "        for index in sorted_indices:\n",
    "          sorted_communities.append(communities[index])\n",
    "\n",
    "        # The gene names of the community ranked highest by the algorithm\n",
    "        most_important_subnetwork = g.gene_names[sorted_communities[0]]\n",
    "\n",
    "        entry_dict = {\n",
    "            'Iteration':[i],\n",
    "            'Model Accuracy':[g.accuracy],\n",
    "            'Final Subnetwork':[most_important_subnetwork]\n",
    "        }\n",
    "\n",
    "        df_entry = pd.DataFrame(entry_dict)\n",
    "\n",
    "        if gnn_subnet:\n",
    "            path_to_save_to = \"subnetworks/subnetworks_gnn_subnet.csv\"\n",
    "        else:\n",
    "            if quantile_aggregation:\n",
    "                path_to_save_to = \"subnetworks/subnetworks_modified_alg_q05.csv\"\n",
    "            else:\n",
    "                path_to_save_to = \"subnetworks/subnetworks_modified_alg_mean.csv\"\n",
    "\n",
    "        df_entry.to_csv(path_to_save_to, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainer::Iteration 5 of 10\n",
      "Explainer::Iteration 6 of 10\n",
      "Explainer::Iteration 7 of 10\n",
      "Explainer::Iteration 8 of 10\n",
      "Explainer::Iteration 9 of 10\n",
      "Explainer::Iteration 10 of 10\n",
      "graphcnn for training ...\n",
      "Graphs class 0: 200, Graphs class 1: 306\n",
      "Length of balanced dataset list: 400\n",
      "Train graph class 0: 157, train graph class 1: 163\n",
      "Validation graph class 0: 43, validation graph class 1: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 124.4750\n",
      "Train Acc 0.4875\n",
      "Epoch 0, val_loss 58.5268\n",
      "Saving best model with validation loss 58.52680587768555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 26.1999\n",
      "Train Acc 0.4906\n",
      "Epoch 1, val_loss 62.2087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:09<00:00,  3.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss 22.8028\n",
      "Train Acc 0.7438\n",
      "Epoch 2, val_loss 6.8886\n",
      "Saving best model with validation loss 6.888577461242676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:08<00:00,  3.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss 18.2533\n",
      "Train Acc 0.7406\n",
      "Epoch 3, val_loss 6.7288\n",
      "Saving best model with validation loss 6.728846549987793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:10<00:00,  3.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss 20.0618\n",
      "Train Acc 0.6937\n",
      "Epoch 4, val_loss 13.1424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss 13.8039\n",
      "Train Acc 0.7812\n",
      "Epoch 5, val_loss 2.5447\n",
      "Saving best model with validation loss 2.544734477996826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss 15.3920\n",
      "Train Acc 0.6813\n",
      "Epoch 6, val_loss 13.0817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, loss 17.0753\n",
      "Train Acc 0.5938\n",
      "Epoch 7, val_loss 25.9555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, loss 14.8178\n",
      "Train Acc 0.5281\n",
      "Epoch 8, val_loss 9.8346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:11<00:00,  3.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, loss 15.8687\n",
      "Train Acc 0.8031\n",
      "Epoch 9, val_loss 2.4726\n",
      "Saving best model with validation loss 2.4725840091705322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss 12.9413\n",
      "Train Acc 0.5094\n",
      "Epoch 10, val_loss 9.6756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, loss 12.0458\n",
      "Train Acc 0.4938\n",
      "Epoch 11, val_loss 13.3967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:14<00:00,  2.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, loss 12.6021\n",
      "Train Acc 0.6750\n",
      "Epoch 12, val_loss 3.1774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, loss 18.2714\n",
      "Train Acc 0.7719\n",
      "Epoch 13, val_loss 14.3962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, loss 13.8490\n",
      "Train Acc 0.6469\n",
      "Epoch 14, val_loss 3.3882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, loss 10.0862\n",
      "Train Acc 0.6937\n",
      "Epoch 15, val_loss 3.4762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, loss 10.8766\n",
      "Train Acc 0.7125\n",
      "Epoch 16, val_loss 9.4151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:11<00:00,  2.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, loss 11.8573\n",
      "Train Acc 0.8344\n",
      "Epoch 17, val_loss 4.0536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, loss 10.4259\n",
      "Train Acc 0.8375\n",
      "Epoch 18, val_loss 2.8251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, loss 12.4228\n",
      "Train Acc 0.4906\n",
      "Epoch 19, val_loss 26.7583\n",
      "Early stopping!\n",
      "\n",
      "Confusion matrix (Validation set):\n",
      "\n",
      "[[33 10]\n",
      " [ 4 33]]\n",
      "Validation accuracy: 82.5%\n",
      "Validation loss 2.4725840091705322\n",
      "\n",
      "------- Run the Explainer -------\n",
      "\n",
      "GNN-SubNet: False\n",
      "Explainer::Iteration 1 of 10\n",
      "Explainer::Iteration 2 of 10\n",
      "Explainer::Iteration 3 of 10\n",
      "Explainer::Iteration 4 of 10\n",
      "Explainer::Iteration 5 of 10\n",
      "Explainer::Iteration 6 of 10\n",
      "Explainer::Iteration 7 of 10\n",
      "Explainer::Iteration 8 of 10\n",
      "Explainer::Iteration 9 of 10\n",
      "Explainer::Iteration 10 of 10\n",
      "graphcnn for training ...\n",
      "Graphs class 0: 200, Graphs class 1: 306\n",
      "Length of balanced dataset list: 400\n",
      "Train graph class 0: 156, train graph class 1: 164\n",
      "Validation graph class 0: 44, validation graph class 1: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 294.7730\n",
      "Train Acc 0.7125\n",
      "Epoch 0, val_loss 38.1410\n",
      "Saving best model with validation loss 38.14098358154297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:06<00:00,  5.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 56.3539\n",
      "Train Acc 0.5062\n",
      "Epoch 1, val_loss 20.4202\n",
      "Saving best model with validation loss 20.42021942138672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss 20.3771\n",
      "Train Acc 0.8031\n",
      "Epoch 2, val_loss 11.1059\n",
      "Saving best model with validation loss 11.10586166381836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss 10.7907\n",
      "Train Acc 0.8250\n",
      "Epoch 3, val_loss 3.6681\n",
      "Saving best model with validation loss 3.6680850982666016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:14<00:00,  2.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss 13.1922\n",
      "Train Acc 0.7031\n",
      "Epoch 4, val_loss 3.9774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss 15.1121\n",
      "Train Acc 0.4875\n",
      "Epoch 5, val_loss 20.1390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss 14.8683\n",
      "Train Acc 0.6656\n",
      "Epoch 6, val_loss 4.1037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:14<00:00,  2.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, loss 11.0630\n",
      "Train Acc 0.5594\n",
      "Epoch 7, val_loss 5.5286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:14<00:00,  2.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, loss 7.9850\n",
      "Train Acc 0.7281\n",
      "Epoch 8, val_loss 11.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:14<00:00,  2.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, loss 14.7283\n",
      "Train Acc 0.6000\n",
      "Epoch 9, val_loss 6.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:14<00:00,  2.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss 12.1901\n",
      "Train Acc 0.4875\n",
      "Epoch 10, val_loss 16.2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:14<00:00,  2.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, loss 12.0367\n",
      "Train Acc 0.8281\n",
      "Epoch 11, val_loss 3.0731\n",
      "Saving best model with validation loss 3.073070764541626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:14<00:00,  2.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, loss 9.7469\n",
      "Train Acc 0.7594\n",
      "Epoch 12, val_loss 14.8784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:14<00:00,  2.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, loss 10.6713\n",
      "Train Acc 0.8375\n",
      "Epoch 13, val_loss 4.5825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:14<00:00,  2.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, loss 8.6870\n",
      "Train Acc 0.8313\n",
      "Epoch 14, val_loss 3.0066\n",
      "Saving best model with validation loss 3.0066347122192383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, loss 7.7851\n",
      "Train Acc 0.8500\n",
      "Epoch 15, val_loss 5.2798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, loss 8.2386\n",
      "Train Acc 0.5406\n",
      "Epoch 16, val_loss 19.6164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, loss 9.2747\n",
      "Train Acc 0.8156\n",
      "Epoch 17, val_loss 2.2748\n",
      "Saving best model with validation loss 2.2748353481292725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, loss 6.2297\n",
      "Train Acc 0.5219\n",
      "Epoch 18, val_loss 5.3274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, loss 6.3778\n",
      "Train Acc 0.4906\n",
      "Epoch 19, val_loss 8.2679\n",
      "\n",
      "Confusion matrix (Validation set):\n",
      "\n",
      "[[31 13]\n",
      " [ 5 31]]\n",
      "Validation accuracy: 77.5%\n",
      "Validation loss 2.2748353481292725\n",
      "\n",
      "------- Run the Explainer -------\n",
      "\n",
      "GNN-SubNet: False\n",
      "Explainer::Iteration 1 of 10\n",
      "Explainer::Iteration 2 of 10\n",
      "Explainer::Iteration 3 of 10\n",
      "Explainer::Iteration 4 of 10\n",
      "Explainer::Iteration 5 of 10\n",
      "Explainer::Iteration 6 of 10\n",
      "Explainer::Iteration 7 of 10\n",
      "Explainer::Iteration 8 of 10\n",
      "Explainer::Iteration 9 of 10\n",
      "Explainer::Iteration 10 of 10\n",
      "graphcnn for training ...\n",
      "Graphs class 0: 200, Graphs class 1: 306\n",
      "Length of balanced dataset list: 400\n",
      "Train graph class 0: 158, train graph class 1: 162\n",
      "Validation graph class 0: 42, validation graph class 1: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.62batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 166.6354\n",
      "Train Acc 0.5062\n",
      "Epoch 0, val_loss 66.2265\n",
      "Saving best model with validation loss 66.22647094726562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 25.6844\n",
      "Train Acc 0.6687\n",
      "Epoch 1, val_loss 4.7774\n",
      "Saving best model with validation loss 4.777444362640381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss 13.8409\n",
      "Train Acc 0.7688\n",
      "Epoch 2, val_loss 4.8997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss 12.6643\n",
      "Train Acc 0.7562\n",
      "Epoch 3, val_loss 2.7277\n",
      "Saving best model with validation loss 2.7276787757873535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss 11.8172\n",
      "Train Acc 0.5125\n",
      "Epoch 4, val_loss 8.3198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss 7.8759\n",
      "Train Acc 0.7250\n",
      "Epoch 5, val_loss 2.2075\n",
      "Saving best model with validation loss 2.207460880279541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss 11.1537\n",
      "Train Acc 0.6875\n",
      "Epoch 6, val_loss 1.4292\n",
      "Saving best model with validation loss 1.4291760921478271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:06<00:00,  5.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, loss 12.4078\n",
      "Train Acc 0.6438\n",
      "Epoch 7, val_loss 9.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, loss 14.7958\n",
      "Train Acc 0.7844\n",
      "Epoch 8, val_loss 3.2776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:11<00:00,  3.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, loss 10.6876\n",
      "Train Acc 0.4938\n",
      "Epoch 9, val_loss 12.8196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss 9.1105\n",
      "Train Acc 0.7312\n",
      "Epoch 10, val_loss 0.9903\n",
      "Saving best model with validation loss 0.9903373718261719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, loss 7.9640\n",
      "Train Acc 0.5125\n",
      "Epoch 11, val_loss 17.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, loss 8.7007\n",
      "Train Acc 0.5125\n",
      "Epoch 12, val_loss 6.1295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, loss 8.2490\n",
      "Train Acc 0.5219\n",
      "Epoch 13, val_loss 4.6148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, loss 6.6413\n",
      "Train Acc 0.7031\n",
      "Epoch 14, val_loss 1.2464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, loss 5.2328\n",
      "Train Acc 0.6438\n",
      "Epoch 15, val_loss 1.1760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, loss 9.4522\n",
      "Train Acc 0.7500\n",
      "Epoch 16, val_loss 4.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, loss 5.1838\n",
      "Train Acc 0.6875\n",
      "Epoch 17, val_loss 1.1549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, loss 5.7407\n",
      "Train Acc 0.4875\n",
      "Epoch 18, val_loss 7.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, loss 12.2065\n",
      "Train Acc 0.7875\n",
      "Epoch 19, val_loss 0.7544\n",
      "Saving best model with validation loss 0.7544386386871338\n",
      "\n",
      "Confusion matrix (Validation set):\n",
      "\n",
      "[[35  7]\n",
      " [ 3 35]]\n",
      "Validation accuracy: 87.5%\n",
      "Validation loss 0.7544386386871338\n",
      "\n",
      "------- Run the Explainer -------\n",
      "\n",
      "GNN-SubNet: False\n",
      "Explainer::Iteration 1 of 10\n",
      "Explainer::Iteration 2 of 10\n",
      "Explainer::Iteration 3 of 10\n",
      "Explainer::Iteration 4 of 10\n",
      "Explainer::Iteration 5 of 10\n",
      "Explainer::Iteration 6 of 10\n",
      "Explainer::Iteration 7 of 10\n",
      "Explainer::Iteration 8 of 10\n",
      "Explainer::Iteration 9 of 10\n",
      "Explainer::Iteration 10 of 10\n",
      "graphcnn for training ...\n",
      "Graphs class 0: 200, Graphs class 1: 306\n",
      "Length of balanced dataset list: 400\n",
      "Train graph class 0: 160, train graph class 1: 160\n",
      "Validation graph class 0: 40, validation graph class 1: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 155.0706\n",
      "Train Acc 0.5500\n",
      "Epoch 0, val_loss 47.0636\n",
      "Saving best model with validation loss 47.0635986328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:04<00:00,  7.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 25.3108\n",
      "Train Acc 0.7312\n",
      "Epoch 1, val_loss 7.4089\n",
      "Saving best model with validation loss 7.4088544845581055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss 17.1232\n",
      "Train Acc 0.5719\n",
      "Epoch 2, val_loss 11.3222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss 8.8571\n",
      "Train Acc 0.6781\n",
      "Epoch 3, val_loss 6.5504\n",
      "Saving best model with validation loss 6.550389766693115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss 10.4932\n",
      "Train Acc 0.5031\n",
      "Epoch 4, val_loss 9.7847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss 14.1884\n",
      "Train Acc 0.7594\n",
      "Epoch 5, val_loss 5.1078\n",
      "Saving best model with validation loss 5.107825756072998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss 24.7855\n",
      "Train Acc 0.7312\n",
      "Epoch 6, val_loss 6.6175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, loss 11.3841\n",
      "Train Acc 0.7594\n",
      "Epoch 7, val_loss 3.1601\n",
      "Saving best model with validation loss 3.1600847244262695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, loss 13.4148\n",
      "Train Acc 0.7750\n",
      "Epoch 8, val_loss 5.6070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, loss 10.0189\n",
      "Train Acc 0.5094\n",
      "Epoch 9, val_loss 14.4763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss 10.0226\n",
      "Train Acc 0.7500\n",
      "Epoch 10, val_loss 5.3003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, loss 10.7434\n",
      "Train Acc 0.7438\n",
      "Epoch 11, val_loss 6.0785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, loss 17.7313\n",
      "Train Acc 0.7031\n",
      "Epoch 12, val_loss 6.6951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.62batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, loss 12.8681\n",
      "Train Acc 0.7937\n",
      "Epoch 13, val_loss 2.4946\n",
      "Saving best model with validation loss 2.494617462158203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, loss 7.4462\n",
      "Train Acc 0.6750\n",
      "Epoch 14, val_loss 4.4653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, loss 6.1649\n",
      "Train Acc 0.7656\n",
      "Epoch 15, val_loss 1.7270\n",
      "Saving best model with validation loss 1.7270179986953735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, loss 6.8221\n",
      "Train Acc 0.6406\n",
      "Epoch 16, val_loss 10.1797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, loss 9.1512\n",
      "Train Acc 0.7969\n",
      "Epoch 17, val_loss 4.7363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, loss 8.6608\n",
      "Train Acc 0.5344\n",
      "Epoch 18, val_loss 14.4722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:05<00:00,  6.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, loss 6.2948\n",
      "Train Acc 0.7719\n",
      "Epoch 19, val_loss 3.4343\n",
      "\n",
      "Confusion matrix (Validation set):\n",
      "\n",
      "[[33  7]\n",
      " [13 27]]\n",
      "Validation accuracy: 75.0%\n",
      "Validation loss 1.7270179986953735\n",
      "\n",
      "------- Run the Explainer -------\n",
      "\n",
      "GNN-SubNet: False\n",
      "Explainer::Iteration 1 of 10\n",
      "Explainer::Iteration 2 of 10\n",
      "Explainer::Iteration 3 of 10\n",
      "Explainer::Iteration 4 of 10\n"
     ]
    }
   ],
   "source": [
    "obtain_most_relevant_subnetworks(no_of_iterations=10, gnn_subnet=False, quantile_aggregation=True, quantile=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
