{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# See description above for what these variables represent\n",
    "big_loop_iterations = 10\n",
    "explainer_runs = 10\n",
    "thresholds = [30, 50]\n",
    "samples = [10]\n",
    "\n",
    "# Used to label the resulting files -\n",
    "date = \"modified_alg_final\"\n",
    "\n",
    "# Set up directory for result files\n",
    "import os\n",
    "dir = f'./results_{date}'\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph is connected  False\n",
      "Calculate subgraph ...\n",
      "Number of subgraphs:  118\n",
      "Size of subgraph:  2049\n",
      "Graph is connected  True\n",
      "##################\n",
      "# DATASET LOADED #\n",
      "##################\n",
      "\n",
      "Number of nodes: 2049\n",
      "Number of edges: 13588\n",
      "Number of modalities: 2\n"
     ]
    }
   ],
   "source": [
    "from GNNSubNet import GNNSubNet as gnn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# # Kidney data set  ------------------------- #\n",
    "loc   = \"../TCGA\"\n",
    "ppi   = f'{loc}/KIDNEY_RANDOM_PPI.txt'\n",
    "feats = [f'{loc}/KIDNEY_RANDOM_Methy_FEATURES.txt', f'{loc}/KIDNEY_RANDOM_mRNA_FEATURES.txt']\n",
    "targ  = f'{loc}/KIDNEY_RANDOM_TARGET.txt'\n",
    "\n",
    "# # Synthetic data set  ------------------------- #\n",
    "# loc   = \"../GNNSubNet/datasets/synthetic/\"\n",
    "# ppi   = f'{loc}/NETWORK_synthetic.txt'\n",
    "# feats = [f'{loc}/FEATURES_synthetic.txt']\n",
    "# targ  = f'{loc}/TARGET_synthetic.txt'\n",
    "\n",
    "# Read in the synthetic data\n",
    "g = gnn.GNNSubNet(loc, ppi, feats, targ, normalize=False)\n",
    "\n",
    "# Get some general information about the data dimension\n",
    "g.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obtain_BAGEL_scores(loc, ppi, feats, targ, gnn_subnet):\n",
    "    model_info = []\n",
    "    fidelity = []\n",
    "    validity_plus = []\n",
    "    validity_minus = []\n",
    "    validity_plus_matrix = []\n",
    "    validity_minus_matrix = []\n",
    "    sparsity = []\n",
    "\n",
    "    for i in range(9, big_loop_iterations):\n",
    "        print(i)\n",
    "        g = gnn.GNNSubNet(loc, ppi, feats, targ, normalize=False)\n",
    "        g.train()\n",
    "\n",
    "        # Check the performance of the classifier\n",
    "        accuracy = g.accuracy\n",
    "\n",
    "        # Run the explainer the desired number of times\n",
    "        g.explain(explainer_runs, gnn_subnet=gnn_subnet)\n",
    "\n",
    "        # Fidelity\n",
    "        f = g.evaluate_RDT_fidelity_soft()\n",
    "        fidelity.append([i, accuracy, np.mean(f)])\n",
    "        # Save mean fidelity for each sample for further analysis\n",
    "        filename = f\"results_{date}/{i}_fidelities.csv\"\n",
    "        np.savetxt(filename, fidelity, delimiter=',', fmt ='% s')\n",
    "\n",
    "        # Sparsity\n",
    "        sparsities = g.evaluate_sparsity()\n",
    "        # Save raw results in case needed for further analysis\n",
    "        filename = f\"results_{date}/{i}_sparsities.csv\"\n",
    "        np.savetxt(filename, sparsities, delimiter=',', fmt ='% s')\n",
    "        # Save mean sparsity to list to create processed table\n",
    "        sparsity.append([i, accuracy, np.mean(sparsities)])\n",
    "\n",
    "        # Validity at varying thresholds\n",
    "        for t in thresholds:\n",
    "            v_plus, v_minus, mat_plus, mat_minus = g.evaluate_validity(threshold=t, confusion_matrix=True)\n",
    "            validity_plus.append([i, accuracy, t, v_plus])\n",
    "            validity_minus.append([i, accuracy, t, v_minus])\n",
    "            validity_plus_matrix.append([i, accuracy, t, mat_plus[0,0], mat_plus[0,1], mat_plus[1,0], mat_plus[1,1]])\n",
    "            validity_minus_matrix.append([i, accuracy, t, mat_minus[0,0], mat_minus[0,1], mat_minus[1,0], mat_minus[1,1]])\n",
    "\n",
    "        filename = f\"results_{date}/{i}_validity_plus.csv\"\n",
    "        np.savetxt(filename, validity_plus, delimiter=',', fmt ='% s')\n",
    "\n",
    "        filename = f\"results_{date}/{i}_validity_minus.csv\"\n",
    "        np.savetxt(filename, validity_minus, delimiter=',', fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_modified_alg_final\n"
     ]
    }
   ],
   "source": [
    "print(f\"results_{date}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Runs the experiment for a single explainer\n",
    "# Toggle the gnn_subnet parameter for the desired explainer\n",
    "obtain_BAGEL_scores(loc, ppi, feats, targ, gnn_subnet=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
