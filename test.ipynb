{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph is connected  True\n",
      "Graph is connected  True\n",
      "##################\n",
      "# DATASET LOADED #\n",
      "##################\n",
      "\n",
      "Number of nodes: 30\n",
      "Number of edges: 29\n",
      "Number of modalities: 1\n",
      "graphcnn for training ...\n",
      "Graphs class 0: 500, Graphs class 1: 500\n",
      "Length of balanced dataset list: 1000\n",
      "Train graph class 0: 403, train graph class 1: 397\n",
      "Validation graph class 0: 97, validation graph class 1: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35 [00:00<?, ?batch/s]C:\\Users\\elena\\DELFT\\assignments\\RP\\GNN-SubNet_modified\\GNNSubNet\\graphcnn.py:134: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:623.)\n",
      "  graph_pool = torch.sparse.FloatTensor(idx, elem, torch.Size([len(batch_graph), start_idx[-1]]))\n",
      "100%|██████████| 35/35 [00:00<00:00, 78.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 0.5150\n",
      "Train Acc 1.0000\n",
      "Epoch 0, val_loss 0.0001\n",
      "Saving best model with validation loss 0.00010355010454077274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 151.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.2464\n",
      "Train Acc 1.0000\n",
      "Epoch 1, val_loss 0.0000\n",
      "Saving best model with validation loss 8.946555567490577e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 145.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss 0.1751\n",
      "Train Acc 1.0000\n",
      "Epoch 2, val_loss 0.0000\n",
      "Saving best model with validation loss 3.6179838502903294e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 122.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss 0.0988\n",
      "Train Acc 1.0000\n",
      "Epoch 3, val_loss 0.0000\n",
      "Saving best model with validation loss 2.7954465053880995e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 147.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss 0.0741\n",
      "Train Acc 1.0000\n",
      "Epoch 4, val_loss 0.0000\n",
      "Saving best model with validation loss 2.3543752547539043e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 180.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss 0.0739\n",
      "Train Acc 1.0000\n",
      "Epoch 5, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 164.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss 0.0738\n",
      "Train Acc 1.0000\n",
      "Epoch 6, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 182.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, loss 0.0623\n",
      "Train Acc 1.0000\n",
      "Epoch 7, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 168.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, loss 0.0501\n",
      "Train Acc 1.0000\n",
      "Epoch 8, val_loss 0.0000\n",
      "Saving best model with validation loss 2.181521807642639e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 182.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, loss 0.0633\n",
      "Train Acc 1.0000\n",
      "Epoch 9, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 171.48batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss 0.0664\n",
      "Train Acc 1.0000\n",
      "Epoch 10, val_loss 0.0000\n",
      "Saving best model with validation loss 1.3947453680884792e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 182.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, loss 0.0564\n",
      "Train Acc 1.0000\n",
      "Epoch 11, val_loss 0.0000\n",
      "Saving best model with validation loss 6.02005982841547e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 174.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, loss 0.0459\n",
      "Train Acc 1.0000\n",
      "Epoch 12, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 171.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, loss 0.0516\n",
      "Train Acc 1.0000\n",
      "Epoch 13, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 180.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, loss 0.0585\n",
      "Train Acc 1.0000\n",
      "Epoch 14, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 184.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, loss 0.0468\n",
      "Train Acc 1.0000\n",
      "Epoch 15, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 178.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, loss 0.0530\n",
      "Train Acc 1.0000\n",
      "Epoch 16, val_loss 0.0000\n",
      "Saving best model with validation loss 5.245200895842572e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 171.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, loss 0.0474\n",
      "Train Acc 1.0000\n",
      "Epoch 17, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 169.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, loss 0.0530\n",
      "Train Acc 1.0000\n",
      "Epoch 18, val_loss 0.0000\n",
      "Saving best model with validation loss 2.1457658760937193e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 186.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, loss 0.0514\n",
      "Train Acc 1.0000\n",
      "Epoch 19, val_loss 0.0000\n",
      "\n",
      "Confusion matrix (Validation set):\n",
      "\n",
      "[[ 97   0]\n",
      " [  0 103]]\n",
      "Validation accuracy: 100.0%\n",
      "Validation loss 2.1457658760937193e-08\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from GNNSubNet import GNNSubNet as gnn\n",
    "\n",
    "# Synthetic data set  ------------------------- #\n",
    "loc   = \"GNNSubNet/datasets/synthetic\"\n",
    "ppi   = f'{loc}/NETWORK_synthetic.txt'\n",
    "feats = [f'{loc}/FEATURES_synthetic.txt']\n",
    "targ  = f'{loc}/TARGET_synthetic.txt'\n",
    "\n",
    "# Read in the synthetic data\n",
    "g = gnn.GNNSubNet(loc, ppi, feats, targ, normalize=False)\n",
    "\n",
    "# Get some general information about the data dimension\n",
    "g.summary()\n",
    "\n",
    "# Train the GNN classifier and validate performance on a test set\n",
    "g.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([30, 1])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.s2v_test_dataset[0].node_features.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[<GNNSubNet.s2vgraph.S2VGraph at 0x16c91adbfd0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b970d0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97160>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b971f0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97280>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97310>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b973a0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97430>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b974c0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97550>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b975e0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97670>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97700>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97790>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97820>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b978b0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97940>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b979d0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97a60>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97af0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c90567700>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c8ed2dd60>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c8f0fb250>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c8e7d91c0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c8f0a1430>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97be0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97c70>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97d00>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97d90>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97e20>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97eb0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97f40>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91b97fd0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c0a0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c130>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c1c0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c250>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c2e0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c370>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c400>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c490>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c520>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c5b0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c640>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c6d0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c760>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c7f0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c880>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c910>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5c9a0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5ca30>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5cac0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5cb50>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5cbe0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5cc70>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5cd00>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5cd90>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5ce20>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5ceb0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5cf40>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91c5cfd0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d180a0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18130>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d181c0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18250>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d182e0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18370>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18400>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18490>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18520>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d185b0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18640>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d186d0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18760>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d187f0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18880>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18910>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d189a0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18a30>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18ac0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18b50>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18be0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18c70>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18d00>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18d90>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18e20>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18eb0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18f40>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91d18fd0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd30a0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3130>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd31c0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3250>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd32e0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3370>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3400>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3490>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3520>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd35b0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3640>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd36d0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3760>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd37f0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3880>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3910>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd39a0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3a30>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3ac0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3b50>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3be0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3c70>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3d00>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3d90>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3e20>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3eb0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3f40>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91dd3fd0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e0a0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e130>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e1c0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e250>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e2e0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e370>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e400>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e490>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e520>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e5b0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e640>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e6d0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e760>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e7f0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e880>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e910>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8e9a0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8ea30>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8eac0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8eb50>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8ebe0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8ec70>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8ed00>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8ed90>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8ee20>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8eeb0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8ef40>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91e8efd0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f490a0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49130>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f491c0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49250>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f492e0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49370>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49400>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49490>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49520>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f495b0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49640>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f496d0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49760>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f497f0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49880>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49910>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f499a0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49a30>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49ac0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49b50>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49be0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49c70>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49d00>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49d90>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49e20>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49eb0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49f40>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c91f49fd0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c920040a0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004130>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c920041c0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004250>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c920042e0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004370>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004400>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004490>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004520>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c920045b0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004640>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c920046d0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004760>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c920047f0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004880>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004910>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c920049a0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004a30>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004ac0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004b50>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004be0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004c70>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004d00>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004d90>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004e20>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004eb0>,\n <GNNSubNet.s2vgraph.S2VGraph at 0x16c92004f40>]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.s2v_test_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n       0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1.,\n       1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n       0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n       0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n       1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n       0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1.,\n       1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n       0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,\n       1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n       0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from GNNSubNet import gnn_explainer as gnne\n",
    "import torch\n",
    "\n",
    "exp = gnne.GNNExplainer(g.model, epochs=300, lr = 0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "30"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.s2v_test_dataset[0].node_features.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-37.4100], grad_fn=<AddBackward0>)\n",
      "tensor([-37.6718], grad_fn=<AddBackward0>)\n",
      "tensor([-37.9335], grad_fn=<AddBackward0>)\n",
      "tensor([-38.1940], grad_fn=<AddBackward0>)\n",
      "tensor([-38.4524], grad_fn=<AddBackward0>)\n",
      "tensor([-38.7064], grad_fn=<AddBackward0>)\n",
      "tensor([-38.9542], grad_fn=<AddBackward0>)\n",
      "tensor([-39.1947], grad_fn=<AddBackward0>)\n",
      "tensor([-39.4279], grad_fn=<AddBackward0>)\n",
      "tensor([-39.6530], grad_fn=<AddBackward0>)\n",
      "tensor([-39.8687], grad_fn=<AddBackward0>)\n",
      "tensor([-40.0747], grad_fn=<AddBackward0>)\n",
      "tensor([-40.2710], grad_fn=<AddBackward0>)\n",
      "tensor([-40.4567], grad_fn=<AddBackward0>)\n",
      "tensor([-40.6318], grad_fn=<AddBackward0>)\n",
      "tensor([-40.7965], grad_fn=<AddBackward0>)\n",
      "tensor([-40.9507], grad_fn=<AddBackward0>)\n",
      "tensor([-41.0948], grad_fn=<AddBackward0>)\n",
      "tensor([-41.2290], grad_fn=<AddBackward0>)\n",
      "tensor([-41.3536], grad_fn=<AddBackward0>)\n",
      "tensor([-41.4689], grad_fn=<AddBackward0>)\n",
      "tensor([-41.5755], grad_fn=<AddBackward0>)\n",
      "tensor([-41.6740], grad_fn=<AddBackward0>)\n",
      "tensor([-41.7648], grad_fn=<AddBackward0>)\n",
      "tensor([-41.8484], grad_fn=<AddBackward0>)\n",
      "tensor([-41.9254], grad_fn=<AddBackward0>)\n",
      "tensor([-41.9962], grad_fn=<AddBackward0>)\n",
      "tensor([-42.0612], grad_fn=<AddBackward0>)\n",
      "tensor([-42.1210], grad_fn=<AddBackward0>)\n",
      "tensor([-42.1759], grad_fn=<AddBackward0>)\n",
      "tensor([-42.2265], grad_fn=<AddBackward0>)\n",
      "tensor([-42.2729], grad_fn=<AddBackward0>)\n",
      "tensor([-42.3155], grad_fn=<AddBackward0>)\n",
      "tensor([-42.3548], grad_fn=<AddBackward0>)\n",
      "tensor([-42.3910], grad_fn=<AddBackward0>)\n",
      "tensor([-42.4245], grad_fn=<AddBackward0>)\n",
      "tensor([-42.4553], grad_fn=<AddBackward0>)\n",
      "tensor([-42.4838], grad_fn=<AddBackward0>)\n",
      "tensor([-42.5102], grad_fn=<AddBackward0>)\n",
      "tensor([-42.5346], grad_fn=<AddBackward0>)\n",
      "tensor([-42.5573], grad_fn=<AddBackward0>)\n",
      "tensor([-42.5783], grad_fn=<AddBackward0>)\n",
      "tensor([-42.5978], grad_fn=<AddBackward0>)\n",
      "tensor([-42.6160], grad_fn=<AddBackward0>)\n",
      "tensor([-42.6330], grad_fn=<AddBackward0>)\n",
      "tensor([-42.6488], grad_fn=<AddBackward0>)\n",
      "tensor([-42.6636], grad_fn=<AddBackward0>)\n",
      "tensor([-42.6774], grad_fn=<AddBackward0>)\n",
      "tensor([-42.6904], grad_fn=<AddBackward0>)\n",
      "tensor([-42.7025], grad_fn=<AddBackward0>)\n",
      "tensor([-42.7137], grad_fn=<AddBackward0>)\n",
      "tensor([-42.7245], grad_fn=<AddBackward0>)\n",
      "tensor([-42.7346], grad_fn=<AddBackward0>)\n",
      "tensor([-42.7442], grad_fn=<AddBackward0>)\n",
      "tensor([-42.7532], grad_fn=<AddBackward0>)\n",
      "tensor([-42.7618], grad_fn=<AddBackward0>)\n",
      "tensor([-42.7699], grad_fn=<AddBackward0>)\n",
      "tensor([-42.7776], grad_fn=<AddBackward0>)\n",
      "tensor([-42.7849], grad_fn=<AddBackward0>)\n",
      "tensor([-42.7918], grad_fn=<AddBackward0>)\n",
      "tensor([-42.7984], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8047], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8107], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8164], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8219], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8271], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8321], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8369], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8416], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8460], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8502], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8543], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8583], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8621], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8657], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8693], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8727], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8760], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8792], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8823], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8853], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8882], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8910], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8938], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8964], grad_fn=<AddBackward0>)\n",
      "tensor([-42.8990], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9015], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9039], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9063], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9086], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9108], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9130], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9152], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9172], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9193], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9212], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9232], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9250], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9269], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9287], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9300], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9317], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9334], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9350], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9366], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9382], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9397], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9412], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9427], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9442], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9456], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9470], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9483], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9497], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9510], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9523], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9535], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9548], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9560], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9572], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9584], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9595], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9606], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9617], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9628], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9639], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9649], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9660], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9670], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9680], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9690], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9699], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9709], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9718], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9727], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9736], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9745], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9754], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9762], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9770], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9779], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9787], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9795], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9803], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9811], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9818], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9826], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9833], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9841], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9848], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9861], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9868], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9875], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9882], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9888], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9895], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9901], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9908], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9914], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9920], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9926], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9932], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9938], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9944], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9949], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9955], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9961], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9966], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9972], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9977], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9982], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9987], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9992], grad_fn=<AddBackward0>)\n",
      "tensor([-42.9997], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0003], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0007], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0012], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0017], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0022], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0027], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0031], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0036], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0040], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0045], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0049], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0053], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0058], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0062], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0066], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0070], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0075], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0079], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0083], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0087], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0090], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0094], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0098], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0102], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0106], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0109], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0104], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0108], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0111], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0115], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0118], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0122], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0125], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0129], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0132], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0136], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0139], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0142], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0146], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0149], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0152], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0155], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0159], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0162], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0165], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0168], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0171], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0174], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0177], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0180], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0183], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0186], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0188], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0191], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0194], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0197], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0200], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0202], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0205], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0208], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0210], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0213], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0215], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0218], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0220], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0223], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0225], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0228], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0230], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0233], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0235], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0237], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0240], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0242], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0244], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0247], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0251], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0254], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0256], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0258], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0260], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0262], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0264], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0266], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0269], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0271], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0273], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0275], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0277], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0279], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0281], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0282], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0284], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0286], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0288], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0290], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0292], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0294], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0296], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0297], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0299], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0301], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0303], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0304], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0306], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0308], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0310], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0311], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0313], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0315], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0316], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0318], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0319], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0321], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0323], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0324], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0326], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0327], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0329], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0330], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0332], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0333], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0335], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0336], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0338], grad_fn=<AddBackward0>)\n",
      "tensor([-43.0339], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Parameter containing:\n tensor([-6.3686], requires_grad=True)]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigN, bigL = exp.explain_graph_modified_s2v(g.s2v_test_dataset, 0.1)\n",
    "bigN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[[tensor([-37.4100], grad_fn=<AddBackward0>),\n  tensor([-37.6718], grad_fn=<AddBackward0>),\n  tensor([-37.9335], grad_fn=<AddBackward0>),\n  tensor([-38.1940], grad_fn=<AddBackward0>),\n  tensor([-38.4524], grad_fn=<AddBackward0>),\n  tensor([-38.7064], grad_fn=<AddBackward0>),\n  tensor([-38.9542], grad_fn=<AddBackward0>),\n  tensor([-39.1947], grad_fn=<AddBackward0>),\n  tensor([-39.4279], grad_fn=<AddBackward0>),\n  tensor([-39.6530], grad_fn=<AddBackward0>),\n  tensor([-39.8687], grad_fn=<AddBackward0>),\n  tensor([-40.0747], grad_fn=<AddBackward0>),\n  tensor([-40.2710], grad_fn=<AddBackward0>),\n  tensor([-40.4567], grad_fn=<AddBackward0>),\n  tensor([-40.6318], grad_fn=<AddBackward0>),\n  tensor([-40.7965], grad_fn=<AddBackward0>),\n  tensor([-40.9507], grad_fn=<AddBackward0>),\n  tensor([-41.0948], grad_fn=<AddBackward0>),\n  tensor([-41.2290], grad_fn=<AddBackward0>),\n  tensor([-41.3536], grad_fn=<AddBackward0>),\n  tensor([-41.4689], grad_fn=<AddBackward0>),\n  tensor([-41.5755], grad_fn=<AddBackward0>),\n  tensor([-41.6740], grad_fn=<AddBackward0>),\n  tensor([-41.7648], grad_fn=<AddBackward0>),\n  tensor([-41.8484], grad_fn=<AddBackward0>),\n  tensor([-41.9254], grad_fn=<AddBackward0>),\n  tensor([-41.9962], grad_fn=<AddBackward0>),\n  tensor([-42.0612], grad_fn=<AddBackward0>),\n  tensor([-42.1210], grad_fn=<AddBackward0>),\n  tensor([-42.1759], grad_fn=<AddBackward0>),\n  tensor([-42.2265], grad_fn=<AddBackward0>),\n  tensor([-42.2729], grad_fn=<AddBackward0>),\n  tensor([-42.3155], grad_fn=<AddBackward0>),\n  tensor([-42.3548], grad_fn=<AddBackward0>),\n  tensor([-42.3910], grad_fn=<AddBackward0>),\n  tensor([-42.4245], grad_fn=<AddBackward0>),\n  tensor([-42.4553], grad_fn=<AddBackward0>),\n  tensor([-42.4838], grad_fn=<AddBackward0>),\n  tensor([-42.5102], grad_fn=<AddBackward0>),\n  tensor([-42.5346], grad_fn=<AddBackward0>),\n  tensor([-42.5573], grad_fn=<AddBackward0>),\n  tensor([-42.5783], grad_fn=<AddBackward0>),\n  tensor([-42.5978], grad_fn=<AddBackward0>),\n  tensor([-42.6160], grad_fn=<AddBackward0>),\n  tensor([-42.6330], grad_fn=<AddBackward0>),\n  tensor([-42.6488], grad_fn=<AddBackward0>),\n  tensor([-42.6636], grad_fn=<AddBackward0>),\n  tensor([-42.6774], grad_fn=<AddBackward0>),\n  tensor([-42.6904], grad_fn=<AddBackward0>),\n  tensor([-42.7025], grad_fn=<AddBackward0>),\n  tensor([-42.7137], grad_fn=<AddBackward0>),\n  tensor([-42.7245], grad_fn=<AddBackward0>),\n  tensor([-42.7346], grad_fn=<AddBackward0>),\n  tensor([-42.7442], grad_fn=<AddBackward0>),\n  tensor([-42.7532], grad_fn=<AddBackward0>),\n  tensor([-42.7618], grad_fn=<AddBackward0>),\n  tensor([-42.7699], grad_fn=<AddBackward0>),\n  tensor([-42.7776], grad_fn=<AddBackward0>),\n  tensor([-42.7849], grad_fn=<AddBackward0>),\n  tensor([-42.7918], grad_fn=<AddBackward0>),\n  tensor([-42.7984], grad_fn=<AddBackward0>),\n  tensor([-42.8047], grad_fn=<AddBackward0>),\n  tensor([-42.8107], grad_fn=<AddBackward0>),\n  tensor([-42.8164], grad_fn=<AddBackward0>),\n  tensor([-42.8219], grad_fn=<AddBackward0>),\n  tensor([-42.8271], grad_fn=<AddBackward0>),\n  tensor([-42.8321], grad_fn=<AddBackward0>),\n  tensor([-42.8369], grad_fn=<AddBackward0>),\n  tensor([-42.8416], grad_fn=<AddBackward0>),\n  tensor([-42.8460], grad_fn=<AddBackward0>),\n  tensor([-42.8502], grad_fn=<AddBackward0>),\n  tensor([-42.8543], grad_fn=<AddBackward0>),\n  tensor([-42.8583], grad_fn=<AddBackward0>),\n  tensor([-42.8621], grad_fn=<AddBackward0>),\n  tensor([-42.8657], grad_fn=<AddBackward0>),\n  tensor([-42.8693], grad_fn=<AddBackward0>),\n  tensor([-42.8727], grad_fn=<AddBackward0>),\n  tensor([-42.8760], grad_fn=<AddBackward0>),\n  tensor([-42.8792], grad_fn=<AddBackward0>),\n  tensor([-42.8823], grad_fn=<AddBackward0>),\n  tensor([-42.8853], grad_fn=<AddBackward0>),\n  tensor([-42.8882], grad_fn=<AddBackward0>),\n  tensor([-42.8910], grad_fn=<AddBackward0>),\n  tensor([-42.8938], grad_fn=<AddBackward0>),\n  tensor([-42.8964], grad_fn=<AddBackward0>),\n  tensor([-42.8990], grad_fn=<AddBackward0>),\n  tensor([-42.9015], grad_fn=<AddBackward0>),\n  tensor([-42.9039], grad_fn=<AddBackward0>),\n  tensor([-42.9063], grad_fn=<AddBackward0>),\n  tensor([-42.9086], grad_fn=<AddBackward0>),\n  tensor([-42.9108], grad_fn=<AddBackward0>),\n  tensor([-42.9130], grad_fn=<AddBackward0>),\n  tensor([-42.9152], grad_fn=<AddBackward0>),\n  tensor([-42.9172], grad_fn=<AddBackward0>),\n  tensor([-42.9193], grad_fn=<AddBackward0>),\n  tensor([-42.9212], grad_fn=<AddBackward0>),\n  tensor([-42.9232], grad_fn=<AddBackward0>),\n  tensor([-42.9250], grad_fn=<AddBackward0>),\n  tensor([-42.9269], grad_fn=<AddBackward0>),\n  tensor([-42.9287], grad_fn=<AddBackward0>),\n  tensor([-42.9300], grad_fn=<AddBackward0>),\n  tensor([-42.9317], grad_fn=<AddBackward0>),\n  tensor([-42.9334], grad_fn=<AddBackward0>),\n  tensor([-42.9350], grad_fn=<AddBackward0>),\n  tensor([-42.9366], grad_fn=<AddBackward0>),\n  tensor([-42.9382], grad_fn=<AddBackward0>),\n  tensor([-42.9397], grad_fn=<AddBackward0>),\n  tensor([-42.9412], grad_fn=<AddBackward0>),\n  tensor([-42.9427], grad_fn=<AddBackward0>),\n  tensor([-42.9442], grad_fn=<AddBackward0>),\n  tensor([-42.9456], grad_fn=<AddBackward0>),\n  tensor([-42.9470], grad_fn=<AddBackward0>),\n  tensor([-42.9483], grad_fn=<AddBackward0>),\n  tensor([-42.9497], grad_fn=<AddBackward0>),\n  tensor([-42.9510], grad_fn=<AddBackward0>),\n  tensor([-42.9523], grad_fn=<AddBackward0>),\n  tensor([-42.9535], grad_fn=<AddBackward0>),\n  tensor([-42.9548], grad_fn=<AddBackward0>),\n  tensor([-42.9560], grad_fn=<AddBackward0>),\n  tensor([-42.9572], grad_fn=<AddBackward0>),\n  tensor([-42.9584], grad_fn=<AddBackward0>),\n  tensor([-42.9595], grad_fn=<AddBackward0>),\n  tensor([-42.9606], grad_fn=<AddBackward0>),\n  tensor([-42.9617], grad_fn=<AddBackward0>),\n  tensor([-42.9628], grad_fn=<AddBackward0>),\n  tensor([-42.9639], grad_fn=<AddBackward0>),\n  tensor([-42.9649], grad_fn=<AddBackward0>),\n  tensor([-42.9660], grad_fn=<AddBackward0>),\n  tensor([-42.9670], grad_fn=<AddBackward0>),\n  tensor([-42.9680], grad_fn=<AddBackward0>),\n  tensor([-42.9690], grad_fn=<AddBackward0>),\n  tensor([-42.9699], grad_fn=<AddBackward0>),\n  tensor([-42.9709], grad_fn=<AddBackward0>),\n  tensor([-42.9718], grad_fn=<AddBackward0>),\n  tensor([-42.9727], grad_fn=<AddBackward0>),\n  tensor([-42.9736], grad_fn=<AddBackward0>),\n  tensor([-42.9745], grad_fn=<AddBackward0>),\n  tensor([-42.9754], grad_fn=<AddBackward0>),\n  tensor([-42.9762], grad_fn=<AddBackward0>),\n  tensor([-42.9770], grad_fn=<AddBackward0>),\n  tensor([-42.9779], grad_fn=<AddBackward0>),\n  tensor([-42.9787], grad_fn=<AddBackward0>),\n  tensor([-42.9795], grad_fn=<AddBackward0>),\n  tensor([-42.9803], grad_fn=<AddBackward0>),\n  tensor([-42.9811], grad_fn=<AddBackward0>),\n  tensor([-42.9818], grad_fn=<AddBackward0>),\n  tensor([-42.9826], grad_fn=<AddBackward0>),\n  tensor([-42.9833], grad_fn=<AddBackward0>),\n  tensor([-42.9841], grad_fn=<AddBackward0>),\n  tensor([-42.9848], grad_fn=<AddBackward0>),\n  tensor([-42.9861], grad_fn=<AddBackward0>),\n  tensor([-42.9868], grad_fn=<AddBackward0>),\n  tensor([-42.9875], grad_fn=<AddBackward0>),\n  tensor([-42.9882], grad_fn=<AddBackward0>),\n  tensor([-42.9888], grad_fn=<AddBackward0>),\n  tensor([-42.9895], grad_fn=<AddBackward0>),\n  tensor([-42.9901], grad_fn=<AddBackward0>),\n  tensor([-42.9908], grad_fn=<AddBackward0>),\n  tensor([-42.9914], grad_fn=<AddBackward0>),\n  tensor([-42.9920], grad_fn=<AddBackward0>),\n  tensor([-42.9926], grad_fn=<AddBackward0>),\n  tensor([-42.9932], grad_fn=<AddBackward0>),\n  tensor([-42.9938], grad_fn=<AddBackward0>),\n  tensor([-42.9944], grad_fn=<AddBackward0>),\n  tensor([-42.9949], grad_fn=<AddBackward0>),\n  tensor([-42.9955], grad_fn=<AddBackward0>),\n  tensor([-42.9961], grad_fn=<AddBackward0>),\n  tensor([-42.9966], grad_fn=<AddBackward0>),\n  tensor([-42.9972], grad_fn=<AddBackward0>),\n  tensor([-42.9977], grad_fn=<AddBackward0>),\n  tensor([-42.9982], grad_fn=<AddBackward0>),\n  tensor([-42.9987], grad_fn=<AddBackward0>),\n  tensor([-42.9992], grad_fn=<AddBackward0>),\n  tensor([-42.9997], grad_fn=<AddBackward0>),\n  tensor([-43.0003], grad_fn=<AddBackward0>),\n  tensor([-43.0007], grad_fn=<AddBackward0>),\n  tensor([-43.0012], grad_fn=<AddBackward0>),\n  tensor([-43.0017], grad_fn=<AddBackward0>),\n  tensor([-43.0022], grad_fn=<AddBackward0>),\n  tensor([-43.0027], grad_fn=<AddBackward0>),\n  tensor([-43.0031], grad_fn=<AddBackward0>),\n  tensor([-43.0036], grad_fn=<AddBackward0>),\n  tensor([-43.0040], grad_fn=<AddBackward0>),\n  tensor([-43.0045], grad_fn=<AddBackward0>),\n  tensor([-43.0049], grad_fn=<AddBackward0>),\n  tensor([-43.0053], grad_fn=<AddBackward0>),\n  tensor([-43.0058], grad_fn=<AddBackward0>),\n  tensor([-43.0062], grad_fn=<AddBackward0>),\n  tensor([-43.0066], grad_fn=<AddBackward0>),\n  tensor([-43.0070], grad_fn=<AddBackward0>),\n  tensor([-43.0075], grad_fn=<AddBackward0>),\n  tensor([-43.0079], grad_fn=<AddBackward0>),\n  tensor([-43.0083], grad_fn=<AddBackward0>),\n  tensor([-43.0087], grad_fn=<AddBackward0>),\n  tensor([-43.0090], grad_fn=<AddBackward0>),\n  tensor([-43.0094], grad_fn=<AddBackward0>),\n  tensor([-43.0098], grad_fn=<AddBackward0>),\n  tensor([-43.0102], grad_fn=<AddBackward0>),\n  tensor([-43.0106], grad_fn=<AddBackward0>),\n  tensor([-43.0109], grad_fn=<AddBackward0>),\n  tensor([-43.0104], grad_fn=<AddBackward0>),\n  tensor([-43.0108], grad_fn=<AddBackward0>),\n  tensor([-43.0111], grad_fn=<AddBackward0>),\n  tensor([-43.0115], grad_fn=<AddBackward0>),\n  tensor([-43.0118], grad_fn=<AddBackward0>),\n  tensor([-43.0122], grad_fn=<AddBackward0>),\n  tensor([-43.0125], grad_fn=<AddBackward0>),\n  tensor([-43.0129], grad_fn=<AddBackward0>),\n  tensor([-43.0132], grad_fn=<AddBackward0>),\n  tensor([-43.0136], grad_fn=<AddBackward0>),\n  tensor([-43.0139], grad_fn=<AddBackward0>),\n  tensor([-43.0142], grad_fn=<AddBackward0>),\n  tensor([-43.0146], grad_fn=<AddBackward0>),\n  tensor([-43.0149], grad_fn=<AddBackward0>),\n  tensor([-43.0152], grad_fn=<AddBackward0>),\n  tensor([-43.0155], grad_fn=<AddBackward0>),\n  tensor([-43.0159], grad_fn=<AddBackward0>),\n  tensor([-43.0162], grad_fn=<AddBackward0>),\n  tensor([-43.0165], grad_fn=<AddBackward0>),\n  tensor([-43.0168], grad_fn=<AddBackward0>),\n  tensor([-43.0171], grad_fn=<AddBackward0>),\n  tensor([-43.0174], grad_fn=<AddBackward0>),\n  tensor([-43.0177], grad_fn=<AddBackward0>),\n  tensor([-43.0180], grad_fn=<AddBackward0>),\n  tensor([-43.0183], grad_fn=<AddBackward0>),\n  tensor([-43.0186], grad_fn=<AddBackward0>),\n  tensor([-43.0188], grad_fn=<AddBackward0>),\n  tensor([-43.0191], grad_fn=<AddBackward0>),\n  tensor([-43.0194], grad_fn=<AddBackward0>),\n  tensor([-43.0197], grad_fn=<AddBackward0>),\n  tensor([-43.0200], grad_fn=<AddBackward0>),\n  tensor([-43.0202], grad_fn=<AddBackward0>),\n  tensor([-43.0205], grad_fn=<AddBackward0>),\n  tensor([-43.0208], grad_fn=<AddBackward0>),\n  tensor([-43.0210], grad_fn=<AddBackward0>),\n  tensor([-43.0213], grad_fn=<AddBackward0>),\n  tensor([-43.0215], grad_fn=<AddBackward0>),\n  tensor([-43.0218], grad_fn=<AddBackward0>),\n  tensor([-43.0220], grad_fn=<AddBackward0>),\n  tensor([-43.0223], grad_fn=<AddBackward0>),\n  tensor([-43.0225], grad_fn=<AddBackward0>),\n  tensor([-43.0228], grad_fn=<AddBackward0>),\n  tensor([-43.0230], grad_fn=<AddBackward0>),\n  tensor([-43.0233], grad_fn=<AddBackward0>),\n  tensor([-43.0235], grad_fn=<AddBackward0>),\n  tensor([-43.0237], grad_fn=<AddBackward0>),\n  tensor([-43.0240], grad_fn=<AddBackward0>),\n  tensor([-43.0242], grad_fn=<AddBackward0>),\n  tensor([-43.0244], grad_fn=<AddBackward0>),\n  tensor([-43.0247], grad_fn=<AddBackward0>),\n  tensor([-43.0251], grad_fn=<AddBackward0>),\n  tensor([-43.0254], grad_fn=<AddBackward0>),\n  tensor([-43.0256], grad_fn=<AddBackward0>),\n  tensor([-43.0258], grad_fn=<AddBackward0>),\n  tensor([-43.0260], grad_fn=<AddBackward0>),\n  tensor([-43.0262], grad_fn=<AddBackward0>),\n  tensor([-43.0264], grad_fn=<AddBackward0>),\n  tensor([-43.0266], grad_fn=<AddBackward0>),\n  tensor([-43.0269], grad_fn=<AddBackward0>),\n  tensor([-43.0271], grad_fn=<AddBackward0>),\n  tensor([-43.0273], grad_fn=<AddBackward0>),\n  tensor([-43.0275], grad_fn=<AddBackward0>),\n  tensor([-43.0277], grad_fn=<AddBackward0>),\n  tensor([-43.0279], grad_fn=<AddBackward0>),\n  tensor([-43.0281], grad_fn=<AddBackward0>),\n  tensor([-43.0282], grad_fn=<AddBackward0>),\n  tensor([-43.0284], grad_fn=<AddBackward0>),\n  tensor([-43.0286], grad_fn=<AddBackward0>),\n  tensor([-43.0288], grad_fn=<AddBackward0>),\n  tensor([-43.0290], grad_fn=<AddBackward0>),\n  tensor([-43.0292], grad_fn=<AddBackward0>),\n  tensor([-43.0294], grad_fn=<AddBackward0>),\n  tensor([-43.0296], grad_fn=<AddBackward0>),\n  tensor([-43.0297], grad_fn=<AddBackward0>),\n  tensor([-43.0299], grad_fn=<AddBackward0>),\n  tensor([-43.0301], grad_fn=<AddBackward0>),\n  tensor([-43.0303], grad_fn=<AddBackward0>),\n  tensor([-43.0304], grad_fn=<AddBackward0>),\n  tensor([-43.0306], grad_fn=<AddBackward0>),\n  tensor([-43.0308], grad_fn=<AddBackward0>),\n  tensor([-43.0310], grad_fn=<AddBackward0>),\n  tensor([-43.0311], grad_fn=<AddBackward0>),\n  tensor([-43.0313], grad_fn=<AddBackward0>),\n  tensor([-43.0315], grad_fn=<AddBackward0>),\n  tensor([-43.0316], grad_fn=<AddBackward0>),\n  tensor([-43.0318], grad_fn=<AddBackward0>),\n  tensor([-43.0319], grad_fn=<AddBackward0>),\n  tensor([-43.0321], grad_fn=<AddBackward0>),\n  tensor([-43.0323], grad_fn=<AddBackward0>),\n  tensor([-43.0324], grad_fn=<AddBackward0>),\n  tensor([-43.0326], grad_fn=<AddBackward0>),\n  tensor([-43.0327], grad_fn=<AddBackward0>),\n  tensor([-43.0329], grad_fn=<AddBackward0>),\n  tensor([-43.0330], grad_fn=<AddBackward0>),\n  tensor([-43.0332], grad_fn=<AddBackward0>),\n  tensor([-43.0333], grad_fn=<AddBackward0>),\n  tensor([-43.0335], grad_fn=<AddBackward0>),\n  tensor([-43.0336], grad_fn=<AddBackward0>),\n  tensor([-43.0338], grad_fn=<AddBackward0>),\n  tensor([-43.0339], grad_fn=<AddBackward0>)]]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# losses = pd.read_csv(\"GNNSubNet/datasets/loss_values.csv\")\n",
    "# losses\n",
    "bigL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[[-37.40997314453125,\n  -37.671756744384766,\n  -37.93352127075195,\n  -38.19400405883789,\n  -38.45235061645508,\n  -38.706390380859375,\n  -38.95417785644531,\n  -39.19466018676758,\n  -39.42793273925781,\n  -39.65304183959961,\n  -39.8686637878418,\n  -40.07469177246094,\n  -40.27095031738281,\n  -40.456703186035156,\n  -40.63178634643555,\n  -40.796478271484375,\n  -40.950687408447266,\n  -41.09479522705078,\n  -41.2289924621582,\n  -41.35360336303711,\n  -41.468902587890625,\n  -41.57554626464844,\n  -41.67399978637695,\n  -41.764801025390625,\n  -41.84843444824219,\n  -41.9254035949707,\n  -41.99618148803711,\n  -42.06121826171875,\n  -42.12098693847656,\n  -42.17593002319336,\n  -42.22645568847656,\n  -42.272857666015625,\n  -42.31553649902344,\n  -42.354827880859375,\n  -42.39104461669922,\n  -42.42445755004883,\n  -42.45530700683594,\n  -42.48381805419922,\n  -42.51020812988281,\n  -42.534629821777344,\n  -42.55727767944336,\n  -42.57830047607422,\n  -42.59782791137695,\n  -42.61601638793945,\n  -42.632957458496094,\n  -42.648780822753906,\n  -42.663570404052734,\n  -42.677406311035156,\n  -42.69037628173828,\n  -42.702545166015625,\n  -42.71370315551758,\n  -42.7244758605957,\n  -42.73462677001953,\n  -42.74420928955078,\n  -42.75324630737305,\n  -42.76180648803711,\n  -42.7699089050293,\n  -42.777587890625,\n  -42.78488540649414,\n  -42.79182052612305,\n  -42.79841995239258,\n  -42.80470275878906,\n  -42.810699462890625,\n  -42.816429138183594,\n  -42.8218879699707,\n  -42.82712936401367,\n  -42.8321418762207,\n  -42.83694839477539,\n  -42.841556549072266,\n  -42.84598159790039,\n  -42.85024642944336,\n  -42.854347229003906,\n  -42.8582878112793,\n  -42.862083435058594,\n  -42.86574935913086,\n  -42.86929702758789,\n  -42.87271499633789,\n  -42.87602233886719,\n  -42.87921905517578,\n  -42.8823127746582,\n  -42.88529968261719,\n  -42.88821792602539,\n  -42.891021728515625,\n  -42.89375686645508,\n  -42.89640808105469,\n  -42.89898681640625,\n  -42.901493072509766,\n  -42.903926849365234,\n  -42.90629577636719,\n  -42.90860366821289,\n  -42.91084289550781,\n  -42.91303253173828,\n  -42.915157318115234,\n  -42.91722869873047,\n  -42.91926193237305,\n  -42.921226501464844,\n  -42.92316436767578,\n  -42.92504119873047,\n  -42.926883697509766,\n  -42.92866897583008,\n  -42.929954528808594,\n  -42.931678771972656,\n  -42.93336486816406,\n  -42.935001373291016,\n  -42.936622619628906,\n  -42.93819808959961,\n  -42.93973922729492,\n  -42.94124984741211,\n  -42.942726135253906,\n  -42.94417953491211,\n  -42.94559097290039,\n  -42.94698715209961,\n  -42.94834899902344,\n  -42.94968795776367,\n  -42.95100402832031,\n  -42.95228576660156,\n  -42.95354461669922,\n  -42.95478057861328,\n  -42.955997467041016,\n  -42.957191467285156,\n  -42.95835876464844,\n  -42.959503173828125,\n  -42.960628509521484,\n  -42.96173095703125,\n  -42.96281433105469,\n  -42.96389389038086,\n  -42.96493911743164,\n  -42.965965270996094,\n  -42.966976165771484,\n  -42.96796798706055,\n  -42.968955993652344,\n  -42.969913482666016,\n  -42.97085952758789,\n  -42.97178649902344,\n  -42.97270584106445,\n  -42.973602294921875,\n  -42.9744873046875,\n  -42.97535705566406,\n  -42.9762077331543,\n  -42.977046966552734,\n  -42.97787857055664,\n  -42.97869873046875,\n  -42.97949981689453,\n  -42.980289459228516,\n  -42.9810676574707,\n  -42.981834411621094,\n  -42.98258590698242,\n  -42.98332595825195,\n  -42.98405075073242,\n  -42.984779357910156,\n  -42.98612594604492,\n  -42.986820220947266,\n  -42.98750686645508,\n  -42.98817443847656,\n  -42.98883819580078,\n  -42.98948669433594,\n  -42.99012756347656,\n  -42.990760803222656,\n  -42.99138259887695,\n  -42.99199676513672,\n  -42.99259948730469,\n  -42.993202209472656,\n  -42.9937858581543,\n  -42.99436950683594,\n  -42.99494171142578,\n  -42.995506286621094,\n  -42.996063232421875,\n  -42.99660873413086,\n  -42.997154235839844,\n  -42.9976806640625,\n  -42.99821090698242,\n  -42.99873733520508,\n  -42.999244689941406,\n  -42.99974822998047,\n  -43.0002555847168,\n  -43.00074768066406,\n  -43.0012321472168,\n  -43.0017204284668,\n  -43.00218963623047,\n  -43.002662658691406,\n  -43.00312042236328,\n  -43.00358200073242,\n  -43.004032135009766,\n  -43.004478454589844,\n  -43.00491714477539,\n  -43.005348205566406,\n  -43.00578308105469,\n  -43.00621032714844,\n  -43.006629943847656,\n  -43.00704574584961,\n  -43.007450103759766,\n  -43.00786209106445,\n  -43.00825881958008,\n  -43.0086555480957,\n  -43.00904083251953,\n  -43.00943374633789,\n  -43.00981521606445,\n  -43.01019287109375,\n  -43.010562896728516,\n  -43.010929107666016,\n  -43.01039505004883,\n  -43.01076126098633,\n  -43.0111198425293,\n  -43.0114860534668,\n  -43.011837005615234,\n  -43.0121955871582,\n  -43.012542724609375,\n  -43.01289367675781,\n  -43.01323318481445,\n  -43.01357650756836,\n  -43.01390838623047,\n  -43.01424026489258,\n  -43.01457595825195,\n  -43.01490020751953,\n  -43.015220642089844,\n  -43.01553726196289,\n  -43.01585388183594,\n  -43.01617431640625,\n  -43.016475677490234,\n  -43.016780853271484,\n  -43.017086029052734,\n  -43.01738739013672,\n  -43.01768112182617,\n  -43.017974853515625,\n  -43.01826858520508,\n  -43.018550872802734,\n  -43.018836975097656,\n  -43.01911926269531,\n  -43.0193977355957,\n  -43.01968002319336,\n  -43.01995086669922,\n  -43.020225524902344,\n  -43.02048873901367,\n  -43.020755767822266,\n  -43.021018981933594,\n  -43.02127456665039,\n  -43.021541595458984,\n  -43.02178955078125,\n  -43.02204513549805,\n  -43.02229309082031,\n  -43.022544860839844,\n  -43.02278137207031,\n  -43.02302551269531,\n  -43.02326965332031,\n  -43.02351379394531,\n  -43.023738861083984,\n  -43.02397918701172,\n  -43.024208068847656,\n  -43.024436950683594,\n  -43.02466583251953,\n  -43.025146484375,\n  -43.025367736816406,\n  -43.02558898925781,\n  -43.02580261230469,\n  -43.02601623535156,\n  -43.0262336730957,\n  -43.02644348144531,\n  -43.026641845703125,\n  -43.026851654052734,\n  -43.02705383300781,\n  -43.027259826660156,\n  -43.027462005615234,\n  -43.02766036987305,\n  -43.027862548828125,\n  -43.02805709838867,\n  -43.02824783325195,\n  -43.02843475341797,\n  -43.02862548828125,\n  -43.02881622314453,\n  -43.02899932861328,\n  -43.02919006347656,\n  -43.02937316894531,\n  -43.02955627441406,\n  -43.02973175048828,\n  -43.02991485595703,\n  -43.03009033203125,\n  -43.03026580810547,\n  -43.03044128417969,\n  -43.030609130859375,\n  -43.03078842163086,\n  -43.03095626831055,\n  -43.031124114990234,\n  -43.031288146972656,\n  -43.03145217895508,\n  -43.031620025634766,\n  -43.03178405761719,\n  -43.031944274902344,\n  -43.032100677490234,\n  -43.03226089477539,\n  -43.03242111206055,\n  -43.03257751464844,\n  -43.03273391723633,\n  -43.032894134521484,\n  -43.03303527832031,\n  -43.03319549560547,\n  -43.03334426879883,\n  -43.03348922729492,\n  -43.033634185791016,\n  -43.033782958984375,\n  -43.033935546875]]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lossss = [[tensor.item() for tensor in sublist] for sublist in bigL]\n",
    "\n",
    "# for listt in bigL:\n",
    "#     #print(listt)\n",
    "#     losses\n",
    "#     for tensor in listt:\n",
    "#         lossss.append(tensor.detach().item())\n",
    "\n",
    "lossss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x16c916790d0>]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGdCAYAAAA8F1jjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0eUlEQVR4nO3de3xU9Z3/8feZa+4JISEXcoGg4iogChVDW7cKK3hpcbXbqmwV14UHLa7d1qrQ/amt62+ptututbdfu79Vfpa1olitbrG4ItFWpIggioKAQMCQBBLIhIRMkpnv74/JTIi5h5k5k+T1fDzOY2bOOXPmM6dD8/b7/Z7vsYwxRgAAAAnIYXcBAAAAvSGoAACAhEVQAQAACYugAgAAEhZBBQAAJCyCCgAASFgEFQAAkLAIKgAAIGG57C7gTAWDQVVVVSk9PV2WZdldDgAAGABjjBobG1VYWCiHo/d2k2EfVKqqqlRcXGx3GQAAYAgOHTqkoqKiXrcP+6CSnp4uKfRFMzIybK4GAAAMhM/nU3FxceTveG+GfVAJd/dkZGQQVAAAGGb6G7bBYFoAAJCwCCoAACBhEVQAAEDCIqgAAICERVABAAAJi6ACAAASFkEFAAAkLIIKAABIWAQVAACQsAgqAAAgYRFUAABAwiKoAACAhDXsb0oYK69+WKM39hxT+aSxmnd+vt3lAAAwKtGi0ostB47riTcPaNO+OrtLAQBg1CKo9GJculeSdLTRb3MlAACMXgSVXozLCAWV2sYWmysBAGD0Iqj0Ylx6kiSplhYVAABsQ1DpRbjrp9bnlzHG5moAABidCCq9yO0IKqfaAmpqDdhcDQAAoxNBpRepXpdSPU5JUq2PcSoAANiBoNKHcRmMUwEAwE4ElT6Eu38IKgAA2IOg0ofOAbV0/QAAYAeCSh/Clygz6RsAAPYgqPShc9I3ggoAAHYgqPQh0vXD7LQAANiCoNKHyOy0PlpUAACwA0GlD3T9AABgL4JKH8JdPw2n2tTSxuy0AADEG0GlD5nJbnlcoVPElT8AAMQfQaUPlmUpN43uHwAA7EJQ6Ud4nAotKgAAxB9BpR/hcSpHuUQZAIC4I6j0I3KJMi0qAADEHUGlH5EbEzKXCgAAcUdQ6Qez0wIAYB+CSj+Y9A0AAPsQVPrBGBUAAOxDUOlHuOun7qRfgaCxuRoAAEYXgko/xqZ55bCkoAmFFQAAED8ElX44HZbGMjstAAC2IKgMAFf+AABgD4LKAIxjLhUAAGxBUBkArvwBAMAeBJUB4MaEAADYI2ZB5Utf+pJKSkqUlJSkgoICfe1rX1NVVVWXff7whz/okksuUXp6unJzc3X99dfrwIEDsSppyBijAgCAPWIWVC677DKtWbNGu3fv1tq1a7Vv3z59+ctfjmzfv3+/FixYoMsvv1zbt2/XH/7wBx07dkzXXXddrEoasly6fgAAsIUrVgf+1re+FXleWlqq5cuX69prr1VbW5vcbre2bt2qQCCgBx98UA5HKC995zvf0YIFCyL7JIrINPoMpgUAIK7iMkalvr5eq1ev1uzZsyMBZMaMGXI4HHr88ccVCATU0NCgJ598UnPnzu0zpPj9fvl8vi5LrIW7fo42+mUMs9MCABAvMQ0q99xzj1JTUzV27FhVVlbqhRdeiGybOHGi1q9fr+9+97vyer3KysrS4cOHtWbNmj6PuXLlSmVmZkaW4uLiWH4FSVJOx4RvrYGgGk61xfzzAABAyKCCyvLly2VZVp/Lrl27Ivvfdddd2rZtm9avXy+n06mbb7450iJRXV2txYsX65ZbbtGWLVtUUVEhj8ejL3/5y322WqxYsUINDQ2R5dChQ0P86gOX5HYqMznUysM4FQAA4scyg+jLOHr0qOrq6vrcp6ysTB6Pp9v6w4cPq7i4WG+++abKy8t177336uWXX9aWLVu67bNp0yZdcsklA6rJ5/MpMzNTDQ0NysjIGOhXGbS/eqRCe2pP6te3zdLnzs6J2ecAADAaDPTv96AG0+bm5io3N3dIBQWDQUmhMSaS1NzcHBlEG+Z0Orvsm0jGZXi1p/YklygDABBHMRmjsnnzZv3kJz/R9u3bdfDgQW3YsEE33nijJk2apPLycknS1VdfrS1btuiBBx7Qnj179M477+jWW29VaWmpLrzwwliUdUaYnRYAgPiLSVBJSUnRc889pzlz5mjy5Mm67bbbNG3aNFVUVMjrDQ1Mvfzyy/Vf//Vfev7553XhhRdq/vz58nq9evnll5WcnByLss4I9/sBACD+YjKPytSpU7Vhw4Z+97vhhht0ww03xKKEqMtldloAAOKOe/0M0LiMUNcP9/sBACB+CCoDdPqkbwAAID4IKgPUeWNCggoAAPFCUBmgcNfPSX+7mlvbba4GAIDRgaAyQGlel1I8oXleuPIHAID4IKgMAt0/AADEF0FlEDonfeMSZQAA4oGgMgi5GUz6BgBAPBFUBiE3ja4fAADiiaAyCOMymJ0WAIB4IqgMQniMCpO+AQAQHwSVQeDGhAAAxBdBZRDo+gEAIL4IKoMQ7vo53tym1vagzdUAADDyEVQGYUyKW26nJUk6dpLuHwAAYo2gMgiWZXGJMgAAcURQGaTcjpsT1voYpwIAQKwRVAaJ+/0AABA/BJVBIqgAABA/BJVB6pz0ja4fAABijaAySOO4MSEAAHFDUBkkun4AAIgfgsoghbt+mJ0WAIDYI6gMUm5Hi8qxk60KBI3N1QAAMLIRVAYpJ80jy5ICQaP6pla7ywEAYEQjqAySy+nQ2FSPJOko41QAAIgpgsoQ5DJOBQCAuCCoDAFX/gAAEB8ElSEIBxW6fgAAiC2CyhB0TvpG1w8AALFEUBmCzrlUaFEBACCWCCpDwBgVAADig6AyBJGuH676AQAgpggqQxDp+vH5ZQyz0wIAECsElSEIT6Pvbw/K19JuczUAAIxcBJUhSHI7lZnslsSVPwAAxBJBZYjyOsap1PgYUAsAQKwQVIYoLyM0TqWGFhUAAGKGoDJE4aBSTVABACBmCCpDlMfstAAAxBxBZYjyaVEBACDmCCpDNC4yRoXBtAAAxApBZYjyGUwLAEDMEVSGKDyYtrbRr2CQ2WkBAIgFgsoQ5aR55LCkQNDoWBPdPwAAxAJBZYhcTody0sJX/hBUAACIBYLKGcjP7Ljyp4FxKgAAxAJB5QyE76Jc00hQAQAgFmIWVL70pS+ppKRESUlJKigo0Ne+9jVVVVV12WfNmjWaPn26UlJSVFpaqh/+8IexKicm8jM77vdDiwoAADERs6By2WWXac2aNdq9e7fWrl2rffv26ctf/nJk+7p167Rw4UItXbpU77//vn72s5/p3/7t3/STn/wkViVFXV46c6kAABBLljEmLtfW/u53v9O1114rv98vt9utm266SW1tbXrmmWci+zz22GN6+OGHVVlZKcuyBnRcn8+nzMxMNTQ0KCMjI1bl92jNlkO6e+0O/eU5uVr1dxfH9bMBABjOBvr32xWPYurr67V69WrNnj1bbrdbkuT3+5WSktJlv+TkZB0+fFgHDx7UhAkTejyW3++X39/ZguHz+WJWd3/yMpn0DQCAWIrpYNp77rlHqampGjt2rCorK/XCCy9Ets2bN0/PPfecXn31VQWDQX300Uf613/9V0nSkSNHej3mypUrlZmZGVmKi4tj+RX6FL4xIUEFAIDYGFRQWb58uSzL6nPZtWtXZP+77rpL27Zt0/r16+V0OnXzzTcr3NO0ePFi3X777brmmmvk8Xh0ySWX6IYbbggV5ei9rBUrVqihoSGyHDp0aCjfOyrC0+gfb26Tvz1gWx0AAIxUgxqjcvToUdXV1fW5T1lZmTweT7f1hw8fVnFxsd58802Vl5dH1gcCAVVXVys3N1evvvqqrrrqKtXW1io3N3dANdk5RsUYo8n3vqzW9qDeuPsyFWen9P8mAAAQmzEqubm5Aw4QnxYMBiWpy/gSSXI6nRo/frwk6amnnlJ5efmQPyPeLMtSfkaSKuubVeNrIagAABBlMRlMu3nzZm3ZskWf+9znNGbMGO3bt0/33nuvJk2aFGlNOXbsmJ599ll94QtfUEtLix5//HE988wzqqioiEVJMZOX4e0IKlyiDABAtMVkMG1KSoqee+45zZkzR5MnT9Ztt92madOmqaKiQl6vN7LfqlWrNHPmTH32s5/Vzp07tXHjRl188fC6zDd8F+VqBtQCABB1MWlRmTp1qjZs2NDnPjk5Odq0aVMsPj6uwkGllqACAEDUca+fM5RPiwoAADFDUDlD45hLBQCAmCGonKFw1w+DaQEAiD6CyhnKz+icRj9Ot00CAGDUIKicoXCLSnNrQI3+dpurAQBgZCGonKFkj1MZSaGLp2oaGKcCAEA0EVSioDArWZJ0hKACAEBUEVSiID+z4xJlggoAAFFFUImCgo6gUtVwyuZKAAAYWQgqUZCfEer6oUUFAIDoIqhEQbhFhTEqAABEF0ElCgqyGKMCAEAsEFSioLNFhTEqAABEE0ElCvIzQ2NUfC3tamLSNwAAooagEgVpXpfSvaFJ3xinAgBA9BBUooS5VAAAiD6CSpTkM04FAICoI6hESWEmc6kAABBtBJUoibSo+AgqAABEC0ElSiKXKJ+g6wcAgGghqERJPrPTAgAQdQSVKCkIj1Gh6wcAgKghqERJeBr9E81tOtUasLkaAABGBoJKlKR7XUr1OCXRqgIAQLQQVKLEsqzOcSoMqAUAICoIKlEUHqfCgFoAAKKDoBJFkWn06foBACAqCCpRVMg0+gAARBVBJYrymUYfAICoIqhEUXh22qoTBBUAAKKBoBJFjFEBACC6CCpRFG5RqW9qVUsbk74BAHCmCCpRlJnsVrK7Y9I3xqkAAHDGCCpRZFmWCrPC41S48gcAgDNFUImywqzQlT+HCSoAAJwxgkqUFY0JBZVPjhNUAAA4UwSVKBvf0aJC1w8AAGeOoBJl4a6fTwgqAACcMYJKlI0nqAAAEDUElSgb3zFG5ciJFgWDxuZqAAAY3ggqUZaXkSSHJbUGgjp20m93OQAADGsElShzOx3KzwjNpcIlygAAnBmCSgyEu3+48gcAgDNDUImByJU/zKUCAMAZIajEAFf+AAAQHQSVGKDrBwCA6CCoxEDkfj90/QAAcEYIKjFQRNcPAABRQVCJgXCLSmNLu3wtbTZXAwDA8BWXoOL3+zV9+nRZlqXt27d32bZjxw59/vOfV1JSkoqLi/Xwww/Ho6SYSvW6lJXilsQ4FQAAzkRcgsrdd9+twsLCbut9Pp+uuOIKlZaWauvWrfrhD3+o733ve/rlL38Zj7JiajyXKAMAcMZiHlTWrVun9evX60c/+lG3batXr1Zra6v+8z//U+eff75uuOEG3XHHHXrkkUdiXVbMhYMKLSoAAAxdTINKTU2NFi9erCeffFIpKSndtm/atEmXXnqpPB5PZN28efO0e/duHT9+vMdj+v1++Xy+Lksiilz5Q1ABAGDIYhZUjDFatGiRli5dqpkzZ/a4T3V1tfLy8rqsC7+urq7u8T0rV65UZmZmZCkuLo5u4VFSNIauHwAAztSgg8ry5ctlWVafy65du/TYY4+psbFRK1asiGrBK1asUENDQ2Q5dOhQVI8fLXT9AABw5lyDfcOdd96pRYsW9blPWVmZNmzYoE2bNsnr9XbZNnPmTC1cuFCrVq1Sfn6+ampqumwPv87Pz+/x2F6vt9sxE1Ehc6kAAHDGBh1UcnNzlZub2+9+jz76qB588MHI66qqKs2bN09PP/20Zs2aJUkqLy/XP/3TP6mtrU1ud+hy3ldeeUWTJ0/WmDFjBltaQglPo1/b6Fdre1AeF1PWAAAwWDH761lSUqIpU6ZElnPOOUeSNGnSJBUVFUmSbrrpJnk8Ht12223auXOnnn76af34xz/Wt7/97ViVFTdjUz1KcjtkjHSkgVYVAACGwtb/zM/MzNT69eu1f/9+zZgxQ3feeafuu+8+LVmyxM6yosKyLBWNCV3pdKieoAIAwFAMuutnqCZMmCBjTLf106ZN0xtvvBGvMuKqJDtFe2tP6tDxZrtLAQBgWGLgRAwVd4xTqawnqAAAMBQElRgqzg51/RBUAAAYGoJKDJVkh8eoEFQAABgKgkoMlYylRQUAgDNBUImh4o6rfk40t8nX0mZzNQAADD8ElRhK9bo0NjV0w0W6fwAAGDyCSowVM04FAIAhI6jEWAlX/gAAMGQElRgjqAAAMHQElRjrDCpMow8AwGARVGKsKDs0O+1hWlQAABg0gkqMhVtUDh8/pUCw+72OAABA7wgqMVaQmSyXw1JrIKgaX4vd5QAAMKwQVGLM6bBUxM0JAQAYEoJKHHBzQgAAhoagEgfhoMKAWgAABoegEgfMpQIAwNAQVOKAoAIAwNAQVOKASd8AABgagkochMeoHDvpV3Nru83VAAAwfBBU4iAz2a3MZLckun8AABgMgkqcTMhJlSQdONZkcyUAAAwfBJU4KesIKh8TVAAAGDCCSpxM7Agq+48SVAAAGCiCSpxEggotKgAADBhBJU4IKgAADB5BJU7CQaWuqVUNzW02VwMAwPBAUImTVK9LeRleSdL+OlpVAAAYCIJKHHV2/5y0uRIAAIYHgkocTcxJk8SVPwAADBRBJY7Cc6nsY0AtAAADQlCJI+ZSAQBgcAgqcTQxt/MSZWOMzdUAAJD4CCpxVDwmRU6HpVNtAdX4/HaXAwBAwiOoxJHH5VBJdook6WOu/AEAoF8ElThjhloAAAaOoBJnDKgFAGDgCCpxRosKAAADR1CJszKCCgAAA0ZQibPwJcqV9c1qCwRtrgYAgMRGUImzvPQkJbudag8aHapvtrscAAASGkElzhwOS2UdrSp7arlEGQCAvhBUbDA5L12StKem0eZKAABIbAQVG5zdEVR219CiAgBAXwgqNjgnL00SLSoAAPSHoGKDczpaVD4+2sSVPwAA9IGgYoPxWclK8TjVGgjqYB3zqQAA0BuCig0cDktnjwt1/3zEOBUAAHpFULFJuPvnI8apAADQq5gHFb/fr+nTp8uyLG3fvj2yvqWlRYsWLdLUqVPlcrl07bXXxrqUhEJQAQCgfzEPKnfffbcKCwu7rQ8EAkpOTtYdd9yhuXPnxrqMhHN2Hl0/AAD0xxXLg69bt07r16/X2rVrtW7dui7bUlNT9fOf/1yS9Kc//UknTpyIZSkJJ9yicuBYk/ztAXldTpsrAgAg8cQsqNTU1Gjx4sV6/vnnlZKSErXj+v1++f3+yGufzxe1Y8dTQWaS0r0uNfrbtf9Yk87Nz7C7JAAAEk5Mun6MMVq0aJGWLl2qmTNnRvXYK1euVGZmZmQpLi6O6vHjxbIsun8AAOjHoILK8uXLZVlWn8uuXbv02GOPqbGxUStWrIh6wStWrFBDQ0NkOXToUNQ/I17O4Z4/AAD0aVBdP3feeacWLVrU5z5lZWXasGGDNm3aJK/X22XbzJkztXDhQq1atWrQhYZ5vd5uxx2uwkFldzVBBQCAngwqqOTm5io3N7ff/R599FE9+OCDkddVVVWaN2+enn76ac2aNWvwVY5QkRaVWrp+AADoSUwG05aUlHR5nZYWGosxadIkFRUVRdZ/8MEHam1tVX19vRobGyPzrEyfPj0WZSWc8M0JD9Y1qaUtoCQ3V/4AAHC6mF6e3J+rrrpKBw8ejLy+8MILJYUG444GueleZaW4daK5TXtrT2rK+Ey7SwIAIKHEZQr9CRMmyBjTraXkwIEDMsZ0W0YLy7J0XkHosuSdVQ02VwMAQOLhXj82C7eivP/J8JwPBgCAWCKo2Oz8wlCLyvu0qAAA0A1BxWbhFpUPj/gUCI6ebi8AAAaCoGKziWNTlepxqqUtqI+PcpkyAACnI6jYzOGwdB7dPwAA9IigkgDOL2RALQAAPSGoJIDOK39oUQEA4HQElQQwZXyo6+eDKp+CDKgFACCCoJIAzspNk9flUKO/XZX1zXaXAwBAwiCoJACX06FzCxhQCwDApxFUEsSU8JU/DKgFACCCoJIgwgNquecPAACdCCoJIjKV/icNo+rGjAAA9IWgkiDOyUuXy2HpeHObPjlxyu5yAABICASVBJHkdmpyfrok6d1DdP8AACARVBLKjNIxkqStB4/bXAkAAImBoJJAOoNKvc2VAACQGAgqCSQcVHZW+XSqNWBzNQAA2I+gkkDGZyUrL8Or9qDRjsMn7C4HAADbEVQSiGVZnd0/lYxTAQCAoJJgLioJBZV3GFALAABBJdHMnJAtKXTlDxO/AQBGO4JKgjmvIENel0PHm9v08bEmu8sBAMBWBJUE43E5dEFRliTmUwEAgKCSgC4qZZwKAAASQSUhMUMtAAAhBJUEFA4qe2pP6kRzq83VAABgH4JKAspO9agsJ1WStOUArSoAgNGLoJKgLpk0VpK0aV+dzZUAAGAfgkqCKi/rCCofE1QAAKMXQSVBXdIRVD484lN9E+NUAACjE0ElQeWme3VOXpok6S1aVQAAoxRBJYHNnpQjSXpz3zGbKwEAwB4ElQRW3jGg9k97aVEBAIxOBJUEVj5prJwOS/uPNelQfbPd5QAAEHcElQSWkeTWjJLQ5G8VHx21uRoAAOKPoJLgLj0nNE6FoAIAGI0IKgnu0nNyJYUmfmsLBG2uBgCA+CKoJLgphZnKTvXopL+dmxQCAEYdgkqCczgsfaGjVeXVD2tsrgYAgPgiqAwDc/4iT5L06oe1NlcCAEB8EVSGgUvPyZHbaenjY036+OhJu8sBACBuCCrDQHqSO3LvH1pVAACjCUFlmJhz7jhJ0isfME4FADB6EFSGib86P1+StOVgvWobW2yuBgCA+CCoDBPjs5I1vThLxkh/2EmrCgBgdCCoDCNXTQ21qqx774jNlQAAEB8ElWHkyikFkqS3Pq7TsZN+m6sBACD2CCrDSHF2iqYVZSpoaFUBAIwOcQkqfr9f06dPl2VZ2r59e2T9xo0btWDBAhUUFCg1NVXTp0/X6tWr41HSsPWlCwolSc9vr7K5EgAAYi8uQeXuu+9WYWFht/Vvvvmmpk2bprVr12rHjh269dZbdfPNN+ull16KR1nD0hcvKJTDkrYePK7Kuma7ywEAIKZiHlTWrVun9evX60c/+lG3bd/97nf1z//8z5o9e7YmTZqkb37zm5o/f76ee+65WJc1bOVlJGn2pBxJ0gvbP7G5GgAAYiumQaWmpkaLFy/Wk08+qZSUlAG9p6GhQdnZ2b1u9/v98vl8XZbRZsH0UOvUc9s+kTHG5moAAIidmAUVY4wWLVqkpUuXaubMmQN6z5o1a7Rlyxbdeuutve6zcuVKZWZmRpbi4uJolTxsXDW1QKkep/Yfa9KWA8ftLgcAgJgZdFBZvny5LMvqc9m1a5cee+wxNTY2asWKFQM67muvvaZbb71Vv/rVr3T++ef3ut+KFSvU0NAQWQ4dOjTYrzDspXpdumZaqFXlN1sqba4GAIDYscwg+w6OHj2qurq6PvcpKyvTV77yFb344ouyLCuyPhAIyOl0auHChVq1alVkfUVFha6++mo98sgjWrJkyaC+gM/nU2ZmphoaGpSRkTGo9w5n71Qe13U/e1NJbof+/E9zlZHktrskAAAGbKB/vwcdVAaqsrKyy/iRqqoqzZs3T88++6xmzZqloqIiSaFLlK+55ho99NBDWrZs2aA/Z7QGFWOM5v376/qo5qS+/6XzdcvsCXaXBADAgA3077crVgWUlJR0eZ2WliZJmjRpUiSkvPbaa7rmmmv0zW9+U9dff72qq6slSR6Pp88BtZAsy9LfXlKq+17YqVWbDujm8tIurVcAAIwEts5Mu2rVKjU3N2vlypUqKCiILNddd52dZQ0b111UpDSvSx8fbdKf9vbdHQcAwHAUt6AyYcIEGWM0ffr0yLonnnhCxphuy8aNG+NV1rCW5nXp+ovGS5Ie/9N+m6sBACD6uNfPMHfL7AmyLOnVXbXaVT365pQBAIxsBJVhriw3TVd13FX5Z6/ts7kaAACii6AyAnz9C5MkSS/tqNKBY002VwMAQPQQVEaAKeMzddnkXAWN9IsKWlUAACMHQWWEWHbZWZKkte8c1pGGUzZXAwBAdBBURoiZE7I1a2K22gJG/6fiY7vLAQAgKggqI8jtl4daVf5rc6Uq65ptrgYAgDNHUBlBPndWjj5/do5aA0GtXPeh3eUAAHDGCCojiGVZ+l9XnyeHJa17v1qbP2a2WgDA8EZQGWEm56frhotD91n65//+QMFgTO45CQBAXBBURqBv/9U5Sve69P4nPq1957Dd5QAAMGQElREoJ82rZR0Da3+wbpfqTvptrggAgKEhqIxQt352gibnpauuqVX3/W6n3eUAADAkBJURyuty6kd/c4GcDkv/veOIfv/eEbtLAgBg0AgqI9jUokx9o+M+QPc+/z5dQACAYYegMsL9w+Vn69z8UBfQiufekzFcBQQAGD4IKiOcx+XQj/7mArmdltZ/UKNfvs70+gCA4YOgMgpMGZ+p+754viTpoZd36c29x2yuCACAgSGojBJ/O6tE119UpKCR/uGpbao6wR2WAQCJj6AySliWpf/911N0fmGG6ppateTJt3XS3253WQAA9ImgMookuZ36xd/OUHaqR+9/4tOS//e2WtoCdpcFAECvCCqjTHF2ilbderFSPU69ua9O//ib7QpwPyAAQIIiqIxCU4sy9atbZsrjdOjlndW6Z+0OwgoAICERVEap2ZNy9OiN0+WwpGe3HtYdT22Tv51uIABAYiGojGLzpxTopzddJLfT0n+/d0R/v+ptNbcywBYAkDgIKqPclVML9H9v+YyS3U69seeYbvzVZlU3tNhdFgAAkggqkHTpObn69d/PUmayW+8eOqEv/uSP2nqw3u6yAAAgqCBkRukY/e72z2pyXrqONvp1wy/f0pNvHeTeQAAAWxFUEFE6NlXPfWO2rpySr7aA0b3Pv6/bVr2t2ka6ggAA9iCooItUr0s/W3iR/tfVfyGP06ENu2o1/9/f0O/fO0LrCgAg7ggq6MayLP3958v04j98Tn9RkKH6plZ9Y/U7uvWJLTpY12R3eQCAUYSggl5Nzk/X88tm6x8uP0sep0Mbdx/VX/3b6/rX9bvV2NJmd3kAgFHAMsO8Pd/n8ykzM1MNDQ3KyMiwu5wR6+OjJ3X/73bqjT3HJEljUtxadtlZ+ttLSpXkdtpcHQBguBno32+CCgbMGKM/7KzWw3/YrY+PhrqAxqV7ddvnJurGWSXKSHLbXCEAYLggqCBm2gNBrX3nsP79f/boSMfkcOlel264uFg3Xlyistw0mysEACQ6ggpirrU9qBe2f6Jfvv6x9tSejKyfPWmsbry4RPPOz5fHxTAoAEB3BBXETTBotPGjWq1+q1Kv7a5V+EbMY1M9unpaga6ZVqiZpWPkcFj2FgoASBgEFdjikxOn9PSfK/X024dU4/NH1udnJOmqqQW6amq+LiwZIyehBQBGNYIKbNUeCOqNvcf00rtHtH5ntRr9nXdlzkpx69Kzc3XZubm69OxcjU3z2lgpAMAOBBUkDH97QK9/dEwv7ajSxt1H1XCqcw4Wy5Im56XrkrKxunhitj4zIVu56QQXABjpCCpISO2BoLYfOqHXdtfqtV1H9cERX7d9ynJTNWtitqYXZ2nq+CydnZcmt5NBuQAwkhBUMCwcbfRry4F6bf64Tpv312tXdWO3fbwuh84rzNC08ZmaWpSlc/PTdda4NCaaA4BhjKCCYelEc6u2HDiutw/Ua8fhBr3/SUOX8S1hDksqyU7R2XnpmpyXrrPz0nROXrrKclPldRFgACDREVQwIgSDRgfqmvTeJw3acbhB733SoI9qGnWiued7DVmWVJiZrNKxKSodm6KS7FRNGJuikrEpKh2bqjSvK87fAADQE4IKRixjjI6e9GtPzUl9VNPYsYSeN7Z0b305XU6aR8XZKSrMTFZBZpIKspJVGH7MSlJOqpf5XgAgDgb695v/vMSwY1mWxqUnaVx6kj57Vk5kvTFGx062qrK+SQeONetgfbMO1jXpYF3o8Xhzm46dbNWxk63aphM9HtvttJSfmaSCjGTlpns7lzRvl9djUz1yMcAXAGKOoIIRw7KsSJCYUZrdbbuvpU2Vdc06VN+sqoYWHTlxSkcaWlTVcEpHTrSotrFFbQGjQ/WndKj+VD+fJWWneEKhJc2jrBSPslM8GpPqUXaKO/SY6tGYyDqPkj2MnQGAwSKoYNTISHJryvhMTRmf2eP2tkBQtY1+HTlxStW+Fh1t9HcuJzufHzvpV9BIdU2tqmtqHfDnJ7kdyk7xKCPZrYxktzKT3cpIcisj2dXx6FZGkkuZyW6lJ7mVnuRSmteltI5Hr8shy6JbCsDoEpeg4vf7NWvWLL377rvatm2bpk+fLknavXu3li5dqg8++EANDQ0qLCzUTTfdpPvvv19utzsepQERbqdD47OSNT4ruc/9AkGj+qbWSIA53tSq+qZWHW8OPZ5obuvy+nhzq9oCRi1tQVU1tKiq447Tg6/PigSXdK+747EzyERee11KS3IrxePsWFxdnid3PGduGgDDQVyCyt13363CwkK9++67Xda73W7dfPPNuuiii5SVlaV3331XixcvVjAY1L/8y7/EozRg0JyOzi6mgTDGqKk1EAk0Dafa5Gtpk+9Ue8dj5+vwtpMt7WpsaddJf2iRpLaA0fHmNh1vbpPUd9fUQHicjkhoSfY4lXpaiDn9ebLHqRS3S163Q0kuh5Lczo7FIa/bqSSXs2NbaF2X7S4n93UCcEZiHlTWrVun9evXa+3atVq3bl2XbWVlZSorK4u8Li0t1caNG/XGG2/EuiwgbiyroyXE61Jxdsqg3x8MGjW1doSWlnb5Wjqfn/S3dQaa08JNo79dp1rb1eQP6FRbQM2t7WpuDai5NaBAx+2tWwNBtZ4KdrmlQSy4nVZHmDk9yIRCTPjR7bTkcTnlcTrkcTnkdYUew68//dzb7zZn57aO7W6nRdcZMAzFNKjU1NRo8eLFev7555WS0v//Qe/du1cvv/yyrrvuul738fv98vs778rr83Wfgh0YSRwOq2PMilvqeXjNgBlj1BoI6lRHaDk9wJxqDaip43X4eXi/U20BtbQF5G8LqqUtoJb2juftAbWE17UF5W8LyN8eVGsgGPnMtoBRW6C9x4n74s3jcsh7esBxOeRyWHI5HHI5LbmcDrkdllxOS25naJvTEQo5p2/rfN7xfmfoGOH9XI7Q+50OK7Su4/juT2379DqX05LTsuR0hBaHZUXWORyWXI7Q4+n7hLcBI1XMgooxRosWLdLSpUs1c+ZMHThwoNd9Z8+erXfeeUd+v19LlizRAw880Ou+K1eu1Pe///0YVAyMfJZlyetyyutyKmvwjTsDFgga+buEmFCACQeaUNAJPW9tD8ofCD1GlkDgtOfBUPg57XVPz8MBqe20de3BrtNEhdfL30vhw5RlqUuYcVqWnJ8OOB3hpqewc/r7HA7J5XB07KNIYArv57BC68PHcHR8htMRqsH6VNByOhTa57T14XrD+zjCn3Na8Dr9vZ37hY/R9Zidj+ry3ayO44aP2Vlv5/pIvZYlK3Lc0KPU9bVliVY5Gwx6wrfly5froYce6nOfDz/8UOvXr9eaNWtUUVEhp9OpAwcOaOLEiV0G04YdOnRIjY2Nevfdd3XXXXfpjjvu0N13393jsXtqUSkuLmbCNwDdBIJGbacHnR4CUVvAqD1g1B4MRh7bTn887Xmgh3XtgVAgaguE3995rLZu28LH6dzWHuj8vPaAUcCEtoeXoAkdc3hPzTmyhINLZ3jp+vr0R0dHuHFYkqXTXp8Wtix1P4Z1WkAKv6fXYzrCnxle1/V1OJxZ6noMhxXauWsYC+/TtZ455+bpc2fn9HdqBiVmM9MePXpUdXV1fe5TVlamr3zlK3rxxRe7pM9AICCn06mFCxdq1apVPb7317/+tZYsWaLGxkY5nf3PO8HMtABGA9MRYNo7wsvpYSZgjIJBqT0YVDCojrATVCCoLvv0FICCwe7HDRoTCU3BYOdj0CiyPdDx+vRagia8TV2OFYx8fuf36Dy2OveJHOPTn2NO+16f+pzwsbrUqk/tF1qM+fQxFBmzhb7dPX+yvvGFs6J6zJjNTJubm6vc3Nx+93v00Uf14IMPRl5XVVVp3rx5evrppzVr1qxe3xcMBtXW1qZgMDigoAIAo4FlhcfH2F3JyBMOOKYjNIUfg8bISDLBztdBIxmdvk/o/dJpr42RiRzntGN1O34ouPX0GP7s8LGCwc51p+8Tfk+Xenr4/B6P3+1zFAmkRqfvb3RRyRjb/veJ2RiVkpKSLq/T0tIkSZMmTVJRUZEkafXq1XK73Zo6daq8Xq/efvttrVixQl/96leZRwUAEBcOhyWHGHuSqGydmdblcumhhx7SRx99JGOMSktLdfvtt+tb3/qWnWUBAIAEwd2TAQBA3A307zdzaAMAgIRFUAEAAAmLoAIAABIWQQUAACQsggoAAEhYBBUAAJCwCCoAACBhEVQAAEDCIqgAAICERVABAAAJi6ACAAASlq03JYyG8K2KfD6fzZUAAICBCv/d7u+Wg8M+qDQ2NkqSiouLba4EAAAMVmNjozIzM3vdPuzvnhwMBlVVVaX09HRZlhXVY/t8PhUXF+vQoUPcmbkfnKuB41wNDudr4DhXg8P5GrhYnCtjjBobG1VYWCiHo/eRKMO+RcXhcKioqCimn5GRkcGPeIA4VwPHuRocztfAca4Gh/M1cNE+V321pIQxmBYAACQsggoAAEhYBJU+eL1e3X///fJ6vXaXkvA4VwPHuRocztfAca4Gh/M1cHaeq2E/mBYAAIxctKgAAICERVABAAAJi6ACAAASFkEFAAAkLIJKL376059qwoQJSkpK0qxZs/TnP//Z7pJs973vfU+WZXVZzj333Mj2lpYWLVu2TGPHjlVaWpquv/561dTU2FhxfL3++uv64he/qMLCQlmWpeeff77LdmOM7rvvPhUUFCg5OVlz587Vnj17uuxTX1+vhQsXKiMjQ1lZWbrtttt08uTJOH6L+OjvXC1atKjbb23+/Pld9hkt52rlypX6zGc+o/T0dI0bN07XXnutdu/e3WWfgfzbq6ys1NVXX62UlBSNGzdOd911l9rb2+P5VWJuIOfqC1/4Qrff1tKlS7vsMxrOlST9/Oc/17Rp0yKTuJWXl2vdunWR7YnyuyKo9ODpp5/Wt7/9bd1///165513dMEFF2jevHmqra21uzTbnX/++Tpy5Ehk+eMf/xjZ9q1vfUsvvviinnnmGVVUVKiqqkrXXXedjdXGV1NTky644AL99Kc/7XH7ww8/rEcffVS/+MUvtHnzZqWmpmrevHlqaWmJ7LNw4ULt3LlTr7zyil566SW9/vrrWrJkSby+Qtz0d64kaf78+V1+a0899VSX7aPlXFVUVGjZsmV666239Morr6itrU1XXHGFmpqaIvv0928vEAjo6quvVmtrq958802tWrVKTzzxhO677z47vlLMDORcSdLixYu7/LYefvjhyLbRcq4kqaioSD/4wQ+0detWvf3227r88su1YMEC7dy5U1IC/a4Murn44ovNsmXLIq8DgYApLCw0K1eutLEq+91///3mggsu6HHbiRMnjNvtNs8880xk3YcffmgkmU2bNsWpwsQhyfz2t7+NvA4GgyY/P9/88Ic/jKw7ceKE8Xq95qmnnjLGGPPBBx8YSWbLli2RfdatW2csyzKffPJJ3GqPt0+fK2OMueWWW8yCBQt6fc9oPVfGGFNbW2skmYqKCmPMwP7t/f73vzcOh8NUV1dH9vn5z39uMjIyjN/vj+8XiKNPnytjjPnLv/xL881vfrPX94zWcxU2ZswY8x//8R8J9buiReVTWltbtXXrVs2dOzeyzuFwaO7cudq0aZONlSWGPXv2qLCwUGVlZVq4cKEqKyslSVu3blVbW1uX83buueeqpKSE8yZp//79qq6u7nJ+MjMzNWvWrMj52bRpk7KysjRz5szIPnPnzpXD4dDmzZvjXrPdNm7cqHHjxmny5Mn6+te/rrq6usi20XyuGhoaJEnZ2dmSBvZvb9OmTZo6dary8vIi+8ybN08+ny/yX88j0afPVdjq1auVk5OjKVOmaMWKFWpubo5sG63nKhAI6De/+Y2amppUXl6eUL+rYX9Twmg7duyYAoFAlxMvSXl5edq1a5dNVSWGWbNm6YknntDkyZN15MgRff/739fnP/95vf/++6qurpbH41FWVlaX9+Tl5am6utqeghNI+Bz09LsKb6uurta4ceO6bHe5XMrOzh5153D+/Pm67rrrNHHiRO3bt0/f/e53deWVV2rTpk1yOp2j9lwFg0H94z/+oz772c9qypQpkjSgf3vV1dU9/vbC20ains6VJN10000qLS1VYWGhduzYoXvuuUe7d+/Wc889J2n0nav33ntP5eXlamlpUVpamn7729/qvPPO0/bt2xPmd0VQwYBdeeWVkefTpk3TrFmzVFpaqjVr1ig5OdnGyjDS3HDDDZHnU6dO1bRp0zRp0iRt3LhRc+bMsbEyey1btkzvv/9+l7Fh6Flv5+r0cUxTp05VQUGB5syZo3379mnSpEnxLtN2kydP1vbt29XQ0KBnn31Wt9xyiyoqKuwuqwu6fj4lJydHTqez28jmmpoa5efn21RVYsrKytI555yjvXv3Kj8/X62trTpx4kSXfThvIeFz0NfvKj8/v9uA7fb2dtXX14/6c1hWVqacnBzt3btX0ug8V7fffrteeuklvfbaayoqKoqsH8i/vfz8/B5/e+FtI01v56ons2bNkqQuv63RdK48Ho/OOusszZgxQytXrtQFF1ygH//4xwn1uyKofIrH49GMGTP06quvRtYFg0G9+uqrKi8vt7GyxHPy5Ent27dPBQUFmjFjhtxud5fztnv3blVWVnLeJE2cOFH5+fldzo/P59PmzZsj56e8vFwnTpzQ1q1bI/ts2LBBwWAw8n+mo9Xhw4dVV1engoICSaPrXBljdPvtt+u3v/2tNmzYoIkTJ3bZPpB/e+Xl5Xrvvfe6hLtXXnlFGRkZOu+88+LzReKgv3PVk+3bt0tSl9/WaDhXvQkGg/L7/Yn1u4rasNwR5De/+Y3xer3miSeeMB988IFZsmSJycrK6jKyeTS68847zcaNG83+/fvNn/70JzN37lyTk5NjamtrjTHGLF261JSUlJgNGzaYt99+25SXl5vy8nKbq46fxsZGs23bNrNt2zYjyTzyyCNm27Zt5uDBg8YYY37wgx+YrKws88ILL5gdO3aYBQsWmIkTJ5pTp05FjjF//nxz4YUXms2bN5s//vGP5uyzzzY33nijXV8pZvo6V42NjeY73/mO2bRpk9m/f7/5n//5H3PRRReZs88+27S0tESOMVrO1de//nWTmZlpNm7caI4cORJZmpubI/v092+vvb3dTJkyxVxxxRVm+/bt5uWXXza5ublmxYoVdnylmOnvXO3du9c88MAD5u233zb79+83L7zwgikrKzOXXnpp5Bij5VwZY8zy5ctNRUWF2b9/v9mxY4dZvny5sSzLrF+/3hiTOL8rgkovHnvsMVNSUmI8Ho+5+OKLzVtvvWV3Sbb76le/agoKCozH4zHjx483X/3qV83evXsj20+dOmW+8Y1vmDFjxpiUlBTz13/91+bIkSM2Vhxfr732mpHUbbnllluMMaFLlO+9916Tl5dnvF6vmTNnjtm9e3eXY9TV1Zkbb7zRpKWlmYyMDHPrrbeaxsZGG75NbPV1rpqbm80VV1xhcnNzjdvtNqWlpWbx4sXd/kNhtJyrns6TJPP4449H9hnIv70DBw6YK6+80iQnJ5ucnBxz5513mra2tjh/m9jq71xVVlaaSy+91GRnZxuv12vOOussc9ddd5mGhoYuxxkN58oYY/7u7/7OlJaWGo/HY3Jzc82cOXMiIcWYxPldWcYYE732GQAAgOhhjAoAAEhYBBUAAJCwCCoAACBhEVQAAEDCIqgAAICERVABAAAJi6ACAAASFkEFAAAkLIIKAABIWAQVAACQsAgqAAAgYRFUAABAwvr/BoeDGqzhrJEAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = plt.plot(lossss[0])\n",
    "\n",
    "plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
