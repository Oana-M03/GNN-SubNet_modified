{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Local Explanations vs Global Explanations\n",
    "\n",
    "This notebook runs GNN-SubNet and its modified version to generate a global node mask. The loss function values for both Gradient Descent procedures are plotted."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph is connected  True\n",
      "Graph is connected  True\n",
      "##################\n",
      "# DATASET LOADED #\n",
      "##################\n",
      "\n",
      "Number of nodes: 30\n",
      "Number of edges: 29\n",
      "Number of modalities: 1\n",
      "graphcnn for training ...\n",
      "Graphs class 0: 500, Graphs class 1: 500\n",
      "Length of balanced dataset list: 1000\n",
      "Train graph class 0: 405, train graph class 1: 395\n",
      "Validation graph class 0: 95, validation graph class 1: 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35 [00:00<?, ?batch/s]C:\\Users\\elena\\DELFT\\assignments\\RP\\GNN-SubNet_modified\\GNNSubNet\\graphcnn.py:134: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:623.)\n",
      "  graph_pool = torch.sparse.FloatTensor(idx, elem, torch.Size([len(batch_graph), start_idx[-1]]))\n",
      "100%|██████████| 35/35 [00:00<00:00, 140.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 0.0864\n",
      "Train Acc 1.0000\n",
      "Epoch 0, val_loss 0.0005\n",
      "Saving best model with validation loss 0.00050460355123505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 144.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.0647\n",
      "Train Acc 1.0000\n",
      "Epoch 1, val_loss 0.0000\n",
      "Saving best model with validation loss 1.7694916323307552e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 146.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss 0.0596\n",
      "Train Acc 1.0000\n",
      "Epoch 2, val_loss 0.0000\n",
      "Saving best model with validation loss 9.709323194329045e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 157.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss 0.0584\n",
      "Train Acc 1.0000\n",
      "Epoch 3, val_loss 0.0000\n",
      "Saving best model with validation loss 8.594686278229346e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 148.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss 0.0570\n",
      "Train Acc 1.0000\n",
      "Epoch 4, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 178.62batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss 0.0657\n",
      "Train Acc 1.0000\n",
      "Epoch 5, val_loss 0.0000\n",
      "Saving best model with validation loss 6.854186835880682e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 171.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss 0.0469\n",
      "Train Acc 1.0000\n",
      "Epoch 6, val_loss 0.0000\n",
      "Saving best model with validation loss 4.4106349150752067e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 154.32batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, loss 0.0542\n",
      "Train Acc 1.0000\n",
      "Epoch 7, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 170.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, loss 0.0377\n",
      "Train Acc 1.0000\n",
      "Epoch 8, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 173.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, loss 0.0365\n",
      "Train Acc 1.0000\n",
      "Epoch 9, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 158.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss 0.0463\n",
      "Train Acc 1.0000\n",
      "Epoch 10, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 153.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, loss 0.0493\n",
      "Train Acc 1.0000\n",
      "Epoch 11, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 165.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, loss 0.0525\n",
      "Train Acc 1.0000\n",
      "Epoch 12, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 171.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, loss 0.0547\n",
      "Train Acc 1.0000\n",
      "Epoch 13, val_loss 0.0000\n",
      "Saving best model with validation loss 5.841226524694321e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 158.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, loss 0.0453\n",
      "Train Acc 1.0000\n",
      "Epoch 14, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 167.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, loss 0.0471\n",
      "Train Acc 1.0000\n",
      "Epoch 15, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 150.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, loss 0.0396\n",
      "Train Acc 1.0000\n",
      "Epoch 16, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 158.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, loss 0.0406\n",
      "Train Acc 1.0000\n",
      "Epoch 17, val_loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 174.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, loss 0.0450\n",
      "Train Acc 1.0000\n",
      "Epoch 18, val_loss 0.0000\n",
      "Saving best model with validation loss 5.602822028549781e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 165.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, loss 0.0470\n",
      "Train Acc 1.0000\n",
      "Epoch 19, val_loss 0.0000\n",
      "Saving best model with validation loss 3.278249849358872e-08\n",
      "\n",
      "Confusion matrix (Validation set):\n",
      "\n",
      "[[ 95   0]\n",
      " [  0 105]]\n",
      "Validation accuracy: 100.0%\n",
      "Validation loss 3.278249849358872e-08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from GNNSubNet import GNNSubNet as gnn\n",
    "\n",
    "# Synthetic data set  ------------------------- #\n",
    "loc   = \"GNNSubNet/datasets/synthetic\"\n",
    "ppi   = f'{loc}/NETWORK_synthetic.txt'\n",
    "feats = [f'{loc}/FEATURES_synthetic.txt']\n",
    "targ  = f'{loc}/TARGET_synthetic.txt'\n",
    "\n",
    "# Read in the synthetic data\n",
    "g = gnn.GNNSubNet(loc, ppi, feats, targ, normalize=False)\n",
    "\n",
    "# Get some general information about the data dimension\n",
    "g.summary()\n",
    "\n",
    "# Train the GNN classifier and validate performance on a test set\n",
    "g.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([30, 1])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.s2v_test_dataset[0].node_features.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "200"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g.s2v_test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n       1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n       0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n       0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n       1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n       1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n       1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n       0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n       1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n       1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n       1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following cells train an explainer for 300 epochs to obtain the aggregation of local explanations. This corresponds to RQs 1 and 2 of the project."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from GNNSubNet import gnn_explainer as gnne\n",
    "import torch\n",
    "\n",
    "exp = gnne.GNNExplainer(g.model, epochs=300, lr = 0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "30"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.s2v_test_dataset[0].node_features.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0/200\n",
      "Progress: 1/200\n",
      "Progress: 2/200\n",
      "Progress: 3/200\n",
      "Progress: 4/200\n",
      "Progress: 5/200\n",
      "Progress: 6/200\n",
      "Progress: 7/200\n",
      "Progress: 8/200\n",
      "Progress: 9/200\n",
      "Progress: 10/200\n",
      "Progress: 11/200\n",
      "Progress: 12/200\n",
      "Progress: 13/200\n",
      "Progress: 14/200\n",
      "Progress: 15/200\n",
      "Progress: 16/200\n",
      "Progress: 17/200\n",
      "Progress: 18/200\n",
      "Progress: 19/200\n",
      "Progress: 20/200\n",
      "Progress: 21/200\n",
      "Progress: 22/200\n",
      "Progress: 23/200\n",
      "Progress: 24/200\n",
      "Progress: 25/200\n",
      "Progress: 26/200\n",
      "Progress: 27/200\n",
      "Progress: 28/200\n",
      "Progress: 29/200\n",
      "Progress: 30/200\n",
      "Progress: 31/200\n",
      "Progress: 32/200\n",
      "Progress: 33/200\n",
      "Progress: 34/200\n",
      "Progress: 35/200\n",
      "Progress: 36/200\n",
      "Progress: 37/200\n",
      "Progress: 38/200\n",
      "Progress: 39/200\n",
      "Progress: 40/200\n",
      "Progress: 41/200\n",
      "Progress: 42/200\n",
      "Progress: 43/200\n",
      "Progress: 44/200\n",
      "Progress: 45/200\n",
      "Progress: 46/200\n",
      "Progress: 47/200\n",
      "Progress: 48/200\n",
      "Progress: 49/200\n",
      "Progress: 50/200\n",
      "Progress: 51/200\n",
      "Progress: 52/200\n",
      "Progress: 53/200\n",
      "Progress: 54/200\n",
      "Progress: 55/200\n",
      "Progress: 56/200\n",
      "Progress: 57/200\n",
      "Progress: 58/200\n",
      "Progress: 59/200\n",
      "Progress: 60/200\n",
      "Progress: 61/200\n",
      "Progress: 62/200\n",
      "Progress: 63/200\n",
      "Progress: 64/200\n",
      "Progress: 65/200\n",
      "Progress: 66/200\n",
      "Progress: 67/200\n",
      "Progress: 68/200\n",
      "Progress: 69/200\n",
      "Progress: 70/200\n",
      "Progress: 71/200\n",
      "Progress: 72/200\n",
      "Progress: 73/200\n",
      "Progress: 74/200\n",
      "Progress: 75/200\n",
      "Progress: 76/200\n",
      "Progress: 77/200\n",
      "Progress: 78/200\n",
      "Progress: 79/200\n",
      "Progress: 80/200\n",
      "Progress: 81/200\n",
      "Progress: 82/200\n",
      "Progress: 83/200\n",
      "Progress: 84/200\n",
      "Progress: 85/200\n",
      "Progress: 86/200\n",
      "Progress: 87/200\n",
      "Progress: 88/200\n",
      "Progress: 89/200\n",
      "Progress: 90/200\n",
      "Progress: 91/200\n",
      "Progress: 92/200\n",
      "Progress: 93/200\n",
      "Progress: 94/200\n",
      "Progress: 95/200\n",
      "Progress: 96/200\n",
      "Progress: 97/200\n",
      "Progress: 98/200\n",
      "Progress: 99/200\n",
      "Progress: 100/200\n",
      "Progress: 101/200\n",
      "Progress: 102/200\n",
      "Progress: 103/200\n",
      "Progress: 104/200\n",
      "Progress: 105/200\n",
      "Progress: 106/200\n",
      "Progress: 107/200\n",
      "Progress: 108/200\n",
      "Progress: 109/200\n",
      "Progress: 110/200\n",
      "Progress: 111/200\n",
      "Progress: 112/200\n",
      "Progress: 113/200\n",
      "Progress: 114/200\n",
      "Progress: 115/200\n",
      "Progress: 116/200\n",
      "Progress: 117/200\n",
      "Progress: 118/200\n",
      "Progress: 119/200\n",
      "Progress: 120/200\n",
      "Progress: 121/200\n",
      "Progress: 122/200\n",
      "Progress: 123/200\n",
      "Progress: 124/200\n",
      "Progress: 125/200\n",
      "Progress: 126/200\n",
      "Progress: 127/200\n",
      "Progress: 128/200\n",
      "Progress: 129/200\n",
      "Progress: 130/200\n",
      "Progress: 131/200\n",
      "Progress: 132/200\n",
      "Progress: 133/200\n",
      "Progress: 134/200\n",
      "Progress: 135/200\n",
      "Progress: 136/200\n",
      "Progress: 137/200\n",
      "Progress: 138/200\n",
      "Progress: 139/200\n",
      "Progress: 140/200\n",
      "Progress: 141/200\n",
      "Progress: 142/200\n",
      "Progress: 143/200\n",
      "Progress: 144/200\n",
      "Progress: 145/200\n",
      "Progress: 146/200\n",
      "Progress: 147/200\n",
      "Progress: 148/200\n",
      "Progress: 149/200\n",
      "Progress: 150/200\n",
      "Progress: 151/200\n",
      "Progress: 152/200\n",
      "Progress: 153/200\n",
      "Progress: 154/200\n",
      "Progress: 155/200\n",
      "Progress: 156/200\n",
      "Progress: 157/200\n",
      "Progress: 158/200\n",
      "Progress: 159/200\n",
      "Progress: 160/200\n",
      "Progress: 161/200\n",
      "Progress: 162/200\n",
      "Progress: 163/200\n",
      "Progress: 164/200\n",
      "Progress: 165/200\n",
      "Progress: 166/200\n",
      "Progress: 167/200\n",
      "Progress: 168/200\n",
      "Progress: 169/200\n",
      "Progress: 170/200\n",
      "Progress: 171/200\n",
      "Progress: 172/200\n",
      "Progress: 173/200\n",
      "Progress: 174/200\n",
      "Progress: 175/200\n",
      "Progress: 176/200\n",
      "Progress: 177/200\n",
      "Progress: 178/200\n",
      "Progress: 179/200\n",
      "Progress: 180/200\n",
      "Progress: 181/200\n",
      "Progress: 182/200\n",
      "Progress: 183/200\n",
      "Progress: 184/200\n",
      "Progress: 185/200\n",
      "Progress: 186/200\n",
      "Progress: 187/200\n",
      "Progress: 188/200\n",
      "Progress: 189/200\n",
      "Progress: 190/200\n",
      "Progress: 191/200\n",
      "Progress: 192/200\n",
      "Progress: 193/200\n",
      "Progress: 194/200\n",
      "Progress: 195/200\n",
      "Progress: 196/200\n",
      "Progress: 197/200\n",
      "Progress: 198/200\n",
      "Progress: 199/200\n"
     ]
    },
    {
     "data": {
      "text/plain": "[-3.03469,\n -0.50785685,\n 6.0254087,\n -0.35703564,\n -0.15171765,\n -2.2598743,\n 6.0362334,\n -2.2528973,\n -0.6884245,\n -2.8732688,\n -2.3612032,\n -2.594422,\n -2.65883,\n -2.713076,\n 0.17486282,\n -2.591317,\n -0.05771812,\n -2.3404734,\n -3.8759441,\n 0.18429281,\n -0.77985334,\n -2.2692478,\n -2.8106787,\n -2.394257,\n -2.215886,\n -2.6080387,\n -0.77246004,\n -2.5150073,\n -2.6827662,\n -2.763542]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_mask = exp.explain_graph_modified_s2v(g.s2v_test_dataset, 0.1, False)\n",
    "node_mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RQ1: How can GNN-SubNet be modified to obtain a local-level explanation?\n",
    "\n",
    "The following code cells retrieve the loss function values generated by a run of the explainer. For each sample of the test dataset, the loss for each epoch was stored. Thus, we can now plot the losses for all of the node mask optimization processes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "      Epoch 0   Epoch 1   Epoch 2   Epoch 3    Epoch 4    Epoch 5    Epoch 6   \n0   -2.933165 -3.407375 -3.881360 -4.355718  -4.829634  -5.302014  -5.767702  \\\n1   -4.493733 -5.047421 -5.593677 -6.123810  -6.647747  -7.158635  -7.646592   \n2   -7.975766 -8.541156 -9.091280 -9.626339 -10.150602 -10.660461 -11.155199   \n3   -6.588441 -7.035859 -7.481597 -7.922063  -8.354877  -8.780503  -9.195539   \n4   -6.694752 -7.166295 -7.616283 -8.053928  -8.484569  -8.902380  -9.304231   \n..        ...       ...       ...       ...        ...        ...        ...   \n195 -0.834945 -1.361531 -1.885686 -2.414170  -2.943361  -3.465523  -3.982598   \n196 -6.953288 -7.380136 -7.807841 -8.239452  -8.662211  -9.073417  -9.476960   \n197 -6.776932 -7.172216 -7.569107 -7.961057  -8.349669  -8.732596  -9.108722   \n198 -0.591080 -1.045437 -1.492157 -1.936009  -2.379244  -2.822161  -3.262963   \n199 -1.155215 -1.620361 -2.080247 -2.535983  -2.987043  -3.429794  -3.862469   \n\n       Epoch 7    Epoch 8    Epoch 9  ...  Epoch 290  Epoch 291  Epoch 292   \n0    -6.227943  -6.687448  -7.142863  ... -14.501631 -14.501821 -14.502130  \\\n1    -8.112535  -8.551369  -8.955214  ... -14.640740 -14.641021 -14.641305   \n2   -11.633164 -12.091222 -12.527003  ... -19.272093 -19.272398 -19.272686   \n3    -9.599740  -9.989349 -10.365689  ... -15.847197 -15.847425 -15.847659   \n4    -9.690889 -10.062457 -10.416364  ... -16.141516 -16.141758 -16.141998   \n..         ...        ...        ...  ...        ...        ...        ...   \n195  -4.493320  -4.990477  -5.470680  ... -12.817194 -12.817499 -12.817808   \n196  -9.872027 -10.262211 -10.649099  ... -16.510418 -16.510658 -16.510895   \n197  -9.475893  -9.834053 -10.180551  ... -15.367954 -15.368166 -15.368379   \n198  -3.696355  -4.123263  -4.543855  ... -11.004396 -11.004661 -11.004924   \n199  -4.284025  -4.696269  -5.099887  ... -11.326133 -11.326380 -11.326615   \n\n     Epoch 293  Epoch 294  Epoch 295  Epoch 296  Epoch 297  Epoch 298   \n0   -14.502438 -14.502788 -14.503004 -14.503168 -14.503442 -14.503760  \\\n1   -14.641585 -14.641865 -14.642141 -14.642414 -14.642689 -14.642960   \n2   -19.272984 -19.273273 -19.273560 -19.273848 -19.274134 -19.274414   \n3   -15.847885 -15.848105 -15.848332 -15.848555 -15.848774 -15.848973   \n4   -16.142241 -16.142473 -16.142706 -16.142939 -16.143171 -16.143400   \n..         ...        ...        ...        ...        ...        ...   \n195 -12.818032 -12.818380 -12.818646 -12.818919 -12.819198 -12.819481   \n196 -16.511131 -16.511366 -16.511595 -16.511827 -16.512053 -16.512280   \n197 -15.368589 -15.368796 -15.369004 -15.369209 -15.369412 -15.369616   \n198 -11.005152 -11.005422 -11.005677 -11.005919 -11.006160 -11.006399   \n199 -11.326884 -11.327119 -11.327364 -11.327593 -11.327824 -11.328073   \n\n     Epoch 299  \n0   -14.504107  \n1   -14.643229  \n2   -19.274694  \n3   -15.849203  \n4   -16.143627  \n..         ...  \n195 -12.819768  \n196 -16.512505  \n197 -15.369816  \n198 -11.006641  \n199 -11.328346  \n\n[200 rows x 300 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Epoch 0</th>\n      <th>Epoch 1</th>\n      <th>Epoch 2</th>\n      <th>Epoch 3</th>\n      <th>Epoch 4</th>\n      <th>Epoch 5</th>\n      <th>Epoch 6</th>\n      <th>Epoch 7</th>\n      <th>Epoch 8</th>\n      <th>Epoch 9</th>\n      <th>...</th>\n      <th>Epoch 290</th>\n      <th>Epoch 291</th>\n      <th>Epoch 292</th>\n      <th>Epoch 293</th>\n      <th>Epoch 294</th>\n      <th>Epoch 295</th>\n      <th>Epoch 296</th>\n      <th>Epoch 297</th>\n      <th>Epoch 298</th>\n      <th>Epoch 299</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-2.933165</td>\n      <td>-3.407375</td>\n      <td>-3.881360</td>\n      <td>-4.355718</td>\n      <td>-4.829634</td>\n      <td>-5.302014</td>\n      <td>-5.767702</td>\n      <td>-6.227943</td>\n      <td>-6.687448</td>\n      <td>-7.142863</td>\n      <td>...</td>\n      <td>-14.501631</td>\n      <td>-14.501821</td>\n      <td>-14.502130</td>\n      <td>-14.502438</td>\n      <td>-14.502788</td>\n      <td>-14.503004</td>\n      <td>-14.503168</td>\n      <td>-14.503442</td>\n      <td>-14.503760</td>\n      <td>-14.504107</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-4.493733</td>\n      <td>-5.047421</td>\n      <td>-5.593677</td>\n      <td>-6.123810</td>\n      <td>-6.647747</td>\n      <td>-7.158635</td>\n      <td>-7.646592</td>\n      <td>-8.112535</td>\n      <td>-8.551369</td>\n      <td>-8.955214</td>\n      <td>...</td>\n      <td>-14.640740</td>\n      <td>-14.641021</td>\n      <td>-14.641305</td>\n      <td>-14.641585</td>\n      <td>-14.641865</td>\n      <td>-14.642141</td>\n      <td>-14.642414</td>\n      <td>-14.642689</td>\n      <td>-14.642960</td>\n      <td>-14.643229</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-7.975766</td>\n      <td>-8.541156</td>\n      <td>-9.091280</td>\n      <td>-9.626339</td>\n      <td>-10.150602</td>\n      <td>-10.660461</td>\n      <td>-11.155199</td>\n      <td>-11.633164</td>\n      <td>-12.091222</td>\n      <td>-12.527003</td>\n      <td>...</td>\n      <td>-19.272093</td>\n      <td>-19.272398</td>\n      <td>-19.272686</td>\n      <td>-19.272984</td>\n      <td>-19.273273</td>\n      <td>-19.273560</td>\n      <td>-19.273848</td>\n      <td>-19.274134</td>\n      <td>-19.274414</td>\n      <td>-19.274694</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-6.588441</td>\n      <td>-7.035859</td>\n      <td>-7.481597</td>\n      <td>-7.922063</td>\n      <td>-8.354877</td>\n      <td>-8.780503</td>\n      <td>-9.195539</td>\n      <td>-9.599740</td>\n      <td>-9.989349</td>\n      <td>-10.365689</td>\n      <td>...</td>\n      <td>-15.847197</td>\n      <td>-15.847425</td>\n      <td>-15.847659</td>\n      <td>-15.847885</td>\n      <td>-15.848105</td>\n      <td>-15.848332</td>\n      <td>-15.848555</td>\n      <td>-15.848774</td>\n      <td>-15.848973</td>\n      <td>-15.849203</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-6.694752</td>\n      <td>-7.166295</td>\n      <td>-7.616283</td>\n      <td>-8.053928</td>\n      <td>-8.484569</td>\n      <td>-8.902380</td>\n      <td>-9.304231</td>\n      <td>-9.690889</td>\n      <td>-10.062457</td>\n      <td>-10.416364</td>\n      <td>...</td>\n      <td>-16.141516</td>\n      <td>-16.141758</td>\n      <td>-16.141998</td>\n      <td>-16.142241</td>\n      <td>-16.142473</td>\n      <td>-16.142706</td>\n      <td>-16.142939</td>\n      <td>-16.143171</td>\n      <td>-16.143400</td>\n      <td>-16.143627</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>-0.834945</td>\n      <td>-1.361531</td>\n      <td>-1.885686</td>\n      <td>-2.414170</td>\n      <td>-2.943361</td>\n      <td>-3.465523</td>\n      <td>-3.982598</td>\n      <td>-4.493320</td>\n      <td>-4.990477</td>\n      <td>-5.470680</td>\n      <td>...</td>\n      <td>-12.817194</td>\n      <td>-12.817499</td>\n      <td>-12.817808</td>\n      <td>-12.818032</td>\n      <td>-12.818380</td>\n      <td>-12.818646</td>\n      <td>-12.818919</td>\n      <td>-12.819198</td>\n      <td>-12.819481</td>\n      <td>-12.819768</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>-6.953288</td>\n      <td>-7.380136</td>\n      <td>-7.807841</td>\n      <td>-8.239452</td>\n      <td>-8.662211</td>\n      <td>-9.073417</td>\n      <td>-9.476960</td>\n      <td>-9.872027</td>\n      <td>-10.262211</td>\n      <td>-10.649099</td>\n      <td>...</td>\n      <td>-16.510418</td>\n      <td>-16.510658</td>\n      <td>-16.510895</td>\n      <td>-16.511131</td>\n      <td>-16.511366</td>\n      <td>-16.511595</td>\n      <td>-16.511827</td>\n      <td>-16.512053</td>\n      <td>-16.512280</td>\n      <td>-16.512505</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>-6.776932</td>\n      <td>-7.172216</td>\n      <td>-7.569107</td>\n      <td>-7.961057</td>\n      <td>-8.349669</td>\n      <td>-8.732596</td>\n      <td>-9.108722</td>\n      <td>-9.475893</td>\n      <td>-9.834053</td>\n      <td>-10.180551</td>\n      <td>...</td>\n      <td>-15.367954</td>\n      <td>-15.368166</td>\n      <td>-15.368379</td>\n      <td>-15.368589</td>\n      <td>-15.368796</td>\n      <td>-15.369004</td>\n      <td>-15.369209</td>\n      <td>-15.369412</td>\n      <td>-15.369616</td>\n      <td>-15.369816</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>-0.591080</td>\n      <td>-1.045437</td>\n      <td>-1.492157</td>\n      <td>-1.936009</td>\n      <td>-2.379244</td>\n      <td>-2.822161</td>\n      <td>-3.262963</td>\n      <td>-3.696355</td>\n      <td>-4.123263</td>\n      <td>-4.543855</td>\n      <td>...</td>\n      <td>-11.004396</td>\n      <td>-11.004661</td>\n      <td>-11.004924</td>\n      <td>-11.005152</td>\n      <td>-11.005422</td>\n      <td>-11.005677</td>\n      <td>-11.005919</td>\n      <td>-11.006160</td>\n      <td>-11.006399</td>\n      <td>-11.006641</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>-1.155215</td>\n      <td>-1.620361</td>\n      <td>-2.080247</td>\n      <td>-2.535983</td>\n      <td>-2.987043</td>\n      <td>-3.429794</td>\n      <td>-3.862469</td>\n      <td>-4.284025</td>\n      <td>-4.696269</td>\n      <td>-5.099887</td>\n      <td>...</td>\n      <td>-11.326133</td>\n      <td>-11.326380</td>\n      <td>-11.326615</td>\n      <td>-11.326884</td>\n      <td>-11.327119</td>\n      <td>-11.327364</td>\n      <td>-11.327593</td>\n      <td>-11.327824</td>\n      <td>-11.328073</td>\n      <td>-11.328346</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 300 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = pd.read_csv(\"GNNSubNet/saved_values/loss_values_modified_alg.csv\")\n",
    "losses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ -2.93316531,  -3.40737462,  -3.88135958,  -4.35571814,\n        -4.82963371,  -5.30201435,  -5.7677021 ,  -6.22794294,\n        -6.68744802,  -7.14286327,  -7.58433676,  -8.01445484,\n        -8.43517303,  -8.84376812,  -9.2318697 ,  -9.60191536,\n        -9.94948196, -10.27787971, -10.58675098, -10.8770647 ,\n       -11.14798355, -11.39916039, -11.62874603, -11.83916187,\n       -12.03229904, -12.20922279, -12.37089348, -12.51962662,\n       -12.65610409, -12.78023243, -12.89355373, -12.99766636,\n       -13.09231853, -13.1787796 , -13.25799274, -13.33053875,\n       -13.3966465 , -13.45705032, -13.51252174, -13.56356716,\n       -13.61041069, -13.65351391, -13.69322681, -13.7297554 ,\n       -13.7636261 , -13.7948637 , -13.82402992, -13.85126972,\n       -13.8765831 , -13.90016937, -13.92214584, -13.94281578,\n       -13.96214962, -13.98029709, -13.99712372, -14.0130825 ,\n       -14.02824974, -14.04263115, -14.05619717, -14.06894016,\n       -14.08104134, -14.09257793, -14.10354614, -14.11398697,\n       -14.12394142, -14.13331413, -14.14237118, -14.1510725 ,\n       -14.15941525, -14.16738892, -14.17502689, -14.18237305,\n       -14.1894455 , -14.19626427, -14.20285225, -14.20918274,\n       -14.21529293, -14.22121525, -14.22688866, -14.23239708,\n       -14.23777962, -14.2429018 , -14.24788952, -14.25279236,\n       -14.25751305, -14.26206589, -14.26659107, -14.27092171,\n       -14.2750845 , -14.27912712, -14.28311157, -14.28691483,\n       -14.29070282, -14.29451752, -14.29795742, -14.30152035,\n       -14.30496025, -14.30834293, -14.3115797 , -14.31476593,\n       -14.31784153, -14.32100391, -14.32390404, -14.3268013 ,\n       -14.32966614, -14.33249092, -14.33528233, -14.33782482,\n       -14.34054565, -14.34315872, -14.34564972, -14.3481226 ,\n       -14.35054779, -14.35286045, -14.35523033, -14.35750484,\n       -14.35972691, -14.36189365, -14.36403751, -14.36619949,\n       -14.36819839, -14.37021542, -14.37229633, -14.37422276,\n       -14.37606621, -14.37796879, -14.37993813, -14.38169384,\n       -14.38342667, -14.3852644 , -14.38709354, -14.38867569,\n       -14.39033699, -14.39203072, -14.39369488, -14.39532948,\n       -14.39686298, -14.39841175, -14.39982414, -14.4013319 ,\n       -14.40295506, -14.40435696, -14.40568447, -14.40709591,\n       -14.40858555, -14.40988064, -14.41125011, -14.41257858,\n       -14.41401958, -14.41521168, -14.41633129, -14.41752434,\n       -14.41880226, -14.42015934, -14.42150688, -14.42243004,\n       -14.42349052, -14.42467785, -14.42579651, -14.42702866,\n       -14.4281702 , -14.42919064, -14.43029881, -14.43128109,\n       -14.43234062, -14.43349361, -14.4343338 , -14.4353056 ,\n       -14.43628883, -14.43729019, -14.43840599, -14.43932438,\n       -14.4402113 , -14.44105148, -14.44193268, -14.44290733,\n       -14.44397068, -14.44487   , -14.44559956, -14.44646645,\n       -14.44741821, -14.4483633 , -14.44911671, -14.44993591,\n       -14.45080185, -14.45152855, -14.45226765, -14.45310211,\n       -14.45392418, -14.45464706, -14.45537853, -14.45620918,\n       -14.45692158, -14.45757484, -14.45835304, -14.45897865,\n       -14.45963192, -14.46038532, -14.46111584, -14.46175575,\n       -14.46249199, -14.46311092, -14.46370602, -14.46441078,\n       -14.46500683, -14.46558952, -14.46627426, -14.46691513,\n       -14.46750164, -14.46818352, -14.46866035, -14.46916008,\n       -14.46975327, -14.47043705, -14.47111607, -14.47159672,\n       -14.47221375, -14.47276783, -14.47330189, -14.4738512 ,\n       -14.47436428, -14.47488308, -14.4753952 , -14.4759388 ,\n       -14.47643566, -14.47684288, -14.477355  , -14.47799778,\n       -14.47843075, -14.47888374, -14.47937012, -14.47992992,\n       -14.4803791 , -14.4808197 , -14.48131561, -14.48181343,\n       -14.48217678, -14.48264313, -14.4831953 , -14.48360538,\n       -14.48396015, -14.48440647, -14.48495388, -14.48520756,\n       -14.48555756, -14.48605728, -14.48654652, -14.48693275,\n       -14.48731422, -14.48779488, -14.48813438, -14.48844624,\n       -14.48885059, -14.48939514, -14.48981285, -14.49013424,\n       -14.49038315, -14.4907589 , -14.49126911, -14.49158382,\n       -14.49178696, -14.49208069, -14.49249268, -14.49301147,\n       -14.49331951, -14.49355698, -14.49384403, -14.49427605,\n       -14.49476147, -14.49510098, -14.49541473, -14.49574471,\n       -14.49606323, -14.49641323, -14.4968462 , -14.49706745,\n       -14.49734783, -14.49773121, -14.49811649, -14.49835205,\n       -14.4986124 , -14.49899673, -14.49936581, -14.4995842 ,\n       -14.49990654, -14.50023937, -14.5004549 , -14.50073338,\n       -14.50104332, -14.50142097, -14.50163078, -14.50182056,\n       -14.50212955, -14.50243759, -14.50278759, -14.50300407,\n       -14.50316811, -14.50344181, -14.50376034, -14.50410748])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "single_loss = losses.iloc[0].values\n",
    "\n",
    "single_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(single_loss)\n",
    "plt.ylabel('Loss function value')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For comparison purposes, the following code cells run the original explainer on the same test dataset and plot the loss function values for GNN-SubNet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-6.6762],\n        [-6.1098],\n        [ 6.0470],\n        [-7.1510],\n        [ 4.5858],\n        [-5.9597],\n        [ 6.0190],\n        [-5.6735],\n        [-5.7310],\n        [-5.1305],\n        [ 5.3261],\n        [-6.5045],\n        [-5.5160],\n        [-5.3908],\n        [-4.2583],\n        [-6.7374],\n        [-4.8749],\n        [-5.6275],\n        [-4.7874],\n        [-6.3620],\n        [-5.6680],\n        [-5.3332],\n        [-7.1080],\n        [-5.7286],\n        [-6.6423],\n        [-5.6701],\n        [-5.6523],\n        [-4.3950],\n        [-5.3129],\n        [-7.1419]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_mask_gnn_subnet = exp.explain_graph_modified_s2v(g.s2v_test_dataset, 0.1, True)\n",
    "node_mask_gnn_subnet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "     Epoch 0    Epoch 1    Epoch 2    Epoch 3    Epoch 4    Epoch 5   Epoch 6   \n0 -30.334724 -33.642708 -36.913509 -40.158226 -43.393124 -46.580338 -49.68969  \\\n\n     Epoch 7    Epoch 8    Epoch 9  ...   Epoch 290   Epoch 291   Epoch 292   \n0 -52.723156 -55.651218 -58.469872  ... -101.110291 -101.114792 -101.119057  \\\n\n    Epoch 293   Epoch 294  Epoch 295   Epoch 296   Epoch 297   Epoch 298   \n0 -101.123123 -101.126999 -101.13073 -101.134323 -101.137787 -101.141136  \\\n\n    Epoch 299  \n0 -101.144402  \n\n[1 rows x 300 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Epoch 0</th>\n      <th>Epoch 1</th>\n      <th>Epoch 2</th>\n      <th>Epoch 3</th>\n      <th>Epoch 4</th>\n      <th>Epoch 5</th>\n      <th>Epoch 6</th>\n      <th>Epoch 7</th>\n      <th>Epoch 8</th>\n      <th>Epoch 9</th>\n      <th>...</th>\n      <th>Epoch 290</th>\n      <th>Epoch 291</th>\n      <th>Epoch 292</th>\n      <th>Epoch 293</th>\n      <th>Epoch 294</th>\n      <th>Epoch 295</th>\n      <th>Epoch 296</th>\n      <th>Epoch 297</th>\n      <th>Epoch 298</th>\n      <th>Epoch 299</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-30.334724</td>\n      <td>-33.642708</td>\n      <td>-36.913509</td>\n      <td>-40.158226</td>\n      <td>-43.393124</td>\n      <td>-46.580338</td>\n      <td>-49.68969</td>\n      <td>-52.723156</td>\n      <td>-55.651218</td>\n      <td>-58.469872</td>\n      <td>...</td>\n      <td>-101.110291</td>\n      <td>-101.114792</td>\n      <td>-101.119057</td>\n      <td>-101.123123</td>\n      <td>-101.126999</td>\n      <td>-101.13073</td>\n      <td>-101.134323</td>\n      <td>-101.137787</td>\n      <td>-101.141136</td>\n      <td>-101.144402</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 300 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_gnn_subnet = pd.read_csv(\"GNNSubNet/saved_values/loss_values_gnn-subnet.csv\")\n",
    "losses_gnn_subnet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses_gnn_subnet.iloc[0].values)\n",
    "plt.ylabel('Loss function value')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RQ2: How can multiple local explanations be aggregated to obtain a global explanation?\n",
    "\n",
    "To verify the correctness of the mask aggregation, we use both methods in the task of disease subnetwork detection and obtain the accuracy of the two explainers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[-3.0346899557500002,\n -0.5078569104999999,\n 6.0254092785,\n -0.3570356859999999,\n -0.1517176115,\n -2.2598742017200006,\n 6.036233232,\n -2.2528973422000003,\n -0.6884245924999999,\n -2.8732688249000002,\n -2.3612033642999997,\n -2.5944220288500004,\n -2.6588298639229997,\n -2.7130762876999994,\n 0.1748628175000001,\n -2.5913167479499997,\n -0.05771814000000001,\n -2.34047323846,\n -3.875944284395,\n 0.18429285500000006,\n -0.7798533915,\n -2.26924792726,\n -2.810678845615,\n -2.3942571201750003,\n -2.21588612475,\n -2.60803866305,\n -0.7724600359999999,\n -2.5150072153200003,\n -2.6827661701500007,\n -2.7635420563000004]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_mask = exp.aggregate_masks_from_file(\"GNNSubNet/saved_values/node_mask_values.csv\", np.mean)\n",
    "node_mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def min_max(arr):\n",
    "\n",
    "    new_arr = []\n",
    "\n",
    "    minimum = min(arr)\n",
    "    maximum = max(arr)\n",
    "\n",
    "    for entry in arr:\n",
    "        new_entry = (entry - minimum) / (maximum - minimum)\n",
    "        new_arr.append(new_entry)\n",
    "\n",
    "    return new_arr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.035974299210022154,\n 0.07889420226356529,\n 1.0,\n 0.0,\n 0.8892814176094395,\n 0.09026474137513367,\n 0.997877620760268,\n 0.11195174744929895,\n 0.107592133944588,\n 0.15309546215707565,\n 0.9453786135029406,\n 0.0489842050314305,\n 0.12388481966659093,\n 0.1333719748174486,\n 0.21917977037015654,\n 0.03134143985569093,\n 0.17246155852163408,\n 0.11543876624820153,\n 0.1790915007245188,\n 0.059785816152258385,\n 0.11236983563808722,\n 0.1377337922090863,\n 0.0032581397221678977,\n 0.107772130086702,\n 0.03854811397679437,\n 0.11220656735904003,\n 0.1135562132612501,\n 0.20881727468715555,\n 0.13926957623337008,\n 0.000688732729249131]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_gnnsubnet = min_max([tensor.item() for tensor in node_mask_gnn_subnet])\n",
    "minmax_gnnsubnet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.08487078921392835,\n 0.3397928828780655,\n 0.9989080145626835,\n 0.3550086338319339,\n 0.37572235431972767,\n 0.1630388559932444,\n 1.0,\n 0.16374272348436436,\n 0.32157613063555,\n 0.10115592238300299,\n 0.15281616149323188,\n 0.12928766191135385,\n 0.12278981267827997,\n 0.11731710764578084,\n 0.40866974942638584,\n 0.12960094129874017,\n 0.3852055855617552,\n 0.15490754109228683,\n 0.0,\n 0.4096211082458181,\n 0.31235224427467984,\n 0.1620931782625445,\n 0.10747037540621354,\n 0.14948150008101152,\n 0.16747663738862836,\n 0.1279139340722915,\n 0.3130981303817205,\n 0.13729950526248894,\n 0.12037497434559175,\n 0.11222581781400277]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_new_alg = min_max(node_mask)\n",
    "minmax_new_alg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.04889649, 0.26089868, 0.00109199, 0.35500863, 0.51355906,\n       0.07277411, 0.00212238, 0.05179098, 0.213984  , 0.05193954,\n       0.79256245, 0.08030346, 0.00109501, 0.01605487, 0.18948998,\n       0.0982595 , 0.21274403, 0.03946877, 0.1790915 , 0.34983529,\n       0.19998241, 0.02435939, 0.10421224, 0.04170937, 0.12892852,\n       0.01570737, 0.19954192, 0.07151777, 0.0188946 , 0.11153709])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(np.subtract(minmax_gnnsubnet, minmax_new_alg))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Disease Subnetwork Detection\n",
    "\n",
    "The following code cells run both GNN-SubNet and the modified algorithm to detect disease subnetworks, then compares the obtained modules and the module importances. The algorithms are run on the TCGA data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph is connected  False\n",
      "Calculate subgraph ...\n",
      "Number of subgraphs:  118\n",
      "Size of subgraph:  2049\n",
      "Graph is connected  True\n",
      "##################\n",
      "# DATASET LOADED #\n",
      "##################\n",
      "graphcnn for training ...\n",
      "Graphs class 0: 200, Graphs class 1: 306\n",
      "Length of balanced dataset list: 400\n",
      "Train graph class 0: 160, train graph class 1: 160\n",
      "Validation graph class 0: 40, validation graph class 1: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35 [00:00<?, ?batch/s]C:\\Users\\elena\\DELFT\\assignments\\RP\\GNN-SubNet_modified\\GNNSubNet\\graphcnn.py:134: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:623.)\n",
      "  graph_pool = torch.sparse.FloatTensor(idx, elem, torch.Size([len(batch_graph), start_idx[-1]]))\n",
      "100%|██████████| 35/35 [00:09<00:00,  3.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 188.7717\n",
      "Train Acc 0.5938\n",
      "Epoch 0, val_loss 37.3064\n",
      "Saving best model with validation loss 37.306392669677734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:11<00:00,  3.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 29.2931\n",
      "Train Acc 0.5813\n",
      "Epoch 1, val_loss 7.3093\n",
      "Saving best model with validation loss 7.309275150299072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:11<00:00,  3.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss 15.3316\n",
      "Train Acc 0.5094\n",
      "Epoch 2, val_loss 9.4518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:11<00:00,  2.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss 17.5996\n",
      "Train Acc 0.5875\n",
      "Epoch 3, val_loss 8.6028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss 12.9845\n",
      "Train Acc 0.6344\n",
      "Epoch 4, val_loss 7.0776\n",
      "Saving best model with validation loss 7.077635288238525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss 13.6562\n",
      "Train Acc 0.5719\n",
      "Epoch 5, val_loss 4.5997\n",
      "Saving best model with validation loss 4.599661827087402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss 9.9030\n",
      "Train Acc 0.5000\n",
      "Epoch 6, val_loss 25.1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.84batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, loss 10.5809\n",
      "Train Acc 0.8063\n",
      "Epoch 7, val_loss 1.2073\n",
      "Saving best model with validation loss 1.2073395252227783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.75batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, loss 9.4772\n",
      "Train Acc 0.7500\n",
      "Epoch 8, val_loss 4.0611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:11<00:00,  2.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, loss 7.9866\n",
      "Train Acc 0.5719\n",
      "Epoch 9, val_loss 3.9823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:11<00:00,  2.96batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss 7.6687\n",
      "Train Acc 0.7375\n",
      "Epoch 10, val_loss 5.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:11<00:00,  2.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, loss 9.4244\n",
      "Train Acc 0.7219\n",
      "Epoch 11, val_loss 1.6219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:11<00:00,  3.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, loss 6.4201\n",
      "Train Acc 0.5437\n",
      "Epoch 12, val_loss 4.5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:12<00:00,  2.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, loss 7.2214\n",
      "Train Acc 0.6875\n",
      "Epoch 13, val_loss 7.4673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:11<00:00,  2.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, loss 7.2107\n",
      "Train Acc 0.7656\n",
      "Epoch 14, val_loss 6.7580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:13<00:00,  2.65batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, loss 4.6127\n",
      "Train Acc 0.5125\n",
      "Epoch 15, val_loss 4.3454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:10<00:00,  3.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, loss 5.5499\n",
      "Train Acc 0.5219\n",
      "Epoch 16, val_loss 4.5623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:11<00:00,  2.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, loss 3.9786\n",
      "Train Acc 0.6594\n",
      "Epoch 17, val_loss 1.4611\n",
      "Early stopping!\n",
      "\n",
      "Confusion matrix (Validation set):\n",
      "\n",
      "[[26 14]\n",
      " [ 5 35]]\n",
      "Validation accuracy: 76.25%\n",
      "Validation loss 1.2073395252227783\n"
     ]
    }
   ],
   "source": [
    "from GNNSubNet import GNNSubNet as gnn\n",
    "\n",
    "# location of the files\n",
    "loc   = \"TCGA\"\n",
    "# PPI network\n",
    "ppi   = f'{loc}/KIDNEY_RANDOM_PPI.txt'\n",
    "# single-omic features\n",
    "#feats = [f'{loc}/KIDNEY_RANDOM_Methy_FEATURES.txt']\n",
    "# multi-omic features\n",
    "feats = [f'{loc}/KIDNEY_RANDOM_mRNA_FEATURES.txt', f'{loc}/KIDNEY_RANDOM_Methy_FEATURES.txt']\n",
    "# outcome class\n",
    "targ  = f'{loc}/KIDNEY_RANDOM_TARGET.txt'\n",
    "\n",
    "# Load the multi-omics data\n",
    "g = gnn.GNNSubNet(loc, ppi, feats, targ)\n",
    "\n",
    "# Train the GNN classifier and validate performance on a test set\n",
    "g.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "80"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g.s2v_test_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GNN-SubNet for disease subnetworks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- Run the Explainer -------\n",
      "\n",
      "Explainer::Iteration 1 of 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Run GNN-SubNet with 10 iterations\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgnn_subnet\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\DELFT\\assignments\\RP\\GNN-SubNet_modified\\GNNSubNet\\GNNSubNet.py:135\u001B[0m, in \u001B[0;36mGNNSubNet.explain\u001B[1;34m(self, n_runs, classifier, communities, gnn_subnet)\u001B[0m\n\u001B[0;32m    132\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexplain_chebconv(n_runs\u001B[38;5;241m=\u001B[39mn_runs, communities\u001B[38;5;241m=\u001B[39mcommunities)\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraphcnn\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 135\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain_graphcnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_runs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_runs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcommunities\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommunities\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgnn_subnet\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgnn_subnet\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraphcheb\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexplain_graphcheb(n_runs\u001B[38;5;241m=\u001B[39mn_runs, communities\u001B[38;5;241m=\u001B[39mcommunities)\n",
      "File \u001B[1;32m~\\DELFT\\assignments\\RP\\GNN-SubNet_modified\\GNNSubNet\\GNNSubNet.py:1269\u001B[0m, in \u001B[0;36mGNNSubNet.explain_graphcnn\u001B[1;34m(self, n_runs, explainer_lambda, communities, save_to_disk, gnn_subnet)\u001B[0m\n\u001B[0;32m   1267\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExplainer::Iteration \u001B[39m\u001B[38;5;132;01m{\u001B[39;00midx\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mno_of_runs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   1268\u001B[0m exp \u001B[38;5;241m=\u001B[39m GNNExplainer(model, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m300\u001B[39m)\n\u001B[1;32m-> 1269\u001B[0m em \u001B[38;5;241m=\u001B[39m \u001B[43mexp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain_graph_modified_s2v\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms2v_test_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlamda\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgnn_subnet\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1270\u001B[0m \u001B[38;5;66;03m#Path(f\"{path}/{sigma}/modified_gnn\").mkdir(parents=True, exist_ok=True)\u001B[39;00m\n\u001B[0;32m   1271\u001B[0m gnn_feature_masks \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mreshape(em, (\u001B[38;5;28mlen\u001B[39m(em), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[1;32m~\\DELFT\\assignments\\RP\\GNN-SubNet_modified\\GNNSubNet\\gnn_explainer.py:799\u001B[0m, in \u001B[0;36mGNNExplainer.explain_graph_modified_s2v\u001B[1;34m(self, dataset, param, gnn_subnet)\u001B[0m\n\u001B[0;32m    797\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel([data_copy])\n\u001B[0;32m    798\u001B[0m log_logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__to_log_prob__(out)\n\u001B[1;32m--> 799\u001B[0m loss_hit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__loss__\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_logits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mPRED\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdd\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    800\u001B[0m loss_fail \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__loss__(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, log_logits, \u001B[38;5;28mabs\u001B[39m(PRED[dd] \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m    801\u001B[0m loss_xx \u001B[38;5;241m=\u001B[39m loss_xx \u001B[38;5;241m+\u001B[39m loss_hit\n",
      "File \u001B[1;32m~\\DELFT\\assignments\\RP\\GNN-SubNet_modified\\GNNSubNet\\gnn_explainer.py:150\u001B[0m, in \u001B[0;36mGNNExplainer.__loss__\u001B[1;34m(self, node_idx, log_logits, pred_label)\u001B[0m\n\u001B[0;32m    148\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoeffs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medge_size\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m*\u001B[39m edge_reduce(m)\n\u001B[0;32m    149\u001B[0m ent \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mm \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39mlog(m \u001B[38;5;241m+\u001B[39m EPS) \u001B[38;5;241m-\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m m) \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m m \u001B[38;5;241m+\u001B[39m EPS)\n\u001B[1;32m--> 150\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoeffs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43medge_ent\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43ment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    152\u001B[0m m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode_feat_mask\u001B[38;5;241m.\u001B[39msigmoid()\n\u001B[0;32m    153\u001B[0m node_feat_reduce \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(torch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoeffs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnode_feat_reduction\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Run GNN-SubNet with 10 iterations\n",
    "g.explain(10, gnn_subnet=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "13588"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g.edge_mask)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def read_communities(file_path):\n",
    "    communities = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line by comma, handling empty elements\n",
    "            community = [int(num) for num in line.strip().split(',') if num]\n",
    "            communities.append(community)\n",
    "\n",
    "    return communities\n",
    "\n",
    "def read_community_importances(file_path):\n",
    "    community_importances = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "          # Remove leading/trailing whitespaces and convert to number\n",
    "          community_importances.append(float(line.strip()))\n",
    "\n",
    "    return community_importances"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "[[0,\n  16,\n  17,\n  45,\n  46,\n  47,\n  48,\n  49,\n  50,\n  62,\n  69,\n  70,\n  71,\n  92,\n  100,\n  101,\n  123,\n  124,\n  125,\n  126,\n  127,\n  128,\n  189,\n  198,\n  204,\n  226,\n  227,\n  229,\n  230,\n  231,\n  232,\n  233,\n  234,\n  235,\n  236,\n  237,\n  280,\n  290,\n  291,\n  295,\n  297,\n  298,\n  301,\n  312,\n  334,\n  336,\n  355,\n  357,\n  358,\n  372,\n  373,\n  374,\n  375,\n  376,\n  377,\n  378,\n  379,\n  380,\n  381,\n  382,\n  383,\n  384,\n  385,\n  386,\n  387,\n  389,\n  390,\n  391,\n  392,\n  396,\n  397,\n  398,\n  405,\n  406,\n  407,\n  408,\n  422,\n  507,\n  521,\n  535,\n  565,\n  568,\n  570,\n  614,\n  615,\n  618,\n  619,\n  620,\n  635,\n  650,\n  656,\n  668,\n  720,\n  722,\n  733,\n  734,\n  742,\n  745,\n  746,\n  747,\n  755,\n  833,\n  834,\n  835,\n  845,\n  906,\n  914,\n  915,\n  916,\n  917,\n  918,\n  919,\n  920,\n  921,\n  922,\n  923,\n  924,\n  925,\n  926,\n  927,\n  928,\n  929,\n  930,\n  931,\n  932,\n  933,\n  934,\n  995,\n  1004,\n  1005,\n  1006,\n  1007,\n  1008,\n  1009,\n  1010,\n  1011,\n  1012,\n  1013,\n  1014,\n  1018,\n  1027,\n  1037,\n  1038,\n  1039,\n  1042,\n  1046,\n  1049,\n  1077,\n  1082,\n  1110,\n  1115,\n  1116,\n  1117,\n  1118,\n  1125,\n  1127,\n  1128,\n  1129,\n  1133,\n  1152,\n  1159,\n  1182,\n  1190,\n  1191,\n  1208,\n  1227,\n  1228,\n  1255,\n  1261,\n  1315,\n  1334,\n  1335,\n  1397,\n  1398,\n  1400,\n  1421,\n  1434,\n  1464,\n  1481,\n  1482,\n  1562,\n  1611,\n  1635,\n  1651,\n  1660,\n  1665,\n  1666,\n  1667,\n  1668,\n  1669,\n  1686,\n  1694,\n  1733,\n  1734,\n  1737,\n  1739,\n  1742,\n  1759,\n  1771,\n  1839,\n  1842,\n  1846,\n  1852,\n  1858,\n  1859,\n  1869,\n  1878,\n  1970,\n  1977,\n  1978,\n  1981,\n  1992,\n  1993,\n  2029],\n [1,\n  15,\n  19,\n  20,\n  21,\n  22,\n  23,\n  24,\n  25,\n  26,\n  27,\n  28,\n  68,\n  82,\n  85,\n  86,\n  152,\n  166,\n  167,\n  169,\n  170,\n  177,\n  220,\n  250,\n  399,\n  404,\n  414,\n  545,\n  632,\n  647,\n  648,\n  701,\n  707,\n  708,\n  712,\n  713,\n  727,\n  728,\n  736,\n  748,\n  749,\n  779,\n  781,\n  782,\n  815,\n  816,\n  817,\n  818,\n  819,\n  821,\n  822,\n  823,\n  836,\n  855,\n  941,\n  962,\n  1036,\n  1083,\n  1114,\n  1226,\n  1301,\n  1308,\n  1322,\n  1324,\n  1325,\n  1326,\n  1338,\n  1339,\n  1342,\n  1343,\n  1354,\n  1355,\n  1356,\n  1357,\n  1358,\n  1359,\n  1365,\n  1391,\n  1518,\n  1519,\n  1520,\n  1691,\n  1692,\n  1693,\n  1860,\n  1866,\n  1942],\n [2,\n  3,\n  63,\n  83,\n  84,\n  95,\n  96,\n  163,\n  265,\n  449,\n  583,\n  629,\n  630,\n  631,\n  671,\n  699,\n  730,\n  853,\n  854,\n  883,\n  1076,\n  1145,\n  1146,\n  1147,\n  1149,\n  1150,\n  1353,\n  1521,\n  1536,\n  1537,\n  1619,\n  1819,\n  2025],\n [4,\n  67,\n  118,\n  168,\n  252,\n  253,\n  345,\n  483,\n  484,\n  485,\n  486,\n  487,\n  573,\n  687,\n  688,\n  731,\n  757,\n  758,\n  759,\n  760,\n  761,\n  762,\n  763,\n  764,\n  765,\n  766,\n  767,\n  770,\n  848,\n  936,\n  937,\n  938,\n  1047,\n  1048,\n  1074,\n  1075,\n  1094,\n  1136,\n  1232,\n  1233,\n  1248,\n  1275,\n  1276,\n  1371,\n  1399,\n  1401,\n  1404,\n  1442,\n  1443,\n  1444,\n  1445,\n  1446,\n  1471,\n  1474,\n  1477,\n  1478,\n  1512,\n  1513,\n  1515,\n  1539,\n  1563,\n  1569,\n  1682,\n  1690,\n  1700,\n  1721,\n  1782,\n  1786,\n  1787,\n  1789,\n  1790,\n  1798,\n  1804,\n  1805,\n  1906,\n  1908,\n  1924,\n  1950,\n  1951],\n [5,\n  7,\n  41,\n  42,\n  43,\n  64,\n  74,\n  147,\n  148,\n  155,\n  156,\n  159,\n  165,\n  179,\n  181,\n  185,\n  196,\n  205,\n  206,\n  217,\n  238,\n  239,\n  254,\n  255,\n  256,\n  264,\n  273,\n  292,\n  338,\n  339,\n  340,\n  341,\n  344,\n  403,\n  409,\n  410,\n  459,\n  489,\n  499,\n  500,\n  501,\n  523,\n  524,\n  529,\n  530,\n  532,\n  536,\n  543,\n  544,\n  547,\n  569,\n  572,\n  599,\n  600,\n  601,\n  602,\n  616,\n  617,\n  623,\n  669,\n  673,\n  676,\n  700,\n  709,\n  785,\n  786,\n  787,\n  788,\n  789,\n  796,\n  798,\n  801,\n  803,\n  804,\n  805,\n  806,\n  807,\n  808,\n  809,\n  810,\n  811,\n  812,\n  813,\n  814,\n  824,\n  830,\n  832,\n  851,\n  885,\n  886,\n  943,\n  947,\n  949,\n  952,\n  957,\n  958,\n  959,\n  961,\n  1056,\n  1057,\n  1069,\n  1072,\n  1079,\n  1080,\n  1081,\n  1092,\n  1098,\n  1099,\n  1100,\n  1101,\n  1102,\n  1103,\n  1104,\n  1105,\n  1107,\n  1120,\n  1126,\n  1142,\n  1143,\n  1144,\n  1163,\n  1168,\n  1169,\n  1185,\n  1200,\n  1201,\n  1202,\n  1203,\n  1204,\n  1205,\n  1206,\n  1212,\n  1214,\n  1218,\n  1219,\n  1220,\n  1221,\n  1251,\n  1252,\n  1253,\n  1254,\n  1262,\n  1263,\n  1264,\n  1266,\n  1268,\n  1272,\n  1283,\n  1320,\n  1321,\n  1348,\n  1360,\n  1361,\n  1362,\n  1363,\n  1364,\n  1406,\n  1415,\n  1437,\n  1438,\n  1439,\n  1440,\n  1441,\n  1457,\n  1458,\n  1461,\n  1490,\n  1500,\n  1534,\n  1535,\n  1544,\n  1556,\n  1575,\n  1610,\n  1615,\n  1618,\n  1670,\n  1687,\n  1701,\n  1702,\n  1703,\n  1719,\n  1720,\n  1744,\n  1810,\n  1827,\n  1828,\n  1843,\n  1844,\n  1847,\n  1848,\n  1849,\n  1853,\n  1854,\n  1862,\n  1863,\n  1899,\n  1934,\n  1940,\n  1947,\n  2013,\n  2026,\n  2032,\n  2033],\n [6,\n  122,\n  158,\n  164,\n  171,\n  172,\n  178,\n  203,\n  210,\n  211,\n  216,\n  257,\n  277,\n  303,\n  309,\n  311,\n  318,\n  319,\n  342,\n  352,\n  353,\n  395,\n  415,\n  430,\n  431,\n  451,\n  453,\n  454,\n  456,\n  458,\n  472,\n  491,\n  502,\n  531,\n  546,\n  590,\n  591,\n  592,\n  593,\n  594,\n  605,\n  625,\n  626,\n  627,\n  637,\n  641,\n  642,\n  777,\n  780,\n  792,\n  800,\n  802,\n  820,\n  910,\n  948,\n  1024,\n  1025,\n  1085,\n  1086,\n  1088,\n  1089,\n  1090,\n  1093,\n  1095,\n  1096,\n  1123,\n  1124,\n  1130,\n  1137,\n  1138,\n  1139,\n  1140,\n  1141,\n  1158,\n  1160,\n  1188,\n  1241,\n  1256,\n  1277,\n  1313,\n  1316,\n  1349,\n  1350,\n  1351,\n  1416,\n  1417,\n  1422,\n  1423,\n  1424,\n  1425,\n  1426,\n  1427,\n  1436,\n  1451,\n  1452,\n  1460,\n  1462,\n  1476,\n  1522,\n  1523,\n  1525,\n  1526,\n  1527,\n  1542,\n  1545,\n  1560,\n  1561,\n  1568,\n  1576,\n  1603,\n  1607,\n  1685,\n  1728,\n  1747,\n  1857,\n  1885,\n  1886,\n  1887,\n  1888,\n  1901,\n  1903,\n  1933,\n  1959,\n  1961,\n  1966,\n  2000,\n  2011,\n  2019,\n  2020,\n  2021,\n  2022,\n  2035,\n  2037,\n  2038,\n  2039,\n  2040,\n  2042],\n [8,\n  9,\n  52,\n  53,\n  54,\n  55,\n  56,\n  57,\n  58,\n  59,\n  76,\n  270,\n  511,\n  512,\n  685,\n  686,\n  717,\n  732,\n  751,\n  752,\n  753,\n  768,\n  769,\n  847,\n  850,\n  953,\n  954,\n  1023,\n  1033,\n  1303,\n  1304,\n  1327,\n  1333,\n  1346,\n  1418,\n  1420,\n  1468,\n  1469,\n  1533,\n  1570,\n  1695,\n  1696,\n  1806,\n  1914],\n [10,\n  18,\n  60,\n  73,\n  129,\n  183,\n  191,\n  219,\n  259,\n  266,\n  306,\n  307,\n  308,\n  337,\n  343,\n  400,\n  401,\n  402,\n  413,\n  416,\n  417,\n  423,\n  426,\n  435,\n  450,\n  461,\n  463,\n  467,\n  468,\n  469,\n  473,\n  474,\n  476,\n  479,\n  540,\n  560,\n  582,\n  585,\n  603,\n  624,\n  649,\n  659,\n  677,\n  704,\n  710,\n  711,\n  744,\n  772,\n  790,\n  825,\n  826,\n  827,\n  828,\n  829,\n  849,\n  882,\n  951,\n  963,\n  970,\n  991,\n  1001,\n  1097,\n  1112,\n  1186,\n  1312,\n  1314,\n  1317,\n  1323,\n  1419,\n  1459,\n  1483,\n  1484,\n  1485,\n  1486,\n  1487,\n  1488,\n  1489,\n  1498,\n  1547,\n  1548,\n  1550,\n  1551,\n  1552,\n  1620,\n  1623,\n  1634,\n  1671,\n  1672,\n  1673,\n  1674,\n  1697,\n  1704,\n  1714,\n  1715,\n  1716,\n  1717,\n  1726,\n  1727,\n  1764,\n  1765,\n  1767,\n  1797,\n  1799,\n  1826,\n  1845,\n  1877,\n  1918,\n  1956,\n  1957,\n  1999,\n  2003,\n  2015,\n  2024,\n  2041,\n  2044],\n [11,\n  12,\n  29,\n  30,\n  31,\n  32,\n  34,\n  35,\n  36,\n  37,\n  39,\n  119,\n  149,\n  197,\n  240,\n  251,\n  275,\n  278,\n  425,\n  432,\n  433,\n  437,\n  438,\n  504,\n  505,\n  564,\n  567,\n  636,\n  638,\n  639,\n  640,\n  643,\n  665,\n  678,\n  1017,\n  1034,\n  1040,\n  1166,\n  1167,\n  1170,\n  1171,\n  1172,\n  1173,\n  1174,\n  1175,\n  1176,\n  1177,\n  1178,\n  1179,\n  1197,\n  1198,\n  1209,\n  1230,\n  1299,\n  1583,\n  1584,\n  1585,\n  1699,\n  1725,\n  1732,\n  1760,\n  1761,\n  1762,\n  1834,\n  1864,\n  1875,\n  1876,\n  1917,\n  1962,\n  1979,\n  1995,\n  1996,\n  1997,\n  1998],\n [13,\n  207,\n  452,\n  460,\n  462,\n  464,\n  480,\n  481,\n  503,\n  534,\n  597,\n  613,\n  634,\n  674,\n  735,\n  791,\n  1132,\n  1164,\n  1189,\n  1199,\n  1239,\n  1243,\n  1244,\n  1245,\n  1246,\n  1247,\n  1319,\n  1330,\n  1352,\n  1372,\n  1428,\n  1517,\n  1549,\n  1604,\n  1605,\n  1606,\n  1689,\n  1823,\n  1915,\n  1968,\n  1969,\n  2002,\n  2005,\n  2023,\n  2030,\n  2031],\n [14,\n  80,\n  81,\n  93,\n  157,\n  160,\n  161,\n  162,\n  305,\n  313,\n  447,\n  465,\n  492,\n  493,\n  494,\n  496,\n  548,\n  595,\n  660,\n  837,\n  838,\n  840,\n  841,\n  842,\n  843,\n  844,\n  846,\n  1028,\n  1053,\n  1060,\n  1064,\n  1065,\n  1071,\n  1073,\n  1148,\n  1250,\n  1265,\n  1340,\n  1366,\n  1367,\n  1368,\n  1369,\n  1381,\n  1384,\n  1385,\n  1386,\n  1388,\n  1389,\n  1390,\n  1467,\n  1470,\n  1543,\n  1567,\n  1597,\n  1598,\n  1600,\n  1601,\n  1602,\n  1677,\n  1816,\n  1817,\n  1821,\n  1831,\n  1832,\n  1833,\n  1835,\n  1840,\n  1911,\n  1912,\n  1948,\n  1949,\n  1952,\n  1953,\n  1971,\n  1972,\n  2007],\n [33,\n  65,\n  146,\n  184,\n  212,\n  213,\n  218,\n  279,\n  310,\n  314,\n  315,\n  421,\n  424,\n  427,\n  471,\n  561,\n  562,\n  563,\n  892,\n  893,\n  894,\n  895,\n  896,\n  897,\n  898,\n  899,\n  902,\n  942,\n  1019,\n  1187,\n  1215,\n  1429,\n  1453,\n  1454,\n  1455,\n  1456,\n  1480,\n  1577,\n  1580,\n  1590,\n  1596,\n  1705,\n  1706,\n  1707,\n  1708,\n  1749,\n  1766,\n  1768,\n  1791,\n  1792,\n  1793,\n  1825,\n  1994,\n  2034,\n  2043,\n  2045],\n [38,\n  200,\n  208,\n  356,\n  411,\n  457,\n  525,\n  526,\n  527,\n  528,\n  658,\n  724,\n  725,\n  726,\n  858,\n  859,\n  860,\n  861,\n  966,\n  967,\n  968,\n  974,\n  976,\n  977,\n  979,\n  980,\n  981,\n  982,\n  983,\n  990,\n  1151,\n  1499,\n  1718,\n  1741,\n  1748,\n  1891,\n  1916,\n  2001,\n  2004],\n [40, 214, 571, 574, 575, 887, 1224, 1811, 1812, 1813, 1814, 1815, 1910],\n [44,\n  61,\n  77,\n  87,\n  117,\n  130,\n  132,\n  133,\n  134,\n  135,\n  136,\n  137,\n  138,\n  139,\n  140,\n  141,\n  142,\n  144,\n  145,\n  176,\n  180,\n  182,\n  190,\n  193,\n  195,\n  202,\n  209,\n  271,\n  272,\n  284,\n  285,\n  286,\n  287,\n  288,\n  289,\n  293,\n  294,\n  296,\n  299,\n  300,\n  347,\n  359,\n  418,\n  419,\n  420,\n  436,\n  445,\n  448,\n  455,\n  482,\n  490,\n  506,\n  515,\n  522,\n  541,\n  542,\n  566,\n  576,\n  577,\n  578,\n  586,\n  587,\n  588,\n  644,\n  645,\n  646,\n  651,\n  652,\n  653,\n  654,\n  655,\n  657,\n  662,\n  663,\n  664,\n  672,\n  684,\n  714,\n  715,\n  716,\n  718,\n  719,\n  729,\n  743,\n  750,\n  754,\n  756,\n  797,\n  852,\n  862,\n  866,\n  867,\n  868,\n  869,\n  873,\n  874,\n  875,\n  876,\n  877,\n  878,\n  879,\n  880,\n  881,\n  888,\n  889,\n  890,\n  891,\n  912,\n  913,\n  935,\n  944,\n  945,\n  946,\n  950,\n  960,\n  964,\n  985,\n  987,\n  988,\n  989,\n  994,\n  1000,\n  1002,\n  1003,\n  1020,\n  1026,\n  1029,\n  1030,\n  1032,\n  1041,\n  1050,\n  1054,\n  1059,\n  1084,\n  1111,\n  1134,\n  1135,\n  1180,\n  1183,\n  1211,\n  1213,\n  1225,\n  1269,\n  1270,\n  1271,\n  1274,\n  1278,\n  1279,\n  1280,\n  1305,\n  1310,\n  1311,\n  1318,\n  1332,\n  1336,\n  1337,\n  1341,\n  1370,\n  1373,\n  1374,\n  1375,\n  1376,\n  1377,\n  1378,\n  1379,\n  1380,\n  1382,\n  1383,\n  1387,\n  1393,\n  1394,\n  1402,\n  1403,\n  1405,\n  1412,\n  1413,\n  1449,\n  1450,\n  1465,\n  1473,\n  1479,\n  1504,\n  1505,\n  1506,\n  1507,\n  1508,\n  1509,\n  1510,\n  1511,\n  1514,\n  1528,\n  1532,\n  1538,\n  1540,\n  1541,\n  1557,\n  1564,\n  1565,\n  1571,\n  1574,\n  1581,\n  1586,\n  1587,\n  1608,\n  1609,\n  1616,\n  1656,\n  1657,\n  1678,\n  1679,\n  1680,\n  1683,\n  1684,\n  1698,\n  1730,\n  1731,\n  1735,\n  1736,\n  1745,\n  1750,\n  1774,\n  1776,\n  1778,\n  1779,\n  1780,\n  1781,\n  1796,\n  1838,\n  1841,\n  1855,\n  1856,\n  1881,\n  1882,\n  1896,\n  1904,\n  1905,\n  1907,\n  1913,\n  1926,\n  1929,\n  1954,\n  1955,\n  1967,\n  1974,\n  1975,\n  1976,\n  1989,\n  2027],\n [51,\n  75,\n  192,\n  194,\n  201,\n  260,\n  261,\n  262,\n  263,\n  267,\n  268,\n  269,\n  346,\n  470,\n  475,\n  589,\n  703,\n  793,\n  794,\n  857,\n  864,\n  865,\n  870,\n  871,\n  872,\n  908,\n  909,\n  911,\n  1035,\n  1055,\n  1061,\n  1062,\n  1063,\n  1066,\n  1067,\n  1068,\n  1078,\n  1106,\n  1113,\n  1161,\n  1162,\n  1222,\n  1223,\n  1234,\n  1235,\n  1236,\n  1237,\n  1238,\n  1242,\n  1249,\n  1295,\n  1296,\n  1297,\n  1298,\n  1302,\n  1306,\n  1307,\n  1347,\n  1472,\n  1475,\n  1491,\n  1492,\n  1493,\n  1494,\n  1495,\n  1496,\n  1497,\n  1554,\n  1555,\n  1558,\n  1559,\n  1572,\n  1573,\n  1578,\n  1579,\n  1599,\n  1617,\n  1621,\n  1758,\n  1775,\n  1777,\n  1820,\n  1865,\n  1870,\n  1871,\n  1890,\n  1892,\n  1893,\n  1900,\n  1928,\n  1930,\n  1935,\n  1939,\n  1960,\n  1964,\n  1965,\n  2014,\n  2028,\n  2047],\n [66,\n  107,\n  108,\n  109,\n  110,\n  111,\n  112,\n  113,\n  114,\n  115,\n  116,\n  335,\n  354,\n  429,\n  446,\n  495,\n  497,\n  498,\n  579,\n  581,\n  584,\n  698,\n  799,\n  863,\n  939,\n  940,\n  1043,\n  1309,\n  1676,\n  1681,\n  1722,\n  1729,\n  1784,\n  1800,\n  1801,\n  1802,\n  1803],\n [72,\n  79,\n  88,\n  94,\n  228,\n  274,\n  317,\n  322,\n  324,\n  325,\n  326,\n  327,\n  328,\n  329,\n  330,\n  331,\n  332,\n  349,\n  350,\n  633,\n  783,\n  784,\n  900,\n  904,\n  973,\n  1015,\n  1210,\n  1216,\n  1229,\n  1240,\n  1257,\n  1258,\n  1282,\n  1300,\n  1328,\n  1329,\n  1392,\n  1407,\n  1408,\n  1591,\n  1592,\n  1622,\n  1625,\n  1636,\n  1675,\n  1783,\n  1807,\n  1808,\n  1822,\n  1830,\n  1867,\n  1919,\n  1920,\n  1921,\n  1922,\n  1923,\n  2012],\n [78,\n  97,\n  98,\n  99,\n  105,\n  154,\n  222,\n  223,\n  224,\n  276,\n  304,\n  316,\n  320,\n  321,\n  323,\n  348,\n  351,\n  488,\n  519,\n  533,\n  596,\n  598,\n  670,\n  884,\n  907,\n  965,\n  969,\n  971,\n  972,\n  975,\n  978,\n  984,\n  996,\n  1031,\n  1051,\n  1052,\n  1091,\n  1109,\n  1121,\n  1165,\n  1192,\n  1193,\n  1194,\n  1195,\n  1196,\n  1207,\n  1231,\n  1281,\n  1293,\n  1344,\n  1345,\n  1524,\n  1546,\n  1688,\n  1709,\n  1710,\n  1711,\n  1712,\n  1713,\n  1740,\n  1772,\n  1773,\n  1794,\n  1795,\n  1809,\n  1883,\n  1884,\n  1902,\n  1963,\n  2036,\n  2048],\n [89, 90, 91, 1501, 1502, 1503, 1824],\n [102,\n  103,\n  104,\n  365,\n  366,\n  367,\n  368,\n  955,\n  956,\n  1217,\n  1267,\n  1516,\n  1626,\n  1627,\n  1628,\n  1629,\n  1630,\n  1631,\n  1632,\n  1751,\n  1752,\n  1753,\n  1754,\n  1755,\n  1756,\n  1757],\n [106,\n  150,\n  333,\n  439,\n  440,\n  441,\n  442,\n  443,\n  444,\n  580,\n  666,\n  667,\n  675,\n  721,\n  778,\n  795,\n  1016,\n  1058,\n  1447,\n  1943,\n  1944,\n  1945,\n  1946],\n [120,\n  121,\n  143,\n  151,\n  174,\n  175,\n  679,\n  680,\n  681,\n  682,\n  683,\n  1021,\n  1022,\n  1044,\n  1045,\n  1466,\n  1582,\n  1588,\n  1589,\n  1633,\n  1743,\n  1829,\n  1861,\n  1872,\n  1874,\n  1973,\n  2006,\n  2008,\n  2009,\n  2010,\n  2046],\n [131,\n  258,\n  369,\n  370,\n  371,\n  388,\n  393,\n  394,\n  434,\n  697,\n  702,\n  705,\n  706,\n  737,\n  738,\n  739,\n  740,\n  741,\n  839,\n  1119,\n  1463,\n  1566,\n  1624,\n  1637,\n  1638,\n  1639,\n  1640,\n  1641,\n  1642,\n  1643,\n  1644,\n  1645,\n  1646,\n  1788,\n  1868,\n  1894,\n  1895,\n  1958,\n  1990,\n  1991],\n [153, 241, 242, 243, 244, 245, 246, 247, 248, 249, 1612, 1613, 1614, 1897],\n [173,\n  186,\n  187,\n  188,\n  281,\n  282,\n  283,\n  428,\n  621,\n  622,\n  771,\n  1122,\n  1260,\n  1650,\n  1925,\n  1927,\n  1931,\n  1932,\n  1936,\n  1937,\n  1938,\n  1941,\n  1980],\n [199, 215, 773, 774, 775, 776, 1430, 1431, 1432, 1723, 1724],\n [221,\n  513,\n  514,\n  516,\n  517,\n  518,\n  520,\n  604,\n  661,\n  992,\n  993,\n  1395,\n  1396,\n  1448,\n  1746,\n  1769,\n  1851],\n [225,\n  689,\n  690,\n  691,\n  692,\n  693,\n  694,\n  695,\n  696,\n  1153,\n  1154,\n  1155,\n  1156,\n  1157,\n  1770],\n [302,\n  466,\n  723,\n  856,\n  901,\n  903,\n  997,\n  998,\n  999,\n  1070,\n  1087,\n  1284,\n  1285,\n  1286,\n  1287,\n  1288,\n  1289,\n  1290,\n  1291,\n  1292,\n  1294,\n  1433,\n  1529,\n  1530,\n  1531,\n  1553,\n  1738,\n  1889,\n  1898,\n  2016,\n  2018],\n [360,\n  361,\n  362,\n  363,\n  364,\n  508,\n  537,\n  538,\n  539,\n  549,\n  550,\n  551,\n  552,\n  553,\n  554,\n  555,\n  556,\n  557,\n  558,\n  559,\n  1331,\n  1593,\n  1594,\n  1647,\n  1648,\n  1649,\n  1763,\n  1785,\n  1873],\n [412,\n  509,\n  510,\n  628,\n  1273,\n  1409,\n  1410,\n  1411,\n  1414,\n  1652,\n  1653,\n  1654,\n  1655,\n  1658,\n  1659],\n [477,\n  606,\n  607,\n  608,\n  609,\n  610,\n  611,\n  612,\n  905,\n  986,\n  1181,\n  1184,\n  1259,\n  1661,\n  1662,\n  1663,\n  1664,\n  1909],\n [478, 1131, 1435, 1595, 1818, 1879, 1880, 2017],\n [831, 1108, 1836, 1837],\n [1850, 1982, 1983, 1984, 1985, 1986, 1987, 1988]]"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_gnn_subnet = read_communities(\"TCGA/communities_gnn_subnet.txt\")\n",
    "communities_gnn_subnet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.305,\n 0.485,\n 0.653,\n 0.436,\n 0.444,\n 0.664,\n 0.421,\n 0.698,\n 0.447,\n 0.843,\n 0.465,\n 0.746,\n 0.786,\n 0.439,\n 0.345,\n 0.597,\n 0.407,\n 0.75,\n 0.712,\n 0.332,\n 0.23,\n 0.244,\n 0.535,\n 0.631,\n 0.41,\n 0.628,\n 0.582,\n 0.224,\n 0.352,\n 0.832,\n 0.669,\n 0.172,\n 0.588,\n 0.327,\n 0.458,\n 0.471]"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_importance_gnn_subnet = read_community_importances(\"TCGA/communities_scores_gnn_subnet.txt\")\n",
    "comm_importance_gnn_subnet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['ABT1', 'BMS1', 'DCAF13', 'DDX18', 'DDX21', 'DDX24', 'DIS3',\n       'DIS3L', 'DNTTIP2', 'EDC4', 'ESF1', 'EXOSC9', 'FBL', 'FTSJ3',\n       'GNL2', 'HEATR1', 'MPHOSPH10', 'MYBBP1A', 'NAT10', 'NCL', 'NMD3',\n       'NOL10', 'NOL6', 'NOP14', 'NOP2', 'NOP58', 'PATL1', 'PDCD11',\n       'PES1', 'PIH1D1', 'POLR1B', 'PWP2', 'RBM28', 'RRP1', 'RRP12',\n       'RRP9', 'SKIV2L', 'TBL3', 'TSR1', 'UTP15', 'UTP20', 'WDR3',\n       'WDR75', 'XRN1', 'ZFP36', 'ZFP36L1'], dtype=object)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices = np.argsort(comm_importance_gnn_subnet)[::-1]\n",
    "\n",
    "sorted_communities_gnn_subnet = []\n",
    "\n",
    "# Loop through sorted indices and assign cluster memberships\n",
    "for index in sorted_indices:\n",
    "  sorted_communities_gnn_subnet.append(communities_gnn_subnet[index])\n",
    "\n",
    "# The gene names of the community ranked highest by gnn-subnet\n",
    "g.gene_names[sorted_communities_gnn_subnet[0]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The modified algorithm for disease subnetworks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- Run the Explainer -------\n",
      "\n",
      "Explainer::Iteration 1 of 10\n",
      "[tensor([[ 1.8565],\n",
      "        [ 2.4349],\n",
      "        [-2.3104],\n",
      "        ...,\n",
      "        [ 2.1373],\n",
      "        [ 0.4272],\n",
      "        [ 2.3223]]), tensor([[-1.6708],\n",
      "        [ 0.2923],\n",
      "        [ 1.7574],\n",
      "        ...,\n",
      "        [ 2.0649],\n",
      "        [ 2.3337],\n",
      "        [-2.3323]]), tensor([[ 0.5216],\n",
      "        [ 2.3830],\n",
      "        [-2.2577],\n",
      "        ...,\n",
      "        [ 2.3305],\n",
      "        [ 0.2096],\n",
      "        [ 2.2452]]), tensor([[ 2.0802],\n",
      "        [ 2.3541],\n",
      "        [-2.4439],\n",
      "        ...,\n",
      "        [ 2.1911],\n",
      "        [ 0.3187],\n",
      "        [ 1.4374]]), tensor([[ 1.7799],\n",
      "        [ 2.3244],\n",
      "        [-2.3496],\n",
      "        ...,\n",
      "        [ 1.3725],\n",
      "        [ 0.1435],\n",
      "        [ 1.7467]]), tensor([[ 0.5489],\n",
      "        [ 2.3203],\n",
      "        [-2.4063],\n",
      "        ...,\n",
      "        [ 2.1277],\n",
      "        [ 0.0392],\n",
      "        [ 1.8281]]), tensor([[ 1.7625],\n",
      "        [ 2.3971],\n",
      "        [-2.3478],\n",
      "        ...,\n",
      "        [ 1.5723],\n",
      "        [-0.4789],\n",
      "        [ 2.4839]]), tensor([[ 2.0650],\n",
      "        [ 2.3296],\n",
      "        [-2.1954],\n",
      "        ...,\n",
      "        [ 2.1810],\n",
      "        [ 0.1786],\n",
      "        [ 1.5763]]), tensor([[-1.7147],\n",
      "        [ 0.2201],\n",
      "        [ 1.7153],\n",
      "        ...,\n",
      "        [ 2.3816],\n",
      "        [ 2.3674],\n",
      "        [-2.4417]]), tensor([[ 1.6041],\n",
      "        [ 2.2725],\n",
      "        [-2.4773],\n",
      "        ...,\n",
      "        [ 2.2683],\n",
      "        [ 0.1652],\n",
      "        [ 2.0146]]), tensor([[ 2.0759],\n",
      "        [ 2.4720],\n",
      "        [-2.3948],\n",
      "        ...,\n",
      "        [ 2.2900],\n",
      "        [ 0.2203],\n",
      "        [ 1.7585]]), tensor([[ 1.6303],\n",
      "        [ 2.3310],\n",
      "        [-2.3748],\n",
      "        ...,\n",
      "        [ 2.1276],\n",
      "        [ 0.0774],\n",
      "        [ 2.2747]]), tensor([[ 2.0002],\n",
      "        [ 2.3241],\n",
      "        [-2.3256],\n",
      "        ...,\n",
      "        [ 2.3081],\n",
      "        [ 0.5745],\n",
      "        [ 3.0605]]), tensor([[-1.6584],\n",
      "        [ 0.2857],\n",
      "        [ 0.9271],\n",
      "        ...,\n",
      "        [ 2.0883],\n",
      "        [ 2.1773],\n",
      "        [-2.6548]]), tensor([[-1.6708],\n",
      "        [ 0.2464],\n",
      "        [ 1.7612],\n",
      "        ...,\n",
      "        [ 1.6101],\n",
      "        [ 2.5249],\n",
      "        [-2.4066]]), tensor([[-0.1922],\n",
      "        [-0.8282],\n",
      "        [-0.1812],\n",
      "        ...,\n",
      "        [ 2.5531],\n",
      "        [ 1.9747],\n",
      "        [-2.6783]]), tensor([[ 0.7814],\n",
      "        [ 2.4151],\n",
      "        [-2.2978],\n",
      "        ...,\n",
      "        [ 2.2726],\n",
      "        [ 0.2358],\n",
      "        [ 1.8295]]), tensor([[ 1.2284],\n",
      "        [ 2.3735],\n",
      "        [-2.2652],\n",
      "        ...,\n",
      "        [ 2.2684],\n",
      "        [ 0.1806],\n",
      "        [ 2.3946]]), tensor([[ 1.8013],\n",
      "        [ 2.2442],\n",
      "        [-2.3885],\n",
      "        ...,\n",
      "        [ 2.1257],\n",
      "        [-0.7827],\n",
      "        [ 2.2427]]), tensor([[-0.9579],\n",
      "        [ 1.3350],\n",
      "        [ 2.6585],\n",
      "        ...,\n",
      "        [ 1.0396],\n",
      "        [ 2.1104],\n",
      "        [-2.3664]]), tensor([[ 1.9299],\n",
      "        [ 2.4082],\n",
      "        [-2.2954],\n",
      "        ...,\n",
      "        [ 2.1349],\n",
      "        [ 0.0179],\n",
      "        [ 2.0769]]), tensor([[ 1.8698],\n",
      "        [ 2.2858],\n",
      "        [-2.2660],\n",
      "        ...,\n",
      "        [ 1.8370],\n",
      "        [-0.0420],\n",
      "        [ 2.1197]]), tensor([[-0.9047],\n",
      "        [ 0.1569],\n",
      "        [ 1.9379],\n",
      "        ...,\n",
      "        [ 2.9076],\n",
      "        [ 2.4435],\n",
      "        [-2.5148]]), tensor([[-1.4654],\n",
      "        [ 1.2027],\n",
      "        [ 0.3080],\n",
      "        ...,\n",
      "        [ 2.1297],\n",
      "        [ 2.0252],\n",
      "        [-2.4428]]), tensor([[ 2.0109],\n",
      "        [ 2.3900],\n",
      "        [-2.3551],\n",
      "        ...,\n",
      "        [ 2.1977],\n",
      "        [ 0.2640],\n",
      "        [ 1.8558]]), tensor([[ 1.5930],\n",
      "        [ 2.3384],\n",
      "        [-2.3327],\n",
      "        ...,\n",
      "        [ 1.8177],\n",
      "        [-0.3831],\n",
      "        [ 2.0940]]), tensor([[ 1.4174],\n",
      "        [ 2.4494],\n",
      "        [-2.3540],\n",
      "        ...,\n",
      "        [ 2.0900],\n",
      "        [-0.5333],\n",
      "        [ 2.3675]]), tensor([[-1.0049],\n",
      "        [-0.8328],\n",
      "        [ 1.8292],\n",
      "        ...,\n",
      "        [ 2.3197],\n",
      "        [ 2.3851],\n",
      "        [-2.4216]]), tensor([[-1.3153],\n",
      "        [ 2.3315],\n",
      "        [ 0.2868],\n",
      "        ...,\n",
      "        [ 2.2681],\n",
      "        [ 2.5462],\n",
      "        [-2.6070]]), tensor([[ 1.5925],\n",
      "        [ 2.5038],\n",
      "        [-2.2768],\n",
      "        ...,\n",
      "        [ 1.8914],\n",
      "        [-0.4159],\n",
      "        [ 2.1832]]), tensor([[ 2.0333],\n",
      "        [ 2.3908],\n",
      "        [-2.3185],\n",
      "        ...,\n",
      "        [ 2.2850],\n",
      "        [-0.3172],\n",
      "        [ 2.2439]]), tensor([[-1.2289],\n",
      "        [ 0.2742],\n",
      "        [-1.1514],\n",
      "        ...,\n",
      "        [ 2.3705],\n",
      "        [ 1.6987],\n",
      "        [-2.4136]]), tensor([[-1.4510],\n",
      "        [-0.9236],\n",
      "        [ 1.6995],\n",
      "        ...,\n",
      "        [ 2.1812],\n",
      "        [ 2.4498],\n",
      "        [-2.4565]]), tensor([[-0.0456],\n",
      "        [ 2.3784],\n",
      "        [-2.3814],\n",
      "        ...,\n",
      "        [ 2.2901],\n",
      "        [ 0.2980],\n",
      "        [ 1.9051]]), tensor([[-1.1803],\n",
      "        [ 0.3472],\n",
      "        [ 1.9012],\n",
      "        ...,\n",
      "        [-0.1644],\n",
      "        [ 2.4395],\n",
      "        [-2.0996]]), tensor([[ 1.3414],\n",
      "        [ 2.3534],\n",
      "        [-2.3394],\n",
      "        ...,\n",
      "        [ 2.1347],\n",
      "        [ 0.1930],\n",
      "        [ 2.1064]]), tensor([[-1.2387],\n",
      "        [ 0.0834],\n",
      "        [ 1.9616],\n",
      "        ...,\n",
      "        [ 1.9684],\n",
      "        [ 1.7858],\n",
      "        [-2.2992]]), tensor([[-0.8229],\n",
      "        [ 1.6593],\n",
      "        [ 1.8984],\n",
      "        ...,\n",
      "        [ 2.2495],\n",
      "        [ 2.5682],\n",
      "        [-2.4889]]), tensor([[ 1.5856],\n",
      "        [ 2.2969],\n",
      "        [-2.4267],\n",
      "        ...,\n",
      "        [ 2.1976],\n",
      "        [ 0.3723],\n",
      "        [ 2.1574]]), tensor([[ 1.9124],\n",
      "        [ 2.3817],\n",
      "        [-2.4182],\n",
      "        ...,\n",
      "        [ 2.2266],\n",
      "        [ 1.4482],\n",
      "        [ 1.1132]]), tensor([[-1.3241],\n",
      "        [ 0.4564],\n",
      "        [ 1.7314],\n",
      "        ...,\n",
      "        [ 1.9236],\n",
      "        [ 2.1623],\n",
      "        [-2.4721]]), tensor([[-0.6209],\n",
      "        [ 2.2924],\n",
      "        [-2.3041],\n",
      "        ...,\n",
      "        [ 2.3286],\n",
      "        [-0.3494],\n",
      "        [ 2.3784]]), tensor([[ 2.1423],\n",
      "        [ 2.3133],\n",
      "        [-2.3216],\n",
      "        ...,\n",
      "        [ 2.2518],\n",
      "        [ 1.3916],\n",
      "        [ 2.2842]]), tensor([[ 1.6223],\n",
      "        [ 2.4577],\n",
      "        [-2.3628],\n",
      "        ...,\n",
      "        [ 1.9808],\n",
      "        [-0.3656],\n",
      "        [ 2.2815]]), tensor([[ 0.3344],\n",
      "        [ 2.3701],\n",
      "        [-2.2807],\n",
      "        ...,\n",
      "        [ 2.1714],\n",
      "        [-0.0815],\n",
      "        [ 1.6572]]), tensor([[ 1.4234],\n",
      "        [ 2.4771],\n",
      "        [-2.1278],\n",
      "        ...,\n",
      "        [ 2.1742],\n",
      "        [ 0.6407],\n",
      "        [ 1.5286]]), tensor([[ 2.0370],\n",
      "        [ 2.2962],\n",
      "        [-2.4494],\n",
      "        ...,\n",
      "        [ 2.2452],\n",
      "        [-0.3307],\n",
      "        [ 2.3830]]), tensor([[ 1.7379],\n",
      "        [ 2.3267],\n",
      "        [-2.3850],\n",
      "        ...,\n",
      "        [ 2.2432],\n",
      "        [ 0.3864],\n",
      "        [ 2.1911]]), tensor([[-0.5856],\n",
      "        [-0.8243],\n",
      "        [ 1.8093],\n",
      "        ...,\n",
      "        [ 1.4724],\n",
      "        [ 2.3279],\n",
      "        [-2.3659]]), tensor([[-1.4690],\n",
      "        [ 0.7946],\n",
      "        [ 1.5757],\n",
      "        ...,\n",
      "        [ 2.3369],\n",
      "        [ 2.3675],\n",
      "        [-2.3798]]), tensor([[ 0.8338],\n",
      "        [ 2.3047],\n",
      "        [-2.3119],\n",
      "        ...,\n",
      "        [ 2.2320],\n",
      "        [ 0.3665],\n",
      "        [ 1.8555]]), tensor([[ 0.6797],\n",
      "        [ 2.2685],\n",
      "        [-2.3087],\n",
      "        ...,\n",
      "        [ 2.1537],\n",
      "        [ 0.5019],\n",
      "        [ 1.7479]]), tensor([[ 1.8987],\n",
      "        [ 2.3293],\n",
      "        [-2.2630],\n",
      "        ...,\n",
      "        [ 1.9455],\n",
      "        [ 0.1098],\n",
      "        [ 2.2491]]), tensor([[-1.4389],\n",
      "        [-0.4573],\n",
      "        [ 2.0360],\n",
      "        ...,\n",
      "        [-1.6325],\n",
      "        [ 2.4444],\n",
      "        [-2.5509]]), tensor([[ 1.7206],\n",
      "        [ 2.2873],\n",
      "        [-2.3577],\n",
      "        ...,\n",
      "        [ 2.2271],\n",
      "        [ 0.1965],\n",
      "        [ 1.6058]]), tensor([[ 1.9754],\n",
      "        [ 2.2191],\n",
      "        [-2.4678],\n",
      "        ...,\n",
      "        [ 2.1625],\n",
      "        [ 0.7797],\n",
      "        [ 2.2405]]), tensor([[-0.0272],\n",
      "        [ 2.4068],\n",
      "        [-2.3514],\n",
      "        ...,\n",
      "        [ 2.2238],\n",
      "        [ 0.2391],\n",
      "        [ 2.2123]]), tensor([[ 0.7249],\n",
      "        [ 0.2638],\n",
      "        [ 0.2628],\n",
      "        ...,\n",
      "        [-1.7337],\n",
      "        [ 2.1814],\n",
      "        [-2.7019]]), tensor([[ 1.5211],\n",
      "        [ 2.5223],\n",
      "        [-1.8836],\n",
      "        ...,\n",
      "        [ 2.2705],\n",
      "        [ 0.7200],\n",
      "        [ 1.9702]]), tensor([[ 0.4051],\n",
      "        [ 2.4806],\n",
      "        [-2.2508],\n",
      "        ...,\n",
      "        [ 2.2989],\n",
      "        [ 0.3631],\n",
      "        [ 2.1977]]), tensor([[ 1.8844],\n",
      "        [ 2.3647],\n",
      "        [-2.3293],\n",
      "        ...,\n",
      "        [ 2.1551],\n",
      "        [-0.3581],\n",
      "        [ 2.2711]]), tensor([[-0.2163],\n",
      "        [-0.1151],\n",
      "        [-0.4822],\n",
      "        ...,\n",
      "        [ 2.5997],\n",
      "        [ 1.9013],\n",
      "        [-2.0964]]), tensor([[ 1.5743],\n",
      "        [ 2.4106],\n",
      "        [-2.3538],\n",
      "        ...,\n",
      "        [ 2.2706],\n",
      "        [ 0.1266],\n",
      "        [ 2.1241]]), tensor([[-1.5105],\n",
      "        [ 0.4726],\n",
      "        [ 1.0185],\n",
      "        ...,\n",
      "        [ 1.7821],\n",
      "        [ 2.4225],\n",
      "        [-2.5656]]), tensor([[-1.3527],\n",
      "        [ 0.5392],\n",
      "        [ 1.2234],\n",
      "        ...,\n",
      "        [ 2.2024],\n",
      "        [ 2.4437],\n",
      "        [-2.2804]]), tensor([[ 1.4616],\n",
      "        [ 2.1585],\n",
      "        [-2.3109],\n",
      "        ...,\n",
      "        [ 2.2316],\n",
      "        [-0.4621],\n",
      "        [ 1.4816]]), tensor([[ 1.9331],\n",
      "        [ 2.4297],\n",
      "        [-2.3160],\n",
      "        ...,\n",
      "        [ 2.2672],\n",
      "        [-0.3909],\n",
      "        [ 1.8376]]), tensor([[-1.6005],\n",
      "        [ 0.5513],\n",
      "        [ 1.6401],\n",
      "        ...,\n",
      "        [ 2.2998],\n",
      "        [ 2.5020],\n",
      "        [-2.3743]]), tensor([[-0.6559],\n",
      "        [ 2.3296],\n",
      "        [-2.0319],\n",
      "        ...,\n",
      "        [ 2.1491],\n",
      "        [ 0.2301],\n",
      "        [ 1.9727]]), tensor([[ 1.7194],\n",
      "        [ 2.3824],\n",
      "        [-2.3024],\n",
      "        ...,\n",
      "        [ 1.8275],\n",
      "        [-0.5013],\n",
      "        [ 1.6203]]), tensor([[-0.6481],\n",
      "        [-0.6384],\n",
      "        [ 1.1470],\n",
      "        ...,\n",
      "        [ 2.1246],\n",
      "        [ 2.1387],\n",
      "        [-2.4475]]), tensor([[ 2.1884],\n",
      "        [ 2.4015],\n",
      "        [-2.2609],\n",
      "        ...,\n",
      "        [ 2.0072],\n",
      "        [-0.0710],\n",
      "        [ 2.2279]]), tensor([[ 0.5002],\n",
      "        [ 2.2860],\n",
      "        [-2.2743],\n",
      "        ...,\n",
      "        [ 2.2608],\n",
      "        [ 0.3559],\n",
      "        [ 2.4683]]), tensor([[-1.4875],\n",
      "        [ 0.0071],\n",
      "        [ 1.1685],\n",
      "        ...,\n",
      "        [ 2.1021],\n",
      "        [ 2.4352],\n",
      "        [-2.2924]]), tensor([[-0.3343],\n",
      "        [-0.3815],\n",
      "        [ 1.3005],\n",
      "        ...,\n",
      "        [ 0.8118],\n",
      "        [ 2.3814],\n",
      "        [-2.5855]]), tensor([[-0.5908],\n",
      "        [-0.3785],\n",
      "        [-0.8203],\n",
      "        ...,\n",
      "        [ 1.8334],\n",
      "        [ 1.7901],\n",
      "        [-2.6977]]), tensor([[-1.5736],\n",
      "        [ 1.1336],\n",
      "        [ 1.4412],\n",
      "        ...,\n",
      "        [ 2.0583],\n",
      "        [ 2.4383],\n",
      "        [-2.3943]]), tensor([[-0.9316],\n",
      "        [ 2.4623],\n",
      "        [-2.3267],\n",
      "        ...,\n",
      "        [ 2.2215],\n",
      "        [-0.0987],\n",
      "        [ 2.1702]]), tensor([[-1.5670],\n",
      "        [-1.0992],\n",
      "        [ 1.5811],\n",
      "        ...,\n",
      "        [ 2.2609],\n",
      "        [ 2.4736],\n",
      "        [-2.4607]]), tensor([[-1.6807],\n",
      "        [ 0.2108],\n",
      "        [ 1.7245],\n",
      "        ...,\n",
      "        [ 2.0976],\n",
      "        [ 2.4772],\n",
      "        [-2.3602]])]\n",
      "Explainer::Iteration 2 of 10\n",
      "[tensor([[ 1.7709],\n",
      "        [ 2.3338],\n",
      "        [-2.4116],\n",
      "        ...,\n",
      "        [ 2.1414],\n",
      "        [ 0.3304],\n",
      "        [ 2.0132]]), tensor([[-1.4811],\n",
      "        [ 0.2972],\n",
      "        [ 2.0305],\n",
      "        ...,\n",
      "        [ 2.2758],\n",
      "        [ 2.4774],\n",
      "        [-2.4568]]), tensor([[ 0.4540],\n",
      "        [ 2.3992],\n",
      "        [-2.3877],\n",
      "        ...,\n",
      "        [ 2.2967],\n",
      "        [ 0.1793],\n",
      "        [ 2.0718]]), tensor([[ 2.1761],\n",
      "        [ 2.3423],\n",
      "        [-2.4210],\n",
      "        ...,\n",
      "        [ 2.0929],\n",
      "        [ 0.1808],\n",
      "        [ 1.4552]]), tensor([[ 1.6961],\n",
      "        [ 2.3967],\n",
      "        [-2.2102],\n",
      "        ...,\n",
      "        [ 1.5907],\n",
      "        [-0.2428],\n",
      "        [ 1.5406]]), tensor([[ 0.3572],\n",
      "        [ 2.4202],\n",
      "        [-2.2630],\n",
      "        ...,\n",
      "        [ 2.3023],\n",
      "        [ 0.0269],\n",
      "        [ 1.8827]]), tensor([[ 1.6824],\n",
      "        [ 2.2497],\n",
      "        [-2.2947],\n",
      "        ...,\n",
      "        [ 1.5767],\n",
      "        [-0.2781],\n",
      "        [ 2.2339]]), tensor([[ 1.8361],\n",
      "        [ 2.4087],\n",
      "        [-2.3392],\n",
      "        ...,\n",
      "        [ 2.2946],\n",
      "        [ 0.1201],\n",
      "        [ 1.6091]]), tensor([[-1.7505],\n",
      "        [ 0.2034],\n",
      "        [ 1.8422],\n",
      "        ...,\n",
      "        [ 2.3672],\n",
      "        [ 2.4267],\n",
      "        [-2.5616]]), tensor([[ 1.6722],\n",
      "        [ 2.2771],\n",
      "        [-2.3423],\n",
      "        ...,\n",
      "        [ 2.3389],\n",
      "        [-0.5566],\n",
      "        [ 1.8521]]), tensor([[ 2.2161],\n",
      "        [ 2.4540],\n",
      "        [-2.3769],\n",
      "        ...,\n",
      "        [ 2.2791],\n",
      "        [ 0.2128],\n",
      "        [ 1.7823]]), tensor([[ 1.6855],\n",
      "        [ 2.4559],\n",
      "        [-2.3921],\n",
      "        ...,\n",
      "        [ 2.1062],\n",
      "        [-0.0130],\n",
      "        [ 2.1478]]), tensor([[ 1.8773],\n",
      "        [ 2.3139],\n",
      "        [-2.4029],\n",
      "        ...,\n",
      "        [ 2.1898],\n",
      "        [ 0.2945],\n",
      "        [ 3.0094]]), tensor([[-1.5647],\n",
      "        [ 0.2700],\n",
      "        [ 0.8214],\n",
      "        ...,\n",
      "        [ 1.9638],\n",
      "        [ 2.0675],\n",
      "        [-2.5342]]), tensor([[-1.6022],\n",
      "        [ 0.2545],\n",
      "        [ 1.8203],\n",
      "        ...,\n",
      "        [ 1.7592],\n",
      "        [ 2.4367],\n",
      "        [-2.4213]]), tensor([[ 0.1392],\n",
      "        [-0.8414],\n",
      "        [-0.3198],\n",
      "        ...,\n",
      "        [ 2.5633],\n",
      "        [ 2.1012],\n",
      "        [-2.6198]]), tensor([[ 0.8403],\n",
      "        [ 2.3603],\n",
      "        [-2.3334],\n",
      "        ...,\n",
      "        [ 2.2415],\n",
      "        [ 0.2400],\n",
      "        [ 1.9204]]), tensor([[ 1.3509],\n",
      "        [ 2.2133],\n",
      "        [-2.3690],\n",
      "        ...,\n",
      "        [ 2.2947],\n",
      "        [ 0.3448],\n",
      "        [ 2.3656]]), tensor([[ 1.8512],\n",
      "        [ 2.3846],\n",
      "        [-2.3212],\n",
      "        ...,\n",
      "        [ 2.1309],\n",
      "        [-0.6777],\n",
      "        [ 2.0760]]), tensor([[-0.8933],\n",
      "        [ 1.3113],\n",
      "        [ 2.6436],\n",
      "        ...,\n",
      "        [ 0.9089],\n",
      "        [ 2.0758],\n",
      "        [-2.4059]]), tensor([[ 1.8633],\n",
      "        [ 2.3222],\n",
      "        [-2.3521],\n",
      "        ...,\n",
      "        [ 2.1161],\n",
      "        [-0.7442],\n",
      "        [ 2.3756]]), tensor([[ 1.9194],\n",
      "        [ 2.2525],\n",
      "        [-2.4305],\n",
      "        ...,\n",
      "        [ 1.8160],\n",
      "        [-0.0233],\n",
      "        [ 2.0707]]), tensor([[-0.9713],\n",
      "        [ 0.1645],\n",
      "        [ 1.9500],\n",
      "        ...,\n",
      "        [ 2.9761],\n",
      "        [ 2.4105],\n",
      "        [-2.4044]]), tensor([[-1.2678],\n",
      "        [ 1.1977],\n",
      "        [ 0.1410],\n",
      "        ...,\n",
      "        [ 2.2589],\n",
      "        [ 2.1575],\n",
      "        [-2.7692]]), tensor([[ 1.9414],\n",
      "        [ 2.2991],\n",
      "        [-2.2485],\n",
      "        ...,\n",
      "        [ 2.2381],\n",
      "        [ 0.0170],\n",
      "        [ 1.7037]]), tensor([[ 1.4712],\n",
      "        [ 2.3694],\n",
      "        [-2.3022],\n",
      "        ...,\n",
      "        [ 1.7769],\n",
      "        [-0.3812],\n",
      "        [ 2.0005]]), tensor([[ 1.3833],\n",
      "        [ 2.3334],\n",
      "        [-2.2759],\n",
      "        ...,\n",
      "        [ 2.1241],\n",
      "        [-0.6247],\n",
      "        [ 2.3779]]), tensor([[-1.1598],\n",
      "        [-0.8363],\n",
      "        [ 1.8562],\n",
      "        ...,\n",
      "        [ 2.2710],\n",
      "        [ 2.3925],\n",
      "        [-2.3246]]), tensor([[-1.3682],\n",
      "        [ 2.1934],\n",
      "        [ 0.0906],\n",
      "        ...,\n",
      "        [ 2.1858],\n",
      "        [ 2.3471],\n",
      "        [-2.3688]]), tensor([[ 1.5646],\n",
      "        [ 2.1691],\n",
      "        [-2.3345],\n",
      "        ...,\n",
      "        [ 1.8314],\n",
      "        [-1.4536],\n",
      "        [ 2.2323]]), tensor([[ 1.8648],\n",
      "        [ 2.3424],\n",
      "        [-2.3170],\n",
      "        ...,\n",
      "        [ 2.1100],\n",
      "        [-0.0753],\n",
      "        [ 2.4220]]), tensor([[-1.4403],\n",
      "        [ 0.2867],\n",
      "        [-1.3600],\n",
      "        ...,\n",
      "        [ 2.3681],\n",
      "        [ 1.6818],\n",
      "        [-2.5220]]), tensor([[-1.4852],\n",
      "        [-0.9248],\n",
      "        [ 1.7076],\n",
      "        ...,\n",
      "        [ 2.1254],\n",
      "        [ 2.4799],\n",
      "        [-2.2801]]), tensor([[-0.1794],\n",
      "        [ 2.2799],\n",
      "        [-2.2198],\n",
      "        ...,\n",
      "        [ 2.2326],\n",
      "        [ 0.0766],\n",
      "        [ 1.8218]]), tensor([[-1.3030],\n",
      "        [ 0.3408],\n",
      "        [ 1.9213],\n",
      "        ...,\n",
      "        [-0.2274],\n",
      "        [ 2.4427],\n",
      "        [-2.2622]]), tensor([[ 1.2957],\n",
      "        [ 2.4038],\n",
      "        [-2.3260],\n",
      "        ...,\n",
      "        [ 2.3433],\n",
      "        [ 0.1671],\n",
      "        [ 2.0603]]), tensor([[-1.2953],\n",
      "        [ 0.0163],\n",
      "        [ 0.8218],\n",
      "        ...,\n",
      "        [ 2.1533],\n",
      "        [ 1.8394],\n",
      "        [-2.2417]]), tensor([[-0.7775],\n",
      "        [ 1.6619],\n",
      "        [ 1.9240],\n",
      "        ...,\n",
      "        [ 2.3102],\n",
      "        [ 2.4586],\n",
      "        [-2.4166]]), tensor([[ 1.6085],\n",
      "        [ 2.3847],\n",
      "        [-2.1899],\n",
      "        ...,\n",
      "        [ 2.2716],\n",
      "        [ 0.3824],\n",
      "        [ 2.0860]]), tensor([[ 2.0160],\n",
      "        [ 2.3807],\n",
      "        [-2.3802],\n",
      "        ...,\n",
      "        [ 1.9665],\n",
      "        [-0.1515],\n",
      "        [ 1.0385]]), tensor([[-1.3648],\n",
      "        [ 0.4540],\n",
      "        [ 1.4998],\n",
      "        ...,\n",
      "        [ 1.9575],\n",
      "        [ 2.1105],\n",
      "        [-2.4058]]), tensor([[-0.3491],\n",
      "        [ 2.2810],\n",
      "        [-2.3500],\n",
      "        ...,\n",
      "        [ 2.2728],\n",
      "        [-0.2773],\n",
      "        [ 2.3202]]), tensor([[ 2.1568],\n",
      "        [ 2.3520],\n",
      "        [-2.3104],\n",
      "        ...,\n",
      "        [ 2.2652],\n",
      "        [ 2.8104],\n",
      "        [ 2.6374]]), tensor([[ 1.5290],\n",
      "        [ 2.3572],\n",
      "        [-2.3119],\n",
      "        ...,\n",
      "        [ 2.0185],\n",
      "        [-0.2079],\n",
      "        [ 2.7973]]), tensor([[ 0.3229],\n",
      "        [ 2.3571],\n",
      "        [-2.4392],\n",
      "        ...,\n",
      "        [ 2.1501],\n",
      "        [-0.0345],\n",
      "        [ 1.9808]]), tensor([[ 1.3638],\n",
      "        [ 2.4046],\n",
      "        [-2.2891],\n",
      "        ...,\n",
      "        [ 2.2371],\n",
      "        [ 0.6962],\n",
      "        [ 1.6021]]), tensor([[ 2.1590],\n",
      "        [ 2.4279],\n",
      "        [-2.2622],\n",
      "        ...,\n",
      "        [ 2.1652],\n",
      "        [-0.1887],\n",
      "        [ 2.2142]]), tensor([[ 1.8129],\n",
      "        [ 2.3495],\n",
      "        [-2.2589],\n",
      "        ...,\n",
      "        [ 2.2446],\n",
      "        [ 0.4373],\n",
      "        [ 2.2154]]), tensor([[-0.7476],\n",
      "        [-0.8263],\n",
      "        [ 1.7568],\n",
      "        ...,\n",
      "        [ 1.6460],\n",
      "        [ 2.3546],\n",
      "        [-2.3301]]), tensor([[-1.4971],\n",
      "        [ 0.7993],\n",
      "        [ 1.4560],\n",
      "        ...,\n",
      "        [ 2.1757],\n",
      "        [ 2.3928],\n",
      "        [-2.3295]]), tensor([[ 0.8786],\n",
      "        [ 2.2547],\n",
      "        [-2.2510],\n",
      "        ...,\n",
      "        [ 2.2757],\n",
      "        [ 0.4887],\n",
      "        [ 1.8954]]), tensor([[ 0.6068],\n",
      "        [ 2.3360],\n",
      "        [-2.3005],\n",
      "        ...,\n",
      "        [ 2.1485],\n",
      "        [ 0.6304],\n",
      "        [ 1.9326]]), tensor([[ 1.8124],\n",
      "        [ 2.3075],\n",
      "        [-2.3657],\n",
      "        ...,\n",
      "        [ 1.7792],\n",
      "        [-0.1021],\n",
      "        [ 2.0661]]), tensor([[-1.5475],\n",
      "        [-0.4577],\n",
      "        [ 2.1158],\n",
      "        ...,\n",
      "        [-1.6642],\n",
      "        [ 2.5498],\n",
      "        [-2.5451]]), tensor([[ 1.5958],\n",
      "        [ 2.3493],\n",
      "        [-2.2366],\n",
      "        ...,\n",
      "        [ 2.4778],\n",
      "        [ 0.1839],\n",
      "        [ 1.6068]]), tensor([[ 1.8087],\n",
      "        [ 2.3990],\n",
      "        [-2.4976],\n",
      "        ...,\n",
      "        [ 2.2921],\n",
      "        [ 0.6869],\n",
      "        [ 1.8292]]), tensor([[ 0.0070],\n",
      "        [ 2.4707],\n",
      "        [-2.3672],\n",
      "        ...,\n",
      "        [ 2.2397],\n",
      "        [ 0.1863],\n",
      "        [ 2.2282]]), tensor([[ 0.4558],\n",
      "        [ 0.1896],\n",
      "        [ 0.0375],\n",
      "        ...,\n",
      "        [-2.2580],\n",
      "        [ 2.2720],\n",
      "        [-2.5483]]), tensor([[ 1.5504],\n",
      "        [ 2.3566],\n",
      "        [-1.9132],\n",
      "        ...,\n",
      "        [ 2.2955],\n",
      "        [-0.0169],\n",
      "        [ 2.0034]]), tensor([[ 0.4342],\n",
      "        [ 2.3615],\n",
      "        [-2.2640],\n",
      "        ...,\n",
      "        [ 2.3273],\n",
      "        [ 0.3286],\n",
      "        [ 2.2741]]), tensor([[ 1.6915],\n",
      "        [ 2.4327],\n",
      "        [-2.2749],\n",
      "        ...,\n",
      "        [ 2.0626],\n",
      "        [-0.4690],\n",
      "        [ 1.9904]]), tensor([[-0.3709],\n",
      "        [-0.1001],\n",
      "        [-0.1842],\n",
      "        ...,\n",
      "        [ 2.5726],\n",
      "        [ 1.9479],\n",
      "        [-2.0957]]), tensor([[ 1.6217],\n",
      "        [ 2.2964],\n",
      "        [-2.4388],\n",
      "        ...,\n",
      "        [ 2.2200],\n",
      "        [ 0.2683],\n",
      "        [ 2.1469]]), tensor([[-1.5036],\n",
      "        [ 0.4771],\n",
      "        [ 0.8124],\n",
      "        ...,\n",
      "        [ 1.6841],\n",
      "        [ 2.5152],\n",
      "        [-2.4811]]), tensor([[-1.2568],\n",
      "        [ 0.5572],\n",
      "        [ 1.6138],\n",
      "        ...,\n",
      "        [ 2.2726],\n",
      "        [ 2.4617],\n",
      "        [-2.5191]]), tensor([[ 1.5952],\n",
      "        [ 2.3861],\n",
      "        [-2.3546],\n",
      "        ...,\n",
      "        [ 2.2841],\n",
      "        [-0.4834],\n",
      "        [ 1.3719]]), tensor([[ 1.8415],\n",
      "        [ 2.3936],\n",
      "        [-2.3122],\n",
      "        ...,\n",
      "        [ 2.1935],\n",
      "        [-0.4084],\n",
      "        [ 1.6844]]), tensor([[-1.6007],\n",
      "        [ 0.5854],\n",
      "        [ 1.5608],\n",
      "        ...,\n",
      "        [ 2.3983],\n",
      "        [ 2.5389],\n",
      "        [-2.5089]]), tensor([[-0.7416],\n",
      "        [ 2.3095],\n",
      "        [-1.4416],\n",
      "        ...,\n",
      "        [ 2.3068],\n",
      "        [-0.0034],\n",
      "        [ 2.0121]]), tensor([[ 1.7249],\n",
      "        [ 2.5058],\n",
      "        [-2.3543],\n",
      "        ...,\n",
      "        [ 1.9488],\n",
      "        [-0.5274],\n",
      "        [ 1.8305]]), tensor([[-0.7463],\n",
      "        [-0.6675],\n",
      "        [ 1.5787],\n",
      "        ...,\n",
      "        [ 2.0423],\n",
      "        [ 2.1816],\n",
      "        [-2.4891]]), tensor([[ 2.1728],\n",
      "        [ 2.3297],\n",
      "        [-2.3414],\n",
      "        ...,\n",
      "        [ 1.9340],\n",
      "        [-0.1087],\n",
      "        [ 1.6144]]), tensor([[ 0.5918],\n",
      "        [ 2.4451],\n",
      "        [-2.3075],\n",
      "        ...,\n",
      "        [ 2.1070],\n",
      "        [ 0.0345],\n",
      "        [ 2.4023]]), tensor([[-1.4505],\n",
      "        [-0.0142],\n",
      "        [ 1.1451],\n",
      "        ...,\n",
      "        [ 2.0678],\n",
      "        [ 2.4162],\n",
      "        [-2.4070]]), tensor([[-0.5771],\n",
      "        [-0.3737],\n",
      "        [ 1.2335],\n",
      "        ...,\n",
      "        [ 0.6510],\n",
      "        [ 2.3148],\n",
      "        [-2.4921]]), tensor([[-0.7702],\n",
      "        [-0.3852],\n",
      "        [-0.7167],\n",
      "        ...,\n",
      "        [ 2.1365],\n",
      "        [ 1.7949],\n",
      "        [-2.7265]]), tensor([[-1.4881],\n",
      "        [ 1.1501],\n",
      "        [ 1.2031],\n",
      "        ...,\n",
      "        [ 2.0197],\n",
      "        [ 2.5484],\n",
      "        [-2.3993]]), tensor([[-1.0967],\n",
      "        [ 2.3479],\n",
      "        [-2.3000],\n",
      "        ...,\n",
      "        [ 2.2012],\n",
      "        [-0.5042],\n",
      "        [ 2.0948]]), tensor([[-1.6159],\n",
      "        [-1.0834],\n",
      "        [ 1.4752],\n",
      "        ...,\n",
      "        [ 2.2437],\n",
      "        [ 2.4451],\n",
      "        [-2.4099]]), tensor([[-1.4575],\n",
      "        [ 0.2117],\n",
      "        [ 2.1192],\n",
      "        ...,\n",
      "        [ 2.1106],\n",
      "        [ 2.4200],\n",
      "        [-2.3508]])]\n",
      "Explainer::Iteration 3 of 10\n",
      "[tensor([[ 1.6413],\n",
      "        [ 2.3665],\n",
      "        [-2.3305],\n",
      "        ...,\n",
      "        [ 2.1224],\n",
      "        [ 0.3715],\n",
      "        [ 2.6888]]), tensor([[-1.5193],\n",
      "        [ 0.2918],\n",
      "        [ 1.9034],\n",
      "        ...,\n",
      "        [ 2.2266],\n",
      "        [ 2.3897],\n",
      "        [-2.4551]]), tensor([[ 0.6524],\n",
      "        [ 2.2952],\n",
      "        [-2.2865],\n",
      "        ...,\n",
      "        [ 2.1901],\n",
      "        [ 0.1427],\n",
      "        [ 2.0536]]), tensor([[ 2.0601],\n",
      "        [ 2.2611],\n",
      "        [-2.3901],\n",
      "        ...,\n",
      "        [ 2.0432],\n",
      "        [ 0.1743],\n",
      "        [ 1.4842]]), tensor([[ 1.8259],\n",
      "        [ 2.3243],\n",
      "        [-2.4037],\n",
      "        ...,\n",
      "        [ 1.5410],\n",
      "        [-0.3223],\n",
      "        [ 2.1393]]), tensor([[ 0.5745],\n",
      "        [ 2.2139],\n",
      "        [-2.2051],\n",
      "        ...,\n",
      "        [ 2.1888],\n",
      "        [ 0.0815],\n",
      "        [ 1.8817]]), tensor([[ 1.8189],\n",
      "        [ 2.2309],\n",
      "        [-2.2980],\n",
      "        ...,\n",
      "        [ 1.5451],\n",
      "        [-0.3406],\n",
      "        [ 3.1116]]), tensor([[ 2.1498],\n",
      "        [ 2.4636],\n",
      "        [-2.4493],\n",
      "        ...,\n",
      "        [ 2.2252],\n",
      "        [ 0.2960],\n",
      "        [ 1.4596]]), tensor([[-1.8652],\n",
      "        [ 0.1922],\n",
      "        [ 1.5936],\n",
      "        ...,\n",
      "        [ 2.4382],\n",
      "        [ 2.4044],\n",
      "        [-2.2828]]), tensor([[ 1.4754],\n",
      "        [ 2.3482],\n",
      "        [-2.3944],\n",
      "        ...,\n",
      "        [ 2.3033],\n",
      "        [-0.1469],\n",
      "        [ 1.9219]]), tensor([[ 2.1804],\n",
      "        [ 2.5411],\n",
      "        [-2.2898],\n",
      "        ...,\n",
      "        [ 2.2691],\n",
      "        [ 0.2383],\n",
      "        [ 1.7608]]), tensor([[ 1.7340],\n",
      "        [ 2.4547],\n",
      "        [-2.3354],\n",
      "        ...,\n",
      "        [ 2.1308],\n",
      "        [ 0.1232],\n",
      "        [ 2.3259]]), tensor([[ 1.9884],\n",
      "        [ 2.4174],\n",
      "        [-2.3143],\n",
      "        ...,\n",
      "        [ 2.2028],\n",
      "        [ 0.4224],\n",
      "        [ 2.8796]]), tensor([[-1.7733],\n",
      "        [ 0.2797],\n",
      "        [ 1.0196],\n",
      "        ...,\n",
      "        [ 2.0992],\n",
      "        [ 2.2723],\n",
      "        [-2.4722]]), tensor([[-1.6578],\n",
      "        [ 0.2387],\n",
      "        [ 1.8407],\n",
      "        ...,\n",
      "        [ 1.4603],\n",
      "        [ 2.4747],\n",
      "        [-2.3132]]), tensor([[-0.6224],\n",
      "        [-0.8079],\n",
      "        [-0.1629],\n",
      "        ...,\n",
      "        [ 2.5449],\n",
      "        [ 2.0617],\n",
      "        [-2.5653]]), tensor([[ 0.7827],\n",
      "        [ 2.3605],\n",
      "        [-2.3131],\n",
      "        ...,\n",
      "        [ 2.2051],\n",
      "        [ 0.2420],\n",
      "        [ 1.7860]]), tensor([[ 1.3138],\n",
      "        [ 2.3105],\n",
      "        [-2.2225],\n",
      "        ...,\n",
      "        [ 2.3436],\n",
      "        [ 0.3549],\n",
      "        [ 2.5599]]), tensor([[ 1.6881],\n",
      "        [ 2.4910],\n",
      "        [-2.3607],\n",
      "        ...,\n",
      "        [ 2.1364],\n",
      "        [-0.8128],\n",
      "        [ 2.0381]]), tensor([[-0.7996],\n",
      "        [ 1.3106],\n",
      "        [ 2.5816],\n",
      "        ...,\n",
      "        [ 1.0433],\n",
      "        [ 2.1190],\n",
      "        [-2.4857]]), tensor([[ 1.8589],\n",
      "        [ 2.4153],\n",
      "        [-2.3128],\n",
      "        ...,\n",
      "        [ 2.2646],\n",
      "        [-0.5038],\n",
      "        [ 2.3301]]), tensor([[ 1.9346],\n",
      "        [ 2.4731],\n",
      "        [-2.4535],\n",
      "        ...,\n",
      "        [ 1.9026],\n",
      "        [-0.0276],\n",
      "        [ 2.2210]]), tensor([[-0.7762],\n",
      "        [ 0.1625],\n",
      "        [ 1.8588],\n",
      "        ...,\n",
      "        [ 3.0221],\n",
      "        [ 2.3746],\n",
      "        [-2.4231]]), tensor([[-1.4066],\n",
      "        [ 1.2024],\n",
      "        [ 0.3144],\n",
      "        ...,\n",
      "        [ 2.2696],\n",
      "        [ 1.9633],\n",
      "        [-2.6034]]), tensor([[ 1.8022],\n",
      "        [ 2.3269],\n",
      "        [-2.3806],\n",
      "        ...,\n",
      "        [ 2.2769],\n",
      "        [-0.0166],\n",
      "        [ 1.6084]]), tensor([[ 1.4731],\n",
      "        [ 2.2429],\n",
      "        [-2.3047],\n",
      "        ...,\n",
      "        [ 1.6181],\n",
      "        [-0.4313],\n",
      "        [ 2.3416]]), tensor([[ 1.3129],\n",
      "        [ 2.3662],\n",
      "        [-2.3794],\n",
      "        ...,\n",
      "        [ 2.0624],\n",
      "        [-0.3846],\n",
      "        [ 1.9284]]), tensor([[-1.1898],\n",
      "        [-0.8355],\n",
      "        [ 1.8012],\n",
      "        ...,\n",
      "        [ 2.2796],\n",
      "        [ 2.5353],\n",
      "        [-2.3394]]), tensor([[-1.3019],\n",
      "        [ 2.1999],\n",
      "        [ 0.7036],\n",
      "        ...,\n",
      "        [ 2.2726],\n",
      "        [ 2.6069],\n",
      "        [-2.5580]]), tensor([[ 1.4906],\n",
      "        [ 2.2534],\n",
      "        [-2.3122],\n",
      "        ...,\n",
      "        [ 1.8642],\n",
      "        [-0.5558],\n",
      "        [ 2.3454]]), tensor([[ 1.8194],\n",
      "        [ 2.3370],\n",
      "        [-2.2292],\n",
      "        ...,\n",
      "        [ 2.1915],\n",
      "        [-0.2917],\n",
      "        [ 2.3965]]), tensor([[-1.4848],\n",
      "        [ 0.2794],\n",
      "        [-1.4883],\n",
      "        ...,\n",
      "        [ 2.3565],\n",
      "        [ 1.7888],\n",
      "        [-2.3482]]), tensor([[-1.3773],\n",
      "        [-0.9204],\n",
      "        [ 1.8949],\n",
      "        ...,\n",
      "        [ 2.1156],\n",
      "        [ 2.3948],\n",
      "        [-2.3263]]), tensor([[-0.3142],\n",
      "        [ 2.3137],\n",
      "        [-2.3382],\n",
      "        ...,\n",
      "        [ 2.2335],\n",
      "        [ 0.0488],\n",
      "        [ 2.1742]]), tensor([[-1.1769],\n",
      "        [ 0.3514],\n",
      "        [ 1.5354],\n",
      "        ...,\n",
      "        [-0.1179],\n",
      "        [ 2.3825],\n",
      "        [-2.2884]]), tensor([[ 1.1148],\n",
      "        [ 2.3282],\n",
      "        [-2.2449],\n",
      "        ...,\n",
      "        [ 2.2598],\n",
      "        [ 0.2695],\n",
      "        [ 1.9728]]), tensor([[-1.1729],\n",
      "        [ 0.1050],\n",
      "        [ 0.4590],\n",
      "        ...,\n",
      "        [ 2.2588],\n",
      "        [ 1.8315],\n",
      "        [-2.3564]]), tensor([[-1.0053],\n",
      "        [ 1.7243],\n",
      "        [ 1.8842],\n",
      "        ...,\n",
      "        [ 2.2842],\n",
      "        [ 2.4812],\n",
      "        [-2.4961]]), tensor([[ 1.5989],\n",
      "        [ 2.3860],\n",
      "        [-2.2153],\n",
      "        ...,\n",
      "        [ 2.2669],\n",
      "        [ 0.5496],\n",
      "        [ 1.9379]]), tensor([[ 2.0600],\n",
      "        [ 2.2429],\n",
      "        [-2.5385],\n",
      "        ...,\n",
      "        [ 1.9912],\n",
      "        [ 1.5711],\n",
      "        [ 1.4121]]), tensor([[-1.4401],\n",
      "        [ 0.4502],\n",
      "        [ 1.4825],\n",
      "        ...,\n",
      "        [ 1.9829],\n",
      "        [ 2.2102],\n",
      "        [-2.2876]]), tensor([[-0.7108],\n",
      "        [ 2.2710],\n",
      "        [-2.2626],\n",
      "        ...,\n",
      "        [ 2.2993],\n",
      "        [-0.2823],\n",
      "        [ 2.2720]]), tensor([[ 2.0861],\n",
      "        [ 2.3246],\n",
      "        [-2.2751],\n",
      "        ...,\n",
      "        [ 2.3810],\n",
      "        [ 1.5000],\n",
      "        [ 2.7411]]), tensor([[ 1.6482],\n",
      "        [ 2.3917],\n",
      "        [-2.2314],\n",
      "        ...,\n",
      "        [ 2.0715],\n",
      "        [-0.4408],\n",
      "        [ 2.2649]]), tensor([[ 0.3775],\n",
      "        [ 2.3300],\n",
      "        [-2.2921],\n",
      "        ...,\n",
      "        [ 2.2706],\n",
      "        [-0.1558],\n",
      "        [ 1.7869]]), tensor([[ 1.4346],\n",
      "        [ 2.3743],\n",
      "        [-2.3843],\n",
      "        ...,\n",
      "        [ 2.1731],\n",
      "        [ 0.7444],\n",
      "        [ 1.6646]]), tensor([[ 2.0344],\n",
      "        [ 2.3456],\n",
      "        [-2.3158],\n",
      "        ...,\n",
      "        [ 2.2246],\n",
      "        [ 0.2548],\n",
      "        [ 2.3652]]), tensor([[ 1.8456],\n",
      "        [ 2.3256],\n",
      "        [-2.3401],\n",
      "        ...,\n",
      "        [ 2.2759],\n",
      "        [ 0.2828],\n",
      "        [ 2.1570]]), tensor([[-0.5362],\n",
      "        [-0.7844],\n",
      "        [ 1.6796],\n",
      "        ...,\n",
      "        [ 1.7236],\n",
      "        [ 2.4662],\n",
      "        [-2.4159]]), tensor([[-1.5611],\n",
      "        [ 0.8052],\n",
      "        [ 1.4692],\n",
      "        ...,\n",
      "        [ 2.1731],\n",
      "        [ 2.3506],\n",
      "        [-2.4087]]), tensor([[ 0.8079],\n",
      "        [ 2.3489],\n",
      "        [-2.3582],\n",
      "        ...,\n",
      "        [ 2.2693],\n",
      "        [ 0.3854],\n",
      "        [ 1.7023]]), tensor([[ 0.5702],\n",
      "        [ 2.3465],\n",
      "        [-2.2780],\n",
      "        ...,\n",
      "        [ 2.1934],\n",
      "        [ 0.4227],\n",
      "        [ 1.9368]]), tensor([[ 1.8973],\n",
      "        [ 2.2854],\n",
      "        [-2.4301],\n",
      "        ...,\n",
      "        [ 1.8502],\n",
      "        [ 0.0705],\n",
      "        [ 2.2321]]), tensor([[-1.5571],\n",
      "        [-0.4645],\n",
      "        [ 2.1501],\n",
      "        ...,\n",
      "        [-1.6566],\n",
      "        [ 2.6190],\n",
      "        [-2.4325]]), tensor([[ 1.5984],\n",
      "        [ 2.3877],\n",
      "        [-2.2227],\n",
      "        ...,\n",
      "        [ 2.4063],\n",
      "        [ 0.1919],\n",
      "        [ 1.7093]]), tensor([[ 1.8692],\n",
      "        [ 2.3869],\n",
      "        [-2.4198],\n",
      "        ...,\n",
      "        [ 2.2895],\n",
      "        [ 0.4747],\n",
      "        [ 2.2599]]), tensor([[ 0.1331],\n",
      "        [ 2.3660],\n",
      "        [-2.2978],\n",
      "        ...,\n",
      "        [ 2.3038],\n",
      "        [ 0.3244],\n",
      "        [ 2.1629]]), tensor([[ 0.5431],\n",
      "        [ 0.2567],\n",
      "        [ 0.2000],\n",
      "        ...,\n",
      "        [-2.0195],\n",
      "        [ 2.3133],\n",
      "        [-2.5848]]), tensor([[ 1.4889],\n",
      "        [ 2.3416],\n",
      "        [-1.9143],\n",
      "        ...,\n",
      "        [ 2.2275],\n",
      "        [ 0.1837],\n",
      "        [ 1.9397]]), tensor([[ 0.2625],\n",
      "        [ 2.3983],\n",
      "        [-2.3634],\n",
      "        ...,\n",
      "        [ 2.2270],\n",
      "        [ 0.3956],\n",
      "        [ 2.2056]]), tensor([[ 1.5589],\n",
      "        [ 2.3548],\n",
      "        [-2.3053],\n",
      "        ...,\n",
      "        [ 2.1590],\n",
      "        [-0.4621],\n",
      "        [ 2.2621]]), tensor([[-0.2948],\n",
      "        [-0.1131],\n",
      "        [-0.1463],\n",
      "        ...,\n",
      "        [ 1.9899],\n",
      "        [ 1.9528],\n",
      "        [-2.0220]]), tensor([[ 1.5274],\n",
      "        [ 2.2713],\n",
      "        [-2.3182],\n",
      "        ...,\n",
      "        [ 2.2430],\n",
      "        [-0.4515],\n",
      "        [ 2.0805]]), tensor([[-1.5398],\n",
      "        [ 0.4552],\n",
      "        [ 0.9877],\n",
      "        ...,\n",
      "        [ 1.8866],\n",
      "        [ 2.3847],\n",
      "        [-2.5388]]), tensor([[-1.3199],\n",
      "        [ 0.5505],\n",
      "        [ 1.4423],\n",
      "        ...,\n",
      "        [ 2.2657],\n",
      "        [ 2.3521],\n",
      "        [-2.3934]]), tensor([[ 1.5813],\n",
      "        [ 2.3109],\n",
      "        [-2.3727],\n",
      "        ...,\n",
      "        [ 2.2940],\n",
      "        [-0.3624],\n",
      "        [ 1.5322]]), tensor([[ 1.8052],\n",
      "        [ 2.2466],\n",
      "        [-2.4078],\n",
      "        ...,\n",
      "        [ 2.2630],\n",
      "        [-0.3715],\n",
      "        [ 2.1108]]), tensor([[-1.6152],\n",
      "        [ 0.6221],\n",
      "        [ 1.6705],\n",
      "        ...,\n",
      "        [ 2.4079],\n",
      "        [ 2.5592],\n",
      "        [-2.4465]]), tensor([[-0.6880],\n",
      "        [ 2.3144],\n",
      "        [-1.9480],\n",
      "        ...,\n",
      "        [ 2.1838],\n",
      "        [ 0.0419],\n",
      "        [ 1.7721]]), tensor([[ 1.6270],\n",
      "        [ 2.3595],\n",
      "        [-2.3374],\n",
      "        ...,\n",
      "        [ 1.9079],\n",
      "        [-0.3476],\n",
      "        [ 1.7088]]), tensor([[-0.5825],\n",
      "        [-0.6546],\n",
      "        [ 1.4500],\n",
      "        ...,\n",
      "        [ 2.1112],\n",
      "        [ 2.1238],\n",
      "        [-2.3572]]), tensor([[ 2.1718],\n",
      "        [ 2.4407],\n",
      "        [-2.3336],\n",
      "        ...,\n",
      "        [ 1.9935],\n",
      "        [ 0.0387],\n",
      "        [ 1.5389]]), tensor([[ 0.5207],\n",
      "        [ 2.3536],\n",
      "        [-2.3521],\n",
      "        ...,\n",
      "        [ 2.3273],\n",
      "        [ 0.2036],\n",
      "        [ 2.3640]]), tensor([[-1.3409],\n",
      "        [-0.0071],\n",
      "        [ 1.3994],\n",
      "        ...,\n",
      "        [ 2.0902],\n",
      "        [ 2.4532],\n",
      "        [-2.5873]]), tensor([[-0.4398],\n",
      "        [-0.3943],\n",
      "        [ 1.2135],\n",
      "        ...,\n",
      "        [ 1.6679],\n",
      "        [ 2.3045],\n",
      "        [-2.4749]]), tensor([[-0.6715],\n",
      "        [-0.3892],\n",
      "        [-0.7605],\n",
      "        ...,\n",
      "        [ 1.9973],\n",
      "        [ 1.8619],\n",
      "        [-2.7332]]), tensor([[-1.7107],\n",
      "        [ 1.1395],\n",
      "        [ 1.5517],\n",
      "        ...,\n",
      "        [ 1.9343],\n",
      "        [ 2.5366],\n",
      "        [-2.4406]]), tensor([[-1.3123],\n",
      "        [ 2.3522],\n",
      "        [-2.2959],\n",
      "        ...,\n",
      "        [ 2.1494],\n",
      "        [-0.4131],\n",
      "        [ 2.1086]]), tensor([[-1.5762],\n",
      "        [-1.0811],\n",
      "        [ 1.6229],\n",
      "        ...,\n",
      "        [ 2.1226],\n",
      "        [ 2.3409],\n",
      "        [-2.4559]]), tensor([[-1.4943],\n",
      "        [ 0.2158],\n",
      "        [ 1.7736],\n",
      "        ...,\n",
      "        [ 2.3222],\n",
      "        [ 2.4039],\n",
      "        [-2.4989]])]\n",
      "Explainer::Iteration 4 of 10\n",
      "[tensor([[ 1.8583],\n",
      "        [ 2.4403],\n",
      "        [-2.3680],\n",
      "        ...,\n",
      "        [ 2.1919],\n",
      "        [ 0.4726],\n",
      "        [ 2.2620]]), tensor([[-1.7468],\n",
      "        [ 0.3016],\n",
      "        [ 1.8145],\n",
      "        ...,\n",
      "        [ 2.1703],\n",
      "        [ 2.3880],\n",
      "        [-2.4259]]), tensor([[ 0.5480],\n",
      "        [ 2.3677],\n",
      "        [-2.3887],\n",
      "        ...,\n",
      "        [ 2.2340],\n",
      "        [ 0.1191],\n",
      "        [ 2.0603]]), tensor([[ 1.9518],\n",
      "        [ 2.4201],\n",
      "        [-2.3316],\n",
      "        ...,\n",
      "        [ 1.9885],\n",
      "        [ 0.2593],\n",
      "        [ 1.3500]]), tensor([[ 1.9669],\n",
      "        [ 2.4024],\n",
      "        [-2.3241],\n",
      "        ...,\n",
      "        [ 1.5508],\n",
      "        [-0.3869],\n",
      "        [ 1.8147]]), tensor([[ 0.4762],\n",
      "        [ 2.3072],\n",
      "        [-2.2793],\n",
      "        ...,\n",
      "        [ 2.3773],\n",
      "        [-0.0499],\n",
      "        [ 1.6496]]), tensor([[ 1.5373],\n",
      "        [ 2.4009],\n",
      "        [-2.3769],\n",
      "        ...,\n",
      "        [ 1.5434],\n",
      "        [-0.3483],\n",
      "        [ 2.7579]]), tensor([[ 2.0033],\n",
      "        [ 2.3091],\n",
      "        [-2.2380],\n",
      "        ...,\n",
      "        [ 2.3522],\n",
      "        [ 0.1876],\n",
      "        [ 1.6073]]), tensor([[-1.6795],\n",
      "        [ 0.2097],\n",
      "        [ 1.5636],\n",
      "        ...,\n",
      "        [ 2.3239],\n",
      "        [ 2.3158],\n",
      "        [-2.1885]]), tensor([[ 1.5756],\n",
      "        [ 2.3426],\n",
      "        [-2.4307],\n",
      "        ...,\n",
      "        [ 2.3505],\n",
      "        [-0.4553],\n",
      "        [ 1.8717]]), tensor([[ 2.1209],\n",
      "        [ 2.2304],\n",
      "        [-2.2410],\n",
      "        ...,\n",
      "        [ 2.2596],\n",
      "        [ 0.0058],\n",
      "        [ 1.6604]]), tensor([[ 1.7879],\n",
      "        [ 2.3676],\n",
      "        [-2.3293],\n",
      "        ...,\n",
      "        [ 2.1990],\n",
      "        [ 0.1615],\n",
      "        [ 1.9491]]), tensor([[ 1.9187],\n",
      "        [ 2.3983],\n",
      "        [-2.4255],\n",
      "        ...,\n",
      "        [ 2.1477],\n",
      "        [-0.1243],\n",
      "        [ 2.8245]]), tensor([[-1.6001],\n",
      "        [ 0.2763],\n",
      "        [ 0.8438],\n",
      "        ...,\n",
      "        [ 2.0043],\n",
      "        [ 2.3320],\n",
      "        [-2.5024]]), tensor([[-1.6075],\n",
      "        [ 0.2572],\n",
      "        [ 1.6367],\n",
      "        ...,\n",
      "        [ 1.6860],\n",
      "        [ 2.3965],\n",
      "        [-2.3803]]), tensor([[ 0.0175],\n",
      "        [-0.8341],\n",
      "        [-0.2833],\n",
      "        ...,\n",
      "        [ 2.4535],\n",
      "        [ 1.9465],\n",
      "        [-2.7021]]), tensor([[ 0.8243],\n",
      "        [ 2.2937],\n",
      "        [-2.3109],\n",
      "        ...,\n",
      "        [ 2.3644],\n",
      "        [ 0.1997],\n",
      "        [ 1.6776]]), tensor([[ 1.2486],\n",
      "        [ 2.3197],\n",
      "        [-2.3732],\n",
      "        ...,\n",
      "        [ 2.2215],\n",
      "        [ 0.1374],\n",
      "        [ 2.6081]]), tensor([[ 1.6939],\n",
      "        [ 2.3565],\n",
      "        [-2.3782],\n",
      "        ...,\n",
      "        [ 2.0656],\n",
      "        [-0.4165],\n",
      "        [ 2.1445]]), tensor([[-0.8485],\n",
      "        [ 1.2940],\n",
      "        [ 2.5630],\n",
      "        ...,\n",
      "        [ 1.1042],\n",
      "        [ 2.1865],\n",
      "        [-2.5366]]), tensor([[ 1.8294],\n",
      "        [ 2.4040],\n",
      "        [-2.1873],\n",
      "        ...,\n",
      "        [ 2.1140],\n",
      "        [-0.9356],\n",
      "        [ 2.0107]]), tensor([[ 2.1232],\n",
      "        [ 2.3099],\n",
      "        [-2.3409],\n",
      "        ...,\n",
      "        [ 1.8656],\n",
      "        [-0.1214],\n",
      "        [ 2.1643]]), tensor([[-0.9202],\n",
      "        [ 0.1635],\n",
      "        [ 1.8495],\n",
      "        ...,\n",
      "        [ 3.1172],\n",
      "        [ 2.4743],\n",
      "        [-2.3253]]), tensor([[-1.4929],\n",
      "        [ 1.1956],\n",
      "        [ 0.3268],\n",
      "        ...,\n",
      "        [ 2.3222],\n",
      "        [ 2.1209],\n",
      "        [-2.5570]]), tensor([[ 2.0746],\n",
      "        [ 2.3741],\n",
      "        [-2.3530],\n",
      "        ...,\n",
      "        [ 2.1307],\n",
      "        [ 0.1456],\n",
      "        [ 1.7463]]), tensor([[ 1.5569],\n",
      "        [ 2.4187],\n",
      "        [-2.2715],\n",
      "        ...,\n",
      "        [ 1.7816],\n",
      "        [-0.3729],\n",
      "        [ 2.0550]]), tensor([[ 1.4889],\n",
      "        [ 2.3006],\n",
      "        [-2.4765],\n",
      "        ...,\n",
      "        [ 2.0618],\n",
      "        [-0.4704],\n",
      "        [ 2.4870]]), tensor([[-1.0515],\n",
      "        [-0.8375],\n",
      "        [ 1.8424],\n",
      "        ...,\n",
      "        [ 2.3075],\n",
      "        [ 2.3522],\n",
      "        [-2.3833]]), tensor([[-1.2779],\n",
      "        [ 2.2395],\n",
      "        [ 0.2484],\n",
      "        ...,\n",
      "        [ 2.2155],\n",
      "        [ 2.5072],\n",
      "        [-2.6244]]), tensor([[ 1.4209],\n",
      "        [ 2.3189],\n",
      "        [-2.2952],\n",
      "        ...,\n",
      "        [ 1.8535],\n",
      "        [-1.0312],\n",
      "        [ 2.1452]]), tensor([[ 1.8399],\n",
      "        [ 2.2838],\n",
      "        [-2.3565],\n",
      "        ...,\n",
      "        [ 2.1761],\n",
      "        [-0.3094],\n",
      "        [ 2.3370]]), tensor([[-1.5218],\n",
      "        [ 0.2897],\n",
      "        [-1.2510],\n",
      "        ...,\n",
      "        [ 2.3551],\n",
      "        [ 1.7364],\n",
      "        [-2.2247]]), tensor([[-1.3538],\n",
      "        [-0.9242],\n",
      "        [ 1.9807],\n",
      "        ...,\n",
      "        [ 2.0294],\n",
      "        [ 2.3868],\n",
      "        [-2.3492]]), tensor([[-0.4170],\n",
      "        [ 2.4080],\n",
      "        [-2.1942],\n",
      "        ...,\n",
      "        [ 2.2501],\n",
      "        [ 0.0783],\n",
      "        [ 1.8753]]), tensor([[-1.2511],\n",
      "        [ 0.3495],\n",
      "        [ 1.7354],\n",
      "        ...,\n",
      "        [-0.0269],\n",
      "        [ 2.5554],\n",
      "        [-2.1861]]), tensor([[ 1.3245],\n",
      "        [ 2.3081],\n",
      "        [-2.2610],\n",
      "        ...,\n",
      "        [ 2.2717],\n",
      "        [ 0.1232],\n",
      "        [ 2.0195]]), tensor([[-1.0769],\n",
      "        [ 0.0752],\n",
      "        [ 2.4410],\n",
      "        ...,\n",
      "        [ 2.0802],\n",
      "        [ 1.8614],\n",
      "        [-2.2878]]), tensor([[-0.9323],\n",
      "        [ 1.6664],\n",
      "        [ 1.7202],\n",
      "        ...,\n",
      "        [ 2.4093],\n",
      "        [ 2.3663],\n",
      "        [-2.4144]]), tensor([[ 1.6326],\n",
      "        [ 2.3351],\n",
      "        [-2.2575],\n",
      "        ...,\n",
      "        [ 2.2257],\n",
      "        [ 0.3975],\n",
      "        [ 2.2566]]), tensor([[ 1.8785],\n",
      "        [ 2.3631],\n",
      "        [-2.3862],\n",
      "        ...,\n",
      "        [ 2.0244],\n",
      "        [ 1.6906],\n",
      "        [ 1.0807]]), tensor([[-1.3451],\n",
      "        [ 0.4514],\n",
      "        [ 1.6603],\n",
      "        ...,\n",
      "        [ 2.0752],\n",
      "        [ 2.0370],\n",
      "        [-2.4418]]), tensor([[-0.3840],\n",
      "        [ 2.2299],\n",
      "        [-2.3268],\n",
      "        ...,\n",
      "        [ 2.2203],\n",
      "        [-0.3018],\n",
      "        [ 2.1787]]), tensor([[ 2.1157],\n",
      "        [ 2.3918],\n",
      "        [-2.2478],\n",
      "        ...,\n",
      "        [ 2.3075],\n",
      "        [ 1.4208],\n",
      "        [ 2.5292]]), tensor([[ 1.6120],\n",
      "        [ 2.2886],\n",
      "        [-2.3936],\n",
      "        ...,\n",
      "        [ 2.0364],\n",
      "        [-1.1544],\n",
      "        [ 2.1017]]), tensor([[ 0.5367],\n",
      "        [ 2.3827],\n",
      "        [-2.3205],\n",
      "        ...,\n",
      "        [ 2.2399],\n",
      "        [ 0.4028],\n",
      "        [ 1.5269]]), tensor([[ 1.4203],\n",
      "        [ 2.2680],\n",
      "        [-2.3000],\n",
      "        ...,\n",
      "        [ 2.3212],\n",
      "        [ 0.6666],\n",
      "        [ 1.5638]]), tensor([[ 2.1260],\n",
      "        [ 2.3905],\n",
      "        [-2.3253],\n",
      "        ...,\n",
      "        [ 2.1242],\n",
      "        [-0.3113],\n",
      "        [ 1.8996]]), tensor([[ 1.8157],\n",
      "        [ 2.4131],\n",
      "        [-2.3765],\n",
      "        ...,\n",
      "        [ 2.2474],\n",
      "        [ 0.0755],\n",
      "        [ 2.2548]]), tensor([[-0.5984],\n",
      "        [-0.8161],\n",
      "        [ 1.6281],\n",
      "        ...,\n",
      "        [ 1.5814],\n",
      "        [ 2.3378],\n",
      "        [-2.2199]]), tensor([[-1.4944],\n",
      "        [ 0.7938],\n",
      "        [ 1.6575],\n",
      "        ...,\n",
      "        [ 2.2797],\n",
      "        [ 2.4820],\n",
      "        [-2.3909]]), tensor([[ 0.8048],\n",
      "        [ 2.3208],\n",
      "        [-2.2993],\n",
      "        ...,\n",
      "        [ 2.2629],\n",
      "        [ 0.4400],\n",
      "        [ 2.0272]]), tensor([[ 0.5940],\n",
      "        [ 2.5156],\n",
      "        [-2.2559],\n",
      "        ...,\n",
      "        [ 2.1887],\n",
      "        [ 0.5207],\n",
      "        [ 1.7989]]), tensor([[ 2.0165],\n",
      "        [ 2.3266],\n",
      "        [-2.3319],\n",
      "        ...,\n",
      "        [ 2.0726],\n",
      "        [ 0.0742],\n",
      "        [ 1.6532]]), tensor([[-1.4876],\n",
      "        [-0.4452],\n",
      "        [ 2.1076],\n",
      "        ...,\n",
      "        [-1.6180],\n",
      "        [ 2.6306],\n",
      "        [-2.5181]]), tensor([[ 1.3991],\n",
      "        [ 2.3978],\n",
      "        [-2.2872],\n",
      "        ...,\n",
      "        [ 2.2959],\n",
      "        [ 0.1812],\n",
      "        [ 1.6095]]), tensor([[ 1.8699],\n",
      "        [ 2.3122],\n",
      "        [-2.4794],\n",
      "        ...,\n",
      "        [ 2.4474],\n",
      "        [ 0.4959],\n",
      "        [ 2.2941]]), tensor([[ 0.0343],\n",
      "        [ 2.4635],\n",
      "        [-2.3500],\n",
      "        ...,\n",
      "        [ 2.2437],\n",
      "        [ 0.2710],\n",
      "        [ 2.0929]]), tensor([[ 0.6440],\n",
      "        [ 0.2260],\n",
      "        [ 0.1714],\n",
      "        ...,\n",
      "        [-2.1665],\n",
      "        [ 2.2391],\n",
      "        [-2.3956]]), tensor([[ 1.5056],\n",
      "        [ 2.3723],\n",
      "        [-1.8129],\n",
      "        ...,\n",
      "        [ 2.2812],\n",
      "        [-0.2272],\n",
      "        [ 1.9030]]), tensor([[ 0.4543],\n",
      "        [ 2.3204],\n",
      "        [-2.2755],\n",
      "        ...,\n",
      "        [ 2.2791],\n",
      "        [ 0.3657],\n",
      "        [ 2.1779]]), tensor([[ 1.8326],\n",
      "        [ 2.3635],\n",
      "        [-2.2354],\n",
      "        ...,\n",
      "        [ 2.1867],\n",
      "        [-0.4445],\n",
      "        [ 2.2656]]), tensor([[-0.3928],\n",
      "        [-0.1448],\n",
      "        [-0.3641],\n",
      "        ...,\n",
      "        [ 2.0908],\n",
      "        [ 1.8920],\n",
      "        [-2.0675]]), tensor([[ 1.6354],\n",
      "        [ 2.3527],\n",
      "        [-2.2721],\n",
      "        ...,\n",
      "        [ 2.2373],\n",
      "        [ 0.4107],\n",
      "        [ 2.1870]]), tensor([[-1.5328],\n",
      "        [ 0.4614],\n",
      "        [ 1.0080],\n",
      "        ...,\n",
      "        [ 1.7409],\n",
      "        [ 2.4369],\n",
      "        [-2.6109]]), tensor([[-1.4661],\n",
      "        [ 0.5492],\n",
      "        [ 1.3125],\n",
      "        ...,\n",
      "        [ 2.2642],\n",
      "        [ 2.3742],\n",
      "        [-2.3938]]), tensor([[ 1.5486],\n",
      "        [ 2.2999],\n",
      "        [-2.3829],\n",
      "        ...,\n",
      "        [ 2.1622],\n",
      "        [-0.4492],\n",
      "        [ 1.4556]]), tensor([[ 1.7968],\n",
      "        [ 2.3384],\n",
      "        [-2.2825],\n",
      "        ...,\n",
      "        [ 2.3998],\n",
      "        [-0.2895],\n",
      "        [ 1.8022]]), tensor([[-1.7192],\n",
      "        [ 0.5215],\n",
      "        [ 1.7056],\n",
      "        ...,\n",
      "        [ 2.4144],\n",
      "        [ 2.4963],\n",
      "        [-2.5034]]), tensor([[-0.7634],\n",
      "        [ 2.3086],\n",
      "        [-1.8527],\n",
      "        ...,\n",
      "        [ 2.1305],\n",
      "        [ 0.4231],\n",
      "        [ 1.9700]]), tensor([[ 1.7030],\n",
      "        [ 2.3758],\n",
      "        [-2.3719],\n",
      "        ...,\n",
      "        [ 1.8980],\n",
      "        [-0.4970],\n",
      "        [ 1.4770]]), tensor([[-0.4785],\n",
      "        [-0.6683],\n",
      "        [ 1.4790],\n",
      "        ...,\n",
      "        [ 2.1883],\n",
      "        [ 2.1976],\n",
      "        [-2.5612]]), tensor([[ 2.2160],\n",
      "        [ 2.4005],\n",
      "        [-2.3376],\n",
      "        ...,\n",
      "        [ 1.9744],\n",
      "        [-0.0642],\n",
      "        [ 1.5759]]), tensor([[ 0.4456],\n",
      "        [ 2.2483],\n",
      "        [-2.3676],\n",
      "        ...,\n",
      "        [ 2.2489],\n",
      "        [ 0.1330],\n",
      "        [ 2.2483]]), tensor([[-1.4657e+00],\n",
      "        [-9.9668e-04],\n",
      "        [ 1.1049e+00],\n",
      "        ...,\n",
      "        [ 2.1373e+00],\n",
      "        [ 2.5175e+00],\n",
      "        [-2.3181e+00]]), tensor([[-0.3696],\n",
      "        [-0.3780],\n",
      "        [ 1.0841],\n",
      "        ...,\n",
      "        [ 0.8040],\n",
      "        [ 2.3453],\n",
      "        [-2.4216]]), tensor([[-0.6716],\n",
      "        [-0.3772],\n",
      "        [-0.7206],\n",
      "        ...,\n",
      "        [ 2.0339],\n",
      "        [ 1.9096],\n",
      "        [-2.6987]]), tensor([[-1.6347],\n",
      "        [ 1.1468],\n",
      "        [ 1.2536],\n",
      "        ...,\n",
      "        [ 2.0446],\n",
      "        [ 2.3960],\n",
      "        [-2.4271]]), tensor([[-1.1242],\n",
      "        [ 2.3931],\n",
      "        [-2.2830],\n",
      "        ...,\n",
      "        [ 2.2329],\n",
      "        [-0.7094],\n",
      "        [ 1.9006]]), tensor([[-1.6132],\n",
      "        [-1.0838],\n",
      "        [ 1.6600],\n",
      "        ...,\n",
      "        [ 2.1924],\n",
      "        [ 2.3267],\n",
      "        [-2.5364]]), tensor([[-1.6765],\n",
      "        [ 0.2238],\n",
      "        [ 1.9047],\n",
      "        ...,\n",
      "        [ 2.1608],\n",
      "        [ 2.5095],\n",
      "        [-2.3975]])]\n",
      "Explainer::Iteration 5 of 10\n",
      "[tensor([[ 1.7066],\n",
      "        [ 2.4226],\n",
      "        [-2.3974],\n",
      "        ...,\n",
      "        [ 2.2504],\n",
      "        [ 0.3854],\n",
      "        [ 2.2123]]), tensor([[-1.4976],\n",
      "        [ 0.3005],\n",
      "        [ 1.8446],\n",
      "        ...,\n",
      "        [ 2.2798],\n",
      "        [ 2.3785],\n",
      "        [-2.3486]]), tensor([[ 0.3448],\n",
      "        [ 2.3762],\n",
      "        [-2.3581],\n",
      "        ...,\n",
      "        [ 2.1705],\n",
      "        [ 0.2125],\n",
      "        [ 2.1551]]), tensor([[ 2.0202],\n",
      "        [ 2.3556],\n",
      "        [-2.3676],\n",
      "        ...,\n",
      "        [ 2.1554],\n",
      "        [ 0.2130],\n",
      "        [ 1.3928]]), tensor([[ 1.7292],\n",
      "        [ 2.3098],\n",
      "        [-2.2253],\n",
      "        ...,\n",
      "        [ 1.4545],\n",
      "        [-0.3533],\n",
      "        [ 2.2115]]), tensor([[ 0.4850],\n",
      "        [ 2.4204],\n",
      "        [-2.2102],\n",
      "        ...,\n",
      "        [ 2.2424],\n",
      "        [ 0.2024],\n",
      "        [ 1.8426]]), tensor([[ 1.6060],\n",
      "        [ 2.3502],\n",
      "        [-2.2266],\n",
      "        ...,\n",
      "        [ 1.5308],\n",
      "        [-0.3759],\n",
      "        [ 3.0450]]), tensor([[ 2.0139],\n",
      "        [ 2.4116],\n",
      "        [-2.2363],\n",
      "        ...,\n",
      "        [ 2.2366],\n",
      "        [ 0.2824],\n",
      "        [ 1.5570]]), tensor([[-1.5928],\n",
      "        [ 0.2134],\n",
      "        [ 1.7755],\n",
      "        ...,\n",
      "        [ 2.2437],\n",
      "        [ 2.4170],\n",
      "        [-2.2891]]), tensor([[ 1.5636],\n",
      "        [ 2.4113],\n",
      "        [-2.2622],\n",
      "        ...,\n",
      "        [ 2.2223],\n",
      "        [-0.0770],\n",
      "        [ 1.9502]]), tensor([[ 2.2378],\n",
      "        [ 2.3876],\n",
      "        [-2.2601],\n",
      "        ...,\n",
      "        [ 2.4153],\n",
      "        [ 0.1709],\n",
      "        [ 1.7242]]), tensor([[ 1.5897],\n",
      "        [ 2.4870],\n",
      "        [-2.3101],\n",
      "        ...,\n",
      "        [ 2.2505],\n",
      "        [ 0.0614],\n",
      "        [ 2.2790]]), tensor([[ 1.9469],\n",
      "        [ 2.3267],\n",
      "        [-2.2940],\n",
      "        ...,\n",
      "        [ 2.1667],\n",
      "        [ 0.0649],\n",
      "        [ 3.0597]]), tensor([[-1.6936],\n",
      "        [ 0.2713],\n",
      "        [ 0.8377],\n",
      "        ...,\n",
      "        [ 2.0748],\n",
      "        [ 2.2342],\n",
      "        [-2.5359]]), tensor([[-1.7964],\n",
      "        [ 0.2442],\n",
      "        [ 1.5976],\n",
      "        ...,\n",
      "        [ 1.6957],\n",
      "        [ 2.4223],\n",
      "        [-2.4433]]), tensor([[-0.1441],\n",
      "        [-0.8127],\n",
      "        [-0.4779],\n",
      "        ...,\n",
      "        [ 2.6337],\n",
      "        [ 2.0114],\n",
      "        [-2.7236]]), tensor([[ 0.8331],\n",
      "        [ 2.3508],\n",
      "        [-2.3504],\n",
      "        ...,\n",
      "        [ 2.2629],\n",
      "        [ 0.2779],\n",
      "        [ 1.6823]]), tensor([[ 1.2846],\n",
      "        [ 2.2610],\n",
      "        [-2.4162],\n",
      "        ...,\n",
      "        [ 2.3170],\n",
      "        [ 0.2881],\n",
      "        [ 2.1929]]), tensor([[ 1.7923],\n",
      "        [ 2.4217],\n",
      "        [-2.3012],\n",
      "        ...,\n",
      "        [ 1.9911],\n",
      "        [-0.4690],\n",
      "        [ 2.1020]]), tensor([[-0.9180],\n",
      "        [ 1.3174],\n",
      "        [ 2.6373],\n",
      "        ...,\n",
      "        [ 0.8124],\n",
      "        [ 1.8840],\n",
      "        [-2.4819]]), tensor([[ 1.8699],\n",
      "        [ 2.3545],\n",
      "        [-2.3185],\n",
      "        ...,\n",
      "        [ 2.2307],\n",
      "        [-0.9846],\n",
      "        [ 2.2524]]), tensor([[ 1.9584],\n",
      "        [ 2.3454],\n",
      "        [-2.3708],\n",
      "        ...,\n",
      "        [ 1.8602],\n",
      "        [-0.0302],\n",
      "        [ 2.1857]]), tensor([[-0.8380],\n",
      "        [ 0.1624],\n",
      "        [ 1.8911],\n",
      "        ...,\n",
      "        [ 3.0515],\n",
      "        [ 2.3901],\n",
      "        [-2.3306]]), tensor([[-1.5728],\n",
      "        [ 1.1785],\n",
      "        [ 0.1311],\n",
      "        ...,\n",
      "        [ 2.2298],\n",
      "        [ 2.1826],\n",
      "        [-2.6815]]), tensor([[ 2.0539],\n",
      "        [ 2.4004],\n",
      "        [-2.2245],\n",
      "        ...,\n",
      "        [ 2.2200],\n",
      "        [ 0.0172],\n",
      "        [ 1.7442]]), tensor([[ 1.5722],\n",
      "        [ 2.3346],\n",
      "        [-2.3764],\n",
      "        ...,\n",
      "        [ 1.6085],\n",
      "        [-0.3233],\n",
      "        [ 2.5430]]), tensor([[ 1.5250],\n",
      "        [ 2.3221],\n",
      "        [-2.2185],\n",
      "        ...,\n",
      "        [ 2.0941],\n",
      "        [-0.4211],\n",
      "        [ 1.9545]]), tensor([[-1.0748],\n",
      "        [-0.8360],\n",
      "        [ 1.8113],\n",
      "        ...,\n",
      "        [ 2.1789],\n",
      "        [ 2.3279],\n",
      "        [-2.2961]]), tensor([[-1.2442],\n",
      "        [ 2.3008],\n",
      "        [ 0.3787],\n",
      "        ...,\n",
      "        [ 2.2118],\n",
      "        [ 2.4817],\n",
      "        [-2.5208]]), tensor([[ 1.5874],\n",
      "        [ 2.3860],\n",
      "        [-2.2796],\n",
      "        ...,\n",
      "        [ 1.8764],\n",
      "        [-1.1035],\n",
      "        [ 2.1332]]), tensor([[ 1.8677],\n",
      "        [ 2.3310],\n",
      "        [-2.3508],\n",
      "        ...,\n",
      "        [ 2.1221],\n",
      "        [-0.2276],\n",
      "        [ 2.4253]]), tensor([[-1.3103],\n",
      "        [ 0.2929],\n",
      "        [-1.0792],\n",
      "        ...,\n",
      "        [ 2.4741],\n",
      "        [ 1.7644],\n",
      "        [-2.3607]]), tensor([[-1.3831],\n",
      "        [-0.9257],\n",
      "        [ 1.8813],\n",
      "        ...,\n",
      "        [ 2.0975],\n",
      "        [ 2.3201],\n",
      "        [-2.3261]]), tensor([[-0.1922],\n",
      "        [ 2.4013],\n",
      "        [-2.2517],\n",
      "        ...,\n",
      "        [ 2.2620],\n",
      "        [ 0.1627],\n",
      "        [ 1.7518]]), tensor([[-1.3205],\n",
      "        [ 0.3438],\n",
      "        [ 1.7475],\n",
      "        ...,\n",
      "        [-0.1892],\n",
      "        [ 2.3446],\n",
      "        [-2.1967]]), tensor([[ 1.0913],\n",
      "        [ 2.3322],\n",
      "        [-2.2468],\n",
      "        ...,\n",
      "        [ 2.1440],\n",
      "        [ 0.2125],\n",
      "        [ 2.1483]]), tensor([[-0.9900],\n",
      "        [ 0.0786],\n",
      "        [ 1.2915],\n",
      "        ...,\n",
      "        [ 2.2707],\n",
      "        [ 1.8158],\n",
      "        [-2.3148]]), tensor([[-1.0377],\n",
      "        [ 1.7898],\n",
      "        [ 1.9122],\n",
      "        ...,\n",
      "        [ 2.1686],\n",
      "        [ 2.5081],\n",
      "        [-2.4748]]), tensor([[ 1.5815],\n",
      "        [ 2.2590],\n",
      "        [-2.2991],\n",
      "        ...,\n",
      "        [ 2.2726],\n",
      "        [ 0.3437],\n",
      "        [ 2.1007]]), tensor([[ 2.0548],\n",
      "        [ 2.2543],\n",
      "        [-2.3282],\n",
      "        ...,\n",
      "        [ 2.0434],\n",
      "        [ 1.4932],\n",
      "        [ 1.1156]]), tensor([[-1.3009],\n",
      "        [ 0.4523],\n",
      "        [ 1.6893],\n",
      "        ...,\n",
      "        [ 2.0048],\n",
      "        [ 2.0503],\n",
      "        [-2.4430]]), tensor([[-0.4995],\n",
      "        [ 2.2779],\n",
      "        [-2.3142],\n",
      "        ...,\n",
      "        [ 2.2666],\n",
      "        [-0.3198],\n",
      "        [ 2.0782]]), tensor([[ 2.2333],\n",
      "        [ 2.4571],\n",
      "        [-2.2525],\n",
      "        ...,\n",
      "        [ 2.3090],\n",
      "        [ 1.4999],\n",
      "        [ 2.7780]]), tensor([[ 1.6657],\n",
      "        [ 2.3363],\n",
      "        [-2.2805],\n",
      "        ...,\n",
      "        [ 2.1755],\n",
      "        [-0.5382],\n",
      "        [ 2.4339]]), tensor([[ 0.4292],\n",
      "        [ 2.3432],\n",
      "        [-2.3024],\n",
      "        ...,\n",
      "        [ 2.2373],\n",
      "        [ 0.5228],\n",
      "        [ 2.0933]]), tensor([[ 1.4145],\n",
      "        [ 2.4518],\n",
      "        [-2.3546],\n",
      "        ...,\n",
      "        [ 2.2287],\n",
      "        [ 0.6763],\n",
      "        [ 1.6075]]), tensor([[ 2.1675],\n",
      "        [ 2.3817],\n",
      "        [-2.4037],\n",
      "        ...,\n",
      "        [ 2.1102],\n",
      "        [-0.2682],\n",
      "        [ 2.2759]]), tensor([[ 1.8056],\n",
      "        [ 2.4458],\n",
      "        [-2.2840],\n",
      "        ...,\n",
      "        [ 2.3967],\n",
      "        [ 0.2828],\n",
      "        [ 2.1392]]), tensor([[-0.5573],\n",
      "        [-0.8003],\n",
      "        [ 1.5216],\n",
      "        ...,\n",
      "        [ 1.5161],\n",
      "        [ 2.3494],\n",
      "        [-2.3056]]), tensor([[-1.4953],\n",
      "        [ 0.7926],\n",
      "        [ 1.4203],\n",
      "        ...,\n",
      "        [ 2.2580],\n",
      "        [ 2.3656],\n",
      "        [-2.3461]]), tensor([[ 0.9156],\n",
      "        [ 2.3138],\n",
      "        [-2.3725],\n",
      "        ...,\n",
      "        [ 2.1993],\n",
      "        [ 0.3331],\n",
      "        [ 1.8113]]), tensor([[ 0.6924],\n",
      "        [ 2.3223],\n",
      "        [-2.3706],\n",
      "        ...,\n",
      "        [ 2.1306],\n",
      "        [ 0.4653],\n",
      "        [ 1.8964]]), tensor([[ 2.0632],\n",
      "        [ 2.3814],\n",
      "        [-2.3069],\n",
      "        ...,\n",
      "        [ 1.8497],\n",
      "        [ 0.0957],\n",
      "        [ 2.1592]]), tensor([[-1.5224],\n",
      "        [-0.4599],\n",
      "        [ 2.0450],\n",
      "        ...,\n",
      "        [-1.6059],\n",
      "        [ 2.6342],\n",
      "        [-2.4792]]), tensor([[ 1.5138],\n",
      "        [ 2.4138],\n",
      "        [-2.3452],\n",
      "        ...,\n",
      "        [ 2.3426],\n",
      "        [ 0.2804],\n",
      "        [ 1.6061]]), tensor([[ 1.7091],\n",
      "        [ 2.3181],\n",
      "        [-2.4611],\n",
      "        ...,\n",
      "        [ 2.2714],\n",
      "        [ 0.5457],\n",
      "        [ 1.9473]]), tensor([[ 0.0789],\n",
      "        [ 2.4188],\n",
      "        [-2.3950],\n",
      "        ...,\n",
      "        [ 2.4910],\n",
      "        [ 0.3679],\n",
      "        [ 2.3368]]), tensor([[ 0.6797],\n",
      "        [ 0.2936],\n",
      "        [ 0.0517],\n",
      "        ...,\n",
      "        [-1.8262],\n",
      "        [ 2.2649],\n",
      "        [-2.5430]]), tensor([[ 1.4754e+00],\n",
      "        [ 2.4773e+00],\n",
      "        [-2.0029e+00],\n",
      "        ...,\n",
      "        [ 2.3614e+00],\n",
      "        [-3.8980e-04],\n",
      "        [ 2.0376e+00]]), tensor([[ 0.2620],\n",
      "        [ 2.4760],\n",
      "        [-2.2844],\n",
      "        ...,\n",
      "        [ 2.1224],\n",
      "        [ 0.3576],\n",
      "        [ 2.2655]]), tensor([[ 1.7156],\n",
      "        [ 2.4090],\n",
      "        [-2.2574],\n",
      "        ...,\n",
      "        [ 2.0102],\n",
      "        [-0.4882],\n",
      "        [ 1.9172]]), tensor([[-0.5330],\n",
      "        [-0.1174],\n",
      "        [-0.1546],\n",
      "        ...,\n",
      "        [ 1.9059],\n",
      "        [ 1.9091],\n",
      "        [-1.9743]]), tensor([[ 1.6675],\n",
      "        [ 2.3786],\n",
      "        [-2.2337],\n",
      "        ...,\n",
      "        [ 2.2515],\n",
      "        [ 0.3521],\n",
      "        [ 1.6734]]), tensor([[-1.5197],\n",
      "        [ 0.4652],\n",
      "        [ 0.6216],\n",
      "        ...,\n",
      "        [ 1.7827],\n",
      "        [ 2.5288],\n",
      "        [-2.5226]]), tensor([[-1.5394],\n",
      "        [ 0.5456],\n",
      "        [ 1.3620],\n",
      "        ...,\n",
      "        [ 2.2004],\n",
      "        [ 2.4237],\n",
      "        [-2.4844]]), tensor([[ 1.5321],\n",
      "        [ 2.3678],\n",
      "        [-2.3595],\n",
      "        ...,\n",
      "        [ 2.1115],\n",
      "        [-0.3368],\n",
      "        [ 1.4948]]), tensor([[ 1.8925],\n",
      "        [ 2.3020],\n",
      "        [-2.2874],\n",
      "        ...,\n",
      "        [ 2.2149],\n",
      "        [-0.1256],\n",
      "        [ 1.8516]]), tensor([[-1.7238],\n",
      "        [ 0.7267],\n",
      "        [ 1.6255],\n",
      "        ...,\n",
      "        [ 2.3679],\n",
      "        [ 2.5941],\n",
      "        [-2.4519]]), tensor([[-0.7607],\n",
      "        [ 2.3809],\n",
      "        [-1.9349],\n",
      "        ...,\n",
      "        [ 2.1554],\n",
      "        [ 0.1726],\n",
      "        [ 2.0141]]), tensor([[ 1.5202],\n",
      "        [ 2.3538],\n",
      "        [-2.3495],\n",
      "        ...,\n",
      "        [ 1.9010],\n",
      "        [ 0.2117],\n",
      "        [ 1.7077]]), tensor([[-0.5672],\n",
      "        [-0.6270],\n",
      "        [ 1.4311],\n",
      "        ...,\n",
      "        [ 2.0899],\n",
      "        [ 2.1507],\n",
      "        [-2.5006]]), tensor([[ 2.1918],\n",
      "        [ 2.3473],\n",
      "        [-2.2479],\n",
      "        ...,\n",
      "        [ 2.0245],\n",
      "        [-0.1086],\n",
      "        [ 1.4380]]), tensor([[ 0.5321],\n",
      "        [ 2.4320],\n",
      "        [-2.2399],\n",
      "        ...,\n",
      "        [ 2.2129],\n",
      "        [ 0.3859],\n",
      "        [ 2.1223]]), tensor([[-1.3468],\n",
      "        [ 0.0223],\n",
      "        [ 1.5429],\n",
      "        ...,\n",
      "        [ 2.0627],\n",
      "        [ 2.5545],\n",
      "        [-2.4214]]), tensor([[-0.4929],\n",
      "        [-0.3799],\n",
      "        [ 1.1440],\n",
      "        ...,\n",
      "        [ 0.8063],\n",
      "        [ 2.4363],\n",
      "        [-2.5578]]), tensor([[-0.5394],\n",
      "        [-0.3972],\n",
      "        [-0.8021],\n",
      "        ...,\n",
      "        [ 2.1621],\n",
      "        [ 1.9057],\n",
      "        [-2.7335]]), tensor([[-1.6865],\n",
      "        [ 1.1592],\n",
      "        [ 1.4304],\n",
      "        ...,\n",
      "        [ 2.0674],\n",
      "        [ 2.5159],\n",
      "        [-2.3575]]), tensor([[-1.4428],\n",
      "        [ 2.3860],\n",
      "        [-2.3248],\n",
      "        ...,\n",
      "        [ 2.2906],\n",
      "        [-0.2333],\n",
      "        [ 2.2298]]), tensor([[-1.5433],\n",
      "        [-1.0854],\n",
      "        [ 1.6663],\n",
      "        ...,\n",
      "        [ 2.2394],\n",
      "        [ 2.3361],\n",
      "        [-2.3736]]), tensor([[-1.6684],\n",
      "        [ 0.2074],\n",
      "        [ 1.8460],\n",
      "        ...,\n",
      "        [ 2.0717],\n",
      "        [ 2.4665],\n",
      "        [-2.3829]])]\n",
      "Explainer::Iteration 6 of 10\n",
      "[tensor([[ 1.7567],\n",
      "        [ 2.3384],\n",
      "        [-2.2890],\n",
      "        ...,\n",
      "        [ 2.2447],\n",
      "        [ 0.4298],\n",
      "        [ 2.3923]]), tensor([[-1.5848],\n",
      "        [ 0.2946],\n",
      "        [ 1.7215],\n",
      "        ...,\n",
      "        [ 2.0999],\n",
      "        [ 2.3461],\n",
      "        [-2.4590]]), tensor([[ 0.5433],\n",
      "        [ 2.3160],\n",
      "        [-2.2373],\n",
      "        ...,\n",
      "        [ 2.2033],\n",
      "        [ 0.0190],\n",
      "        [ 2.1767]]), tensor([[ 2.1910],\n",
      "        [ 2.1975],\n",
      "        [-2.3376],\n",
      "        ...,\n",
      "        [ 2.1833],\n",
      "        [ 0.1975],\n",
      "        [ 1.6246]]), tensor([[ 1.7057],\n",
      "        [ 2.4164],\n",
      "        [-2.4266],\n",
      "        ...,\n",
      "        [ 1.5035],\n",
      "        [-0.3982],\n",
      "        [ 1.4871]]), tensor([[ 0.5040],\n",
      "        [ 2.3305],\n",
      "        [-2.4237],\n",
      "        ...,\n",
      "        [ 2.2670],\n",
      "        [-0.0565],\n",
      "        [ 2.0330]]), tensor([[ 1.6486],\n",
      "        [ 2.3206],\n",
      "        [-2.2677],\n",
      "        ...,\n",
      "        [ 1.6376],\n",
      "        [-0.2529],\n",
      "        [ 2.6895]]), tensor([[ 2.0267],\n",
      "        [ 2.4137],\n",
      "        [-2.3504],\n",
      "        ...,\n",
      "        [ 2.2351],\n",
      "        [ 0.1057],\n",
      "        [ 1.5588]]), tensor([[-1.8168],\n",
      "        [ 0.2004],\n",
      "        [ 1.8083],\n",
      "        ...,\n",
      "        [ 2.4201],\n",
      "        [ 2.3580],\n",
      "        [-2.2262]]), tensor([[ 1.6149],\n",
      "        [ 2.2321],\n",
      "        [-2.2875],\n",
      "        ...,\n",
      "        [ 2.2979],\n",
      "        [-0.5559],\n",
      "        [ 1.6701]]), tensor([[ 2.2139],\n",
      "        [ 2.4381],\n",
      "        [-2.3035],\n",
      "        ...,\n",
      "        [ 2.1851],\n",
      "        [ 0.1287],\n",
      "        [ 1.6774]]), tensor([[ 1.6103],\n",
      "        [ 2.3868],\n",
      "        [-2.3861],\n",
      "        ...,\n",
      "        [ 2.0471],\n",
      "        [ 0.1589],\n",
      "        [ 1.7779]]), tensor([[ 1.9639],\n",
      "        [ 2.4034],\n",
      "        [-2.3167],\n",
      "        ...,\n",
      "        [ 2.1138],\n",
      "        [-0.2972],\n",
      "        [ 2.8863]]), tensor([[-1.6230],\n",
      "        [ 0.2831],\n",
      "        [ 1.2083],\n",
      "        ...,\n",
      "        [ 2.0513],\n",
      "        [ 2.3275],\n",
      "        [-2.5387]]), tensor([[-1.5923],\n",
      "        [ 0.2469],\n",
      "        [ 1.8379],\n",
      "        ...,\n",
      "        [ 1.7494],\n",
      "        [ 2.4213],\n",
      "        [-2.3324]]), tensor([[-0.1976],\n",
      "        [-0.8272],\n",
      "        [-0.2101],\n",
      "        ...,\n",
      "        [ 2.0657],\n",
      "        [ 1.9401],\n",
      "        [-2.6986]]), tensor([[ 0.8808],\n",
      "        [ 2.3384],\n",
      "        [-2.3095],\n",
      "        ...,\n",
      "        [ 2.1956],\n",
      "        [ 0.2368],\n",
      "        [ 1.9023]]), tensor([[ 1.3880],\n",
      "        [ 2.3143],\n",
      "        [-2.3501],\n",
      "        ...,\n",
      "        [ 2.1574],\n",
      "        [ 0.0110],\n",
      "        [ 2.1414]]), tensor([[ 1.7604],\n",
      "        [ 2.3226],\n",
      "        [-2.3395],\n",
      "        ...,\n",
      "        [ 2.1406],\n",
      "        [-0.3078],\n",
      "        [ 2.1434]]), tensor([[-1.0493],\n",
      "        [ 1.2596],\n",
      "        [ 2.6132],\n",
      "        ...,\n",
      "        [ 0.9128],\n",
      "        [ 2.1666],\n",
      "        [-2.4320]]), tensor([[ 1.9058],\n",
      "        [ 2.3019],\n",
      "        [-2.2836],\n",
      "        ...,\n",
      "        [ 2.2023],\n",
      "        [-0.0762],\n",
      "        [ 1.9724]]), tensor([[ 2.0173e+00],\n",
      "        [ 2.3699e+00],\n",
      "        [-2.3087e+00],\n",
      "        ...,\n",
      "        [ 1.9924e+00],\n",
      "        [-1.7430e-03],\n",
      "        [ 1.9936e+00]]), tensor([[-0.7951],\n",
      "        [ 0.1551],\n",
      "        [ 1.7645],\n",
      "        ...,\n",
      "        [ 2.7495],\n",
      "        [ 2.2928],\n",
      "        [-2.3627]]), tensor([[-1.5817],\n",
      "        [ 1.1944],\n",
      "        [ 0.2918],\n",
      "        ...,\n",
      "        [ 2.3364],\n",
      "        [ 1.9674],\n",
      "        [-2.5613]]), tensor([[ 2.0080],\n",
      "        [ 2.3062],\n",
      "        [-2.2359],\n",
      "        ...,\n",
      "        [ 2.2782],\n",
      "        [ 0.0470],\n",
      "        [ 2.2573]]), tensor([[ 1.5961],\n",
      "        [ 2.3121],\n",
      "        [-2.2382],\n",
      "        ...,\n",
      "        [ 1.9411],\n",
      "        [-0.2800],\n",
      "        [ 1.7916]]), tensor([[ 1.4297],\n",
      "        [ 2.2816],\n",
      "        [-2.2017],\n",
      "        ...,\n",
      "        [ 2.0702],\n",
      "        [-0.4355],\n",
      "        [ 1.8991]]), tensor([[-0.9957],\n",
      "        [-0.8257],\n",
      "        [ 1.8201],\n",
      "        ...,\n",
      "        [ 2.3444],\n",
      "        [ 2.3938],\n",
      "        [-2.3525]]), tensor([[-1.2680],\n",
      "        [ 2.2711],\n",
      "        [-0.1886],\n",
      "        ...,\n",
      "        [ 2.2078],\n",
      "        [ 2.5187],\n",
      "        [-2.5526]]), tensor([[ 1.4746],\n",
      "        [ 2.2742],\n",
      "        [-2.2796],\n",
      "        ...,\n",
      "        [ 1.9232],\n",
      "        [-0.5391],\n",
      "        [ 2.1793]]), tensor([[ 1.8177],\n",
      "        [ 2.3506],\n",
      "        [-2.4003],\n",
      "        ...,\n",
      "        [ 2.1163],\n",
      "        [-0.3245],\n",
      "        [ 2.4494]]), tensor([[-1.2862],\n",
      "        [ 0.2769],\n",
      "        [-1.2097],\n",
      "        ...,\n",
      "        [ 2.4226],\n",
      "        [ 1.8000],\n",
      "        [-2.4845]]), tensor([[-1.4416],\n",
      "        [-0.9314],\n",
      "        [ 1.9839],\n",
      "        ...,\n",
      "        [ 2.2344],\n",
      "        [ 2.3636],\n",
      "        [-2.2951]]), tensor([[-0.3514],\n",
      "        [ 2.4461],\n",
      "        [-2.3393],\n",
      "        ...,\n",
      "        [ 2.2531],\n",
      "        [ 0.2085],\n",
      "        [ 2.1582]]), tensor([[-1.2098],\n",
      "        [ 0.3490],\n",
      "        [ 1.6451],\n",
      "        ...,\n",
      "        [-0.2854],\n",
      "        [ 2.4623],\n",
      "        [-2.1845]]), tensor([[ 1.2205],\n",
      "        [ 2.3694],\n",
      "        [-2.2961],\n",
      "        ...,\n",
      "        [ 2.2939],\n",
      "        [ 0.1704],\n",
      "        [ 2.1232]]), tensor([[-1.1486],\n",
      "        [ 0.1647],\n",
      "        [ 1.9962],\n",
      "        ...,\n",
      "        [ 2.2166],\n",
      "        [ 1.8772],\n",
      "        [-2.3292]]), tensor([[-1.0363],\n",
      "        [ 1.7108],\n",
      "        [ 1.6326],\n",
      "        ...,\n",
      "        [ 2.2634],\n",
      "        [ 2.5735],\n",
      "        [-2.4937]]), tensor([[ 1.4240],\n",
      "        [ 2.3417],\n",
      "        [-2.3029],\n",
      "        ...,\n",
      "        [ 2.3126],\n",
      "        [ 0.2060],\n",
      "        [ 2.1070]]), tensor([[ 2.0744],\n",
      "        [ 2.3495],\n",
      "        [-2.3170],\n",
      "        ...,\n",
      "        [ 1.9706],\n",
      "        [ 1.5227],\n",
      "        [ 1.2361]]), tensor([[-1.5109],\n",
      "        [ 0.4609],\n",
      "        [ 1.6157],\n",
      "        ...,\n",
      "        [ 1.9555],\n",
      "        [ 2.1776],\n",
      "        [-2.3788]]), tensor([[-0.5401],\n",
      "        [ 2.3014],\n",
      "        [-2.2464],\n",
      "        ...,\n",
      "        [ 2.2145],\n",
      "        [-0.2576],\n",
      "        [ 2.2660]]), tensor([[ 2.2393],\n",
      "        [ 2.3439],\n",
      "        [-2.2967],\n",
      "        ...,\n",
      "        [ 2.2853],\n",
      "        [ 1.4087],\n",
      "        [ 2.5152]]), tensor([[ 1.5813],\n",
      "        [ 2.4194],\n",
      "        [-2.2839],\n",
      "        ...,\n",
      "        [ 1.9941],\n",
      "        [-0.5438],\n",
      "        [ 2.2400]]), tensor([[ 0.4463],\n",
      "        [ 2.3951],\n",
      "        [-2.2894],\n",
      "        ...,\n",
      "        [ 2.1685],\n",
      "        [ 0.3873],\n",
      "        [ 1.7414]]), tensor([[ 1.4732],\n",
      "        [ 2.2223],\n",
      "        [-2.2068],\n",
      "        ...,\n",
      "        [ 2.3374],\n",
      "        [ 0.6012],\n",
      "        [ 1.5860]]), tensor([[ 2.0978],\n",
      "        [ 2.4068],\n",
      "        [-2.2954],\n",
      "        ...,\n",
      "        [ 2.1764],\n",
      "        [ 0.1592],\n",
      "        [ 2.0183]]), tensor([[ 1.8635],\n",
      "        [ 2.3915],\n",
      "        [-2.2997],\n",
      "        ...,\n",
      "        [ 2.3411],\n",
      "        [ 0.1817],\n",
      "        [ 2.1541]]), tensor([[-0.4286],\n",
      "        [-0.8145],\n",
      "        [ 1.5277],\n",
      "        ...,\n",
      "        [ 1.4836],\n",
      "        [ 2.5111],\n",
      "        [-2.3204]]), tensor([[-1.2960],\n",
      "        [ 0.7948],\n",
      "        [ 1.2154],\n",
      "        ...,\n",
      "        [ 2.3083],\n",
      "        [ 2.4116],\n",
      "        [-2.3768]]), tensor([[ 0.7751],\n",
      "        [ 2.4008],\n",
      "        [-2.2465],\n",
      "        ...,\n",
      "        [ 2.2575],\n",
      "        [ 0.4476],\n",
      "        [ 1.7478]]), tensor([[ 0.5104],\n",
      "        [ 2.2792],\n",
      "        [-2.2647],\n",
      "        ...,\n",
      "        [ 2.1896],\n",
      "        [ 0.3682],\n",
      "        [ 1.7629]]), tensor([[ 1.9477],\n",
      "        [ 2.3574],\n",
      "        [-2.3275],\n",
      "        ...,\n",
      "        [ 1.8808],\n",
      "        [-0.1213],\n",
      "        [ 2.5283]]), tensor([[-1.3863],\n",
      "        [-0.4532],\n",
      "        [ 2.0861],\n",
      "        ...,\n",
      "        [-1.6348],\n",
      "        [ 2.4081],\n",
      "        [-2.4130]]), tensor([[ 1.5685],\n",
      "        [ 2.3254],\n",
      "        [-2.3145],\n",
      "        ...,\n",
      "        [ 2.3187],\n",
      "        [ 0.1444],\n",
      "        [ 1.6671]]), tensor([[ 1.9350],\n",
      "        [ 2.2318],\n",
      "        [-2.4879],\n",
      "        ...,\n",
      "        [ 2.2594],\n",
      "        [ 0.7011],\n",
      "        [ 2.1691]]), tensor([[ 0.1693],\n",
      "        [ 2.4432],\n",
      "        [-2.2789],\n",
      "        ...,\n",
      "        [ 2.2749],\n",
      "        [ 0.2700],\n",
      "        [ 2.0790]]), tensor([[ 0.7947],\n",
      "        [ 0.2398],\n",
      "        [ 0.1327],\n",
      "        ...,\n",
      "        [-2.2299],\n",
      "        [ 2.2447],\n",
      "        [-2.6099]]), tensor([[ 1.6229],\n",
      "        [ 2.4261],\n",
      "        [-1.8881],\n",
      "        ...,\n",
      "        [ 2.2287],\n",
      "        [-0.0830],\n",
      "        [ 1.9592]]), tensor([[ 0.3504],\n",
      "        [ 2.3680],\n",
      "        [-2.2336],\n",
      "        ...,\n",
      "        [ 2.3228],\n",
      "        [ 0.4313],\n",
      "        [ 2.2847]]), tensor([[ 1.7085],\n",
      "        [ 2.3197],\n",
      "        [-2.3154],\n",
      "        ...,\n",
      "        [ 2.1068],\n",
      "        [-0.5688],\n",
      "        [ 2.0117]]), tensor([[-0.3330],\n",
      "        [-0.1579],\n",
      "        [-0.2714],\n",
      "        ...,\n",
      "        [ 2.3758],\n",
      "        [ 1.7622],\n",
      "        [-2.1248]]), tensor([[ 1.5760],\n",
      "        [ 2.1884],\n",
      "        [-2.2685],\n",
      "        ...,\n",
      "        [ 2.3692],\n",
      "        [ 0.1603],\n",
      "        [ 2.3007]]), tensor([[-1.3512],\n",
      "        [ 0.4800],\n",
      "        [ 0.8038],\n",
      "        ...,\n",
      "        [ 2.1458],\n",
      "        [ 2.3743],\n",
      "        [-2.5408]]), tensor([[-1.4151],\n",
      "        [ 0.5473],\n",
      "        [ 1.5604],\n",
      "        ...,\n",
      "        [ 2.2069],\n",
      "        [ 2.4780],\n",
      "        [-2.3851]]), tensor([[ 1.6337],\n",
      "        [ 2.4486],\n",
      "        [-2.3048],\n",
      "        ...,\n",
      "        [ 2.1119],\n",
      "        [-0.4239],\n",
      "        [ 1.5583]]), tensor([[ 1.8769],\n",
      "        [ 2.3013],\n",
      "        [-2.4529],\n",
      "        ...,\n",
      "        [ 2.2435],\n",
      "        [ 0.8460],\n",
      "        [ 1.6520]]), tensor([[-1.7227],\n",
      "        [ 0.6588],\n",
      "        [ 1.6836],\n",
      "        ...,\n",
      "        [ 2.3406],\n",
      "        [ 2.5186],\n",
      "        [-2.4260]]), tensor([[-0.8195],\n",
      "        [ 2.4533],\n",
      "        [-1.9328],\n",
      "        ...,\n",
      "        [ 2.2143],\n",
      "        [ 0.4069],\n",
      "        [ 1.9561]]), tensor([[ 1.5963],\n",
      "        [ 2.2970],\n",
      "        [-2.3514],\n",
      "        ...,\n",
      "        [ 1.9531],\n",
      "        [-0.3450],\n",
      "        [ 1.4301]]), tensor([[-0.5585],\n",
      "        [-0.6301],\n",
      "        [ 1.4864],\n",
      "        ...,\n",
      "        [ 2.1002],\n",
      "        [ 2.1316],\n",
      "        [-2.4222]]), tensor([[ 2.1476],\n",
      "        [ 2.3072],\n",
      "        [-2.2665],\n",
      "        ...,\n",
      "        [ 1.9442],\n",
      "        [-0.2363],\n",
      "        [ 2.2939]]), tensor([[ 0.4531],\n",
      "        [ 2.2179],\n",
      "        [-2.3249],\n",
      "        ...,\n",
      "        [ 2.1366],\n",
      "        [ 0.0024],\n",
      "        [ 2.0504]]), tensor([[-1.2579],\n",
      "        [ 0.0224],\n",
      "        [ 1.2265],\n",
      "        ...,\n",
      "        [ 2.2100],\n",
      "        [ 2.5553],\n",
      "        [-2.3430]]), tensor([[-0.6523],\n",
      "        [-0.3670],\n",
      "        [ 1.1541],\n",
      "        ...,\n",
      "        [ 0.8908],\n",
      "        [ 2.3518],\n",
      "        [-2.5760]]), tensor([[-0.4766],\n",
      "        [-0.4105],\n",
      "        [-1.0441],\n",
      "        ...,\n",
      "        [ 2.0044],\n",
      "        [ 1.7540],\n",
      "        [-2.7571]]), tensor([[-1.5162],\n",
      "        [ 1.1379],\n",
      "        [ 1.2344],\n",
      "        ...,\n",
      "        [ 2.0552],\n",
      "        [ 2.4085],\n",
      "        [-2.4017]]), tensor([[-1.3022],\n",
      "        [ 2.3265],\n",
      "        [-2.2865],\n",
      "        ...,\n",
      "        [ 2.1917],\n",
      "        [-0.1570],\n",
      "        [ 2.1326]]), tensor([[-1.6367],\n",
      "        [-1.0875],\n",
      "        [ 1.7567],\n",
      "        ...,\n",
      "        [ 2.1393],\n",
      "        [ 2.4137],\n",
      "        [-2.4507]]), tensor([[-1.6361],\n",
      "        [ 0.2113],\n",
      "        [ 1.8429],\n",
      "        ...,\n",
      "        [ 2.1103],\n",
      "        [ 2.4373],\n",
      "        [-2.3896]])]\n",
      "Explainer::Iteration 7 of 10\n",
      "[tensor([[ 1.7891],\n",
      "        [ 2.2925],\n",
      "        [-2.2714],\n",
      "        ...,\n",
      "        [ 2.1382],\n",
      "        [ 0.2150],\n",
      "        [ 2.4516]]), tensor([[-1.7355],\n",
      "        [ 0.2945],\n",
      "        [ 2.0927],\n",
      "        ...,\n",
      "        [ 2.1894],\n",
      "        [ 2.4378],\n",
      "        [-2.4703]]), tensor([[ 0.4165],\n",
      "        [ 2.3111],\n",
      "        [-2.2592],\n",
      "        ...,\n",
      "        [ 2.2423],\n",
      "        [ 0.1717],\n",
      "        [ 2.1359]]), tensor([[ 1.9239],\n",
      "        [ 2.3149],\n",
      "        [-2.3305],\n",
      "        ...,\n",
      "        [ 2.1712],\n",
      "        [-0.0081],\n",
      "        [ 1.5513]]), tensor([[ 1.6992],\n",
      "        [ 2.3581],\n",
      "        [-2.2513],\n",
      "        ...,\n",
      "        [ 1.4056],\n",
      "        [-0.4683],\n",
      "        [ 1.5167]]), tensor([[ 0.4755],\n",
      "        [ 2.4303],\n",
      "        [-2.2533],\n",
      "        ...,\n",
      "        [ 2.2207],\n",
      "        [ 0.0621],\n",
      "        [ 1.8623]]), tensor([[ 1.5338],\n",
      "        [ 2.3199],\n",
      "        [-2.4227],\n",
      "        ...,\n",
      "        [ 1.4674],\n",
      "        [-0.3913],\n",
      "        [ 2.7796]]), tensor([[ 1.9901],\n",
      "        [ 2.4509],\n",
      "        [-2.3489],\n",
      "        ...,\n",
      "        [ 2.1895],\n",
      "        [ 0.0109],\n",
      "        [ 1.4609]]), tensor([[-1.7875],\n",
      "        [ 0.2088],\n",
      "        [ 1.2727],\n",
      "        ...,\n",
      "        [ 2.3146],\n",
      "        [ 2.3967],\n",
      "        [-2.3346]]), tensor([[ 1.5184],\n",
      "        [ 2.3112],\n",
      "        [-2.2435],\n",
      "        ...,\n",
      "        [ 2.3565],\n",
      "        [-0.5410],\n",
      "        [ 1.8020]]), tensor([[ 2.0741],\n",
      "        [ 2.5146],\n",
      "        [-2.3816],\n",
      "        ...,\n",
      "        [ 2.2781],\n",
      "        [ 0.2676],\n",
      "        [ 1.8528]]), tensor([[ 1.6802],\n",
      "        [ 2.3184],\n",
      "        [-2.2528],\n",
      "        ...,\n",
      "        [ 2.0554],\n",
      "        [ 0.0756],\n",
      "        [ 2.1519]]), tensor([[ 1.8861],\n",
      "        [ 2.3902],\n",
      "        [-2.3705],\n",
      "        ...,\n",
      "        [ 2.1539],\n",
      "        [-0.2824],\n",
      "        [ 3.0522]]), tensor([[-1.7660],\n",
      "        [ 0.2857],\n",
      "        [ 0.5153],\n",
      "        ...,\n",
      "        [ 2.0218],\n",
      "        [ 2.2547],\n",
      "        [-2.4693]]), tensor([[-1.7722],\n",
      "        [ 0.2447],\n",
      "        [ 1.9113],\n",
      "        ...,\n",
      "        [ 1.7551],\n",
      "        [ 2.4569],\n",
      "        [-2.4753]]), tensor([[-0.5518],\n",
      "        [-0.8311],\n",
      "        [-0.2574],\n",
      "        ...,\n",
      "        [ 2.4432],\n",
      "        [ 1.9050],\n",
      "        [-2.7436]]), tensor([[ 0.7187],\n",
      "        [ 2.4145],\n",
      "        [-2.2541],\n",
      "        ...,\n",
      "        [ 2.1905],\n",
      "        [ 0.3350],\n",
      "        [ 1.9564]]), tensor([[ 1.1846],\n",
      "        [ 2.2916],\n",
      "        [-2.3886],\n",
      "        ...,\n",
      "        [ 2.3540],\n",
      "        [ 0.0718],\n",
      "        [ 2.2328]]), tensor([[ 1.8544],\n",
      "        [ 2.3738],\n",
      "        [-2.4200],\n",
      "        ...,\n",
      "        [ 2.1547],\n",
      "        [-0.9802],\n",
      "        [ 2.1897]]), tensor([[-0.9882],\n",
      "        [ 1.3209],\n",
      "        [ 2.5956],\n",
      "        ...,\n",
      "        [ 0.8621],\n",
      "        [ 1.9345],\n",
      "        [-2.4051]]), tensor([[ 1.9950],\n",
      "        [ 2.2471],\n",
      "        [-2.3608],\n",
      "        ...,\n",
      "        [ 2.1988],\n",
      "        [-0.1328],\n",
      "        [ 2.5041]]), tensor([[ 1.9434],\n",
      "        [ 2.4400],\n",
      "        [-2.3528],\n",
      "        ...,\n",
      "        [ 1.8381],\n",
      "        [-0.1064],\n",
      "        [ 2.2417]]), tensor([[-0.9076],\n",
      "        [ 0.1696],\n",
      "        [ 1.9113],\n",
      "        ...,\n",
      "        [ 2.9839],\n",
      "        [ 2.3437],\n",
      "        [-2.3511]]), tensor([[-1.5495],\n",
      "        [ 1.2015],\n",
      "        [ 0.1190],\n",
      "        ...,\n",
      "        [ 2.1918],\n",
      "        [ 1.9571],\n",
      "        [-2.5471]]), tensor([[ 1.9423],\n",
      "        [ 2.4462],\n",
      "        [-2.4651],\n",
      "        ...,\n",
      "        [ 2.1524],\n",
      "        [-0.0465],\n",
      "        [ 1.8993]]), tensor([[ 1.5228],\n",
      "        [ 2.3279],\n",
      "        [-2.2295],\n",
      "        ...,\n",
      "        [ 1.7080],\n",
      "        [-0.3150],\n",
      "        [ 1.8515]]), tensor([[ 1.4051],\n",
      "        [ 2.2653],\n",
      "        [-2.3661],\n",
      "        ...,\n",
      "        [ 2.1085],\n",
      "        [-0.4626],\n",
      "        [ 2.1763]]), tensor([[-1.0548],\n",
      "        [-0.8353],\n",
      "        [ 1.6154],\n",
      "        ...,\n",
      "        [ 2.3102],\n",
      "        [ 2.4452],\n",
      "        [-2.3591]]), tensor([[-1.2941],\n",
      "        [ 2.2874],\n",
      "        [ 0.3977],\n",
      "        ...,\n",
      "        [ 2.2792],\n",
      "        [ 2.3757],\n",
      "        [-2.5419]]), tensor([[ 1.5688],\n",
      "        [ 2.2644],\n",
      "        [-2.2944],\n",
      "        ...,\n",
      "        [ 1.9176],\n",
      "        [-0.5344],\n",
      "        [ 2.1987]]), tensor([[ 1.8921],\n",
      "        [ 2.4404],\n",
      "        [-2.1765],\n",
      "        ...,\n",
      "        [ 2.1841],\n",
      "        [-0.2930],\n",
      "        [ 2.3054]]), tensor([[-1.5164],\n",
      "        [ 0.2841],\n",
      "        [-1.3627],\n",
      "        ...,\n",
      "        [ 2.4239],\n",
      "        [ 1.7562],\n",
      "        [-2.3478]]), tensor([[-1.3125],\n",
      "        [-0.9331],\n",
      "        [ 1.9662],\n",
      "        ...,\n",
      "        [ 2.1594],\n",
      "        [ 2.4646],\n",
      "        [-2.3414]]), tensor([[-0.1776],\n",
      "        [ 2.3661],\n",
      "        [-2.3319],\n",
      "        ...,\n",
      "        [ 2.2566],\n",
      "        [ 0.1399],\n",
      "        [ 2.0101]]), tensor([[-1.1897],\n",
      "        [ 0.3461],\n",
      "        [ 1.5289],\n",
      "        ...,\n",
      "        [-0.0555],\n",
      "        [ 2.3830],\n",
      "        [-2.1666]]), tensor([[ 1.2545],\n",
      "        [ 2.2550],\n",
      "        [-2.4155],\n",
      "        ...,\n",
      "        [ 2.2606],\n",
      "        [ 0.1939],\n",
      "        [ 1.9037]]), tensor([[-0.9334],\n",
      "        [ 0.0668],\n",
      "        [ 2.3771],\n",
      "        ...,\n",
      "        [ 2.2709],\n",
      "        [ 1.7764],\n",
      "        [-2.3606]]), tensor([[-0.8795],\n",
      "        [ 1.7980],\n",
      "        [ 1.6893],\n",
      "        ...,\n",
      "        [ 2.3000],\n",
      "        [ 2.4557],\n",
      "        [-2.5165]]), tensor([[ 1.4923],\n",
      "        [ 2.3407],\n",
      "        [-2.2935],\n",
      "        ...,\n",
      "        [ 2.2079],\n",
      "        [ 0.2992],\n",
      "        [ 2.1790]]), tensor([[ 1.9374],\n",
      "        [ 2.3225],\n",
      "        [-2.2638],\n",
      "        ...,\n",
      "        [ 2.0596],\n",
      "        [ 1.2364],\n",
      "        [ 1.2328]]), tensor([[-1.2989],\n",
      "        [ 0.4616],\n",
      "        [ 1.5919],\n",
      "        ...,\n",
      "        [ 1.9294],\n",
      "        [ 2.0940],\n",
      "        [-2.3793]]), tensor([[-0.8286],\n",
      "        [ 2.2788],\n",
      "        [-2.3403],\n",
      "        ...,\n",
      "        [ 2.2639],\n",
      "        [-0.3044],\n",
      "        [ 2.3759]]), tensor([[ 2.1266],\n",
      "        [ 2.4266],\n",
      "        [-2.4760],\n",
      "        ...,\n",
      "        [ 2.2614],\n",
      "        [ 1.4279],\n",
      "        [ 2.5470]]), tensor([[ 1.5496],\n",
      "        [ 2.4681],\n",
      "        [-2.2115],\n",
      "        ...,\n",
      "        [ 1.9322],\n",
      "        [-0.6276],\n",
      "        [ 2.1166]]), tensor([[ 0.1908],\n",
      "        [ 2.4680],\n",
      "        [-2.3304],\n",
      "        ...,\n",
      "        [ 2.2506],\n",
      "        [ 0.3530],\n",
      "        [ 1.8026]]), tensor([[ 1.4625],\n",
      "        [ 2.3450],\n",
      "        [-2.4063],\n",
      "        ...,\n",
      "        [ 2.1993],\n",
      "        [ 0.4417],\n",
      "        [ 1.5726]]), tensor([[ 2.0273],\n",
      "        [ 2.4415],\n",
      "        [-2.3201],\n",
      "        ...,\n",
      "        [ 2.2294],\n",
      "        [-0.2360],\n",
      "        [ 2.2625]]), tensor([[ 1.8443],\n",
      "        [ 2.3647],\n",
      "        [-2.2979],\n",
      "        ...,\n",
      "        [ 2.2908],\n",
      "        [ 0.2537],\n",
      "        [ 2.2523]]), tensor([[-0.5124],\n",
      "        [-0.8399],\n",
      "        [ 1.5107],\n",
      "        ...,\n",
      "        [ 1.4551],\n",
      "        [ 2.4203],\n",
      "        [-2.4844]]), tensor([[-1.5063],\n",
      "        [ 0.7873],\n",
      "        [ 1.2533],\n",
      "        ...,\n",
      "        [ 2.3779],\n",
      "        [ 2.5599],\n",
      "        [-2.3597]]), tensor([[ 0.7810],\n",
      "        [ 2.2764],\n",
      "        [-2.1795],\n",
      "        ...,\n",
      "        [ 2.3188],\n",
      "        [ 0.2256],\n",
      "        [ 1.7964]]), tensor([[ 0.5814],\n",
      "        [ 2.3478],\n",
      "        [-2.3371],\n",
      "        ...,\n",
      "        [ 2.1758],\n",
      "        [ 0.5727],\n",
      "        [ 1.8755]]), tensor([[ 2.0173],\n",
      "        [ 2.3639],\n",
      "        [-2.3017],\n",
      "        ...,\n",
      "        [ 2.0025],\n",
      "        [ 0.0435],\n",
      "        [ 2.1822]]), tensor([[-1.5632],\n",
      "        [-0.4499],\n",
      "        [ 2.1060],\n",
      "        ...,\n",
      "        [-1.6568],\n",
      "        [ 2.4158],\n",
      "        [-2.3113]]), tensor([[ 1.6473],\n",
      "        [ 2.2685],\n",
      "        [-2.4017],\n",
      "        ...,\n",
      "        [ 2.3844],\n",
      "        [ 0.2243],\n",
      "        [ 1.6349]]), tensor([[ 1.8631],\n",
      "        [ 2.4070],\n",
      "        [-2.5262],\n",
      "        ...,\n",
      "        [ 2.2548],\n",
      "        [ 0.4423],\n",
      "        [ 2.1208]]), tensor([[ 0.0321],\n",
      "        [ 2.3961],\n",
      "        [-2.3408],\n",
      "        ...,\n",
      "        [ 2.1988],\n",
      "        [ 0.4996],\n",
      "        [ 1.9389]]), tensor([[ 0.8883],\n",
      "        [ 0.3183],\n",
      "        [ 0.2383],\n",
      "        ...,\n",
      "        [-1.6618],\n",
      "        [ 2.2655],\n",
      "        [-2.3416]]), tensor([[ 1.6517],\n",
      "        [ 2.3136],\n",
      "        [-1.9452],\n",
      "        ...,\n",
      "        [ 2.2136],\n",
      "        [-0.0612],\n",
      "        [ 1.9068]]), tensor([[ 0.3129],\n",
      "        [ 2.2621],\n",
      "        [-2.3956],\n",
      "        ...,\n",
      "        [ 2.2832],\n",
      "        [ 0.4320],\n",
      "        [ 2.2385]]), tensor([[ 1.7351],\n",
      "        [ 2.3386],\n",
      "        [-2.4191],\n",
      "        ...,\n",
      "        [ 2.0091],\n",
      "        [-0.5728],\n",
      "        [ 1.7270]]), tensor([[-0.3205],\n",
      "        [-0.1224],\n",
      "        [-0.3168],\n",
      "        ...,\n",
      "        [ 1.8866],\n",
      "        [ 1.9211],\n",
      "        [-2.1739]]), tensor([[ 1.6660],\n",
      "        [ 2.2624],\n",
      "        [-2.2758],\n",
      "        ...,\n",
      "        [ 2.3178],\n",
      "        [ 0.5504],\n",
      "        [ 2.2846]]), tensor([[-1.4741],\n",
      "        [ 0.4814],\n",
      "        [ 1.0100],\n",
      "        ...,\n",
      "        [ 1.6661],\n",
      "        [ 2.4474],\n",
      "        [-2.4517]]), tensor([[-1.4831],\n",
      "        [ 0.5536],\n",
      "        [ 1.1800],\n",
      "        ...,\n",
      "        [ 2.2210],\n",
      "        [ 2.4688],\n",
      "        [-2.4665]]), tensor([[ 1.7347],\n",
      "        [ 2.3103],\n",
      "        [-2.3634],\n",
      "        ...,\n",
      "        [ 2.2314],\n",
      "        [-0.3142],\n",
      "        [ 1.2712]]), tensor([[ 1.8281],\n",
      "        [ 2.1842],\n",
      "        [-2.4353],\n",
      "        ...,\n",
      "        [ 2.0914],\n",
      "        [ 1.3412],\n",
      "        [ 2.0442]]), tensor([[-1.7146],\n",
      "        [ 0.5510],\n",
      "        [ 1.6536],\n",
      "        ...,\n",
      "        [ 2.3025],\n",
      "        [ 2.4994],\n",
      "        [-2.4262]]), tensor([[-0.5574],\n",
      "        [ 2.3838],\n",
      "        [-2.4191],\n",
      "        ...,\n",
      "        [ 2.2103],\n",
      "        [ 0.3063],\n",
      "        [ 1.9913]]), tensor([[ 1.6585],\n",
      "        [ 2.3191],\n",
      "        [-2.3632],\n",
      "        ...,\n",
      "        [ 1.8158],\n",
      "        [-0.3591],\n",
      "        [ 1.5870]]), tensor([[-0.3943],\n",
      "        [-0.6610],\n",
      "        [ 1.3105],\n",
      "        ...,\n",
      "        [ 2.0042],\n",
      "        [ 2.2365],\n",
      "        [-2.3886]]), tensor([[ 2.1460],\n",
      "        [ 2.3224],\n",
      "        [-2.3970],\n",
      "        ...,\n",
      "        [ 1.9154],\n",
      "        [ 0.0162],\n",
      "        [ 1.6317]]), tensor([[ 0.7189],\n",
      "        [ 2.3445],\n",
      "        [-2.2256],\n",
      "        ...,\n",
      "        [ 2.3430],\n",
      "        [ 0.1717],\n",
      "        [ 2.2416]]), tensor([[-1.3057e+00],\n",
      "        [-1.0268e-03],\n",
      "        [ 1.4137e+00],\n",
      "        ...,\n",
      "        [ 2.0977e+00],\n",
      "        [ 2.4327e+00],\n",
      "        [-2.3529e+00]]), tensor([[-0.3029],\n",
      "        [-0.3844],\n",
      "        [ 1.0678],\n",
      "        ...,\n",
      "        [ 1.8792],\n",
      "        [ 2.3981],\n",
      "        [-2.5506]]), tensor([[-0.5641],\n",
      "        [-0.3605],\n",
      "        [-0.7783],\n",
      "        ...,\n",
      "        [ 2.0888],\n",
      "        [ 1.7849],\n",
      "        [-2.7578]]), tensor([[-1.4734],\n",
      "        [ 1.1422],\n",
      "        [ 1.3578],\n",
      "        ...,\n",
      "        [ 1.9526],\n",
      "        [ 2.4789],\n",
      "        [-2.4920]]), tensor([[-1.3692],\n",
      "        [ 2.3907],\n",
      "        [-2.2926],\n",
      "        ...,\n",
      "        [ 2.2318],\n",
      "        [-0.0148],\n",
      "        [ 2.1277]]), tensor([[-1.7548],\n",
      "        [-1.1500],\n",
      "        [ 1.7354],\n",
      "        ...,\n",
      "        [ 2.1407],\n",
      "        [ 2.4048],\n",
      "        [-2.4086]]), tensor([[-1.6272],\n",
      "        [ 0.2078],\n",
      "        [ 1.7137],\n",
      "        ...,\n",
      "        [ 2.1151],\n",
      "        [ 2.4683],\n",
      "        [-2.3982]])]\n",
      "Explainer::Iteration 8 of 10\n",
      "[tensor([[ 1.7734],\n",
      "        [ 2.5031],\n",
      "        [-2.3787],\n",
      "        ...,\n",
      "        [ 2.1506],\n",
      "        [ 0.1714],\n",
      "        [ 2.2167]]), tensor([[-1.7590],\n",
      "        [ 0.2938],\n",
      "        [ 1.9365],\n",
      "        ...,\n",
      "        [ 2.2729],\n",
      "        [ 2.4009],\n",
      "        [-2.3309]]), tensor([[ 0.4931],\n",
      "        [ 2.3232],\n",
      "        [-2.2879],\n",
      "        ...,\n",
      "        [ 2.2120],\n",
      "        [ 0.0915],\n",
      "        [ 2.1567]]), tensor([[ 1.9615],\n",
      "        [ 2.3098],\n",
      "        [-2.3149],\n",
      "        ...,\n",
      "        [ 2.1161],\n",
      "        [ 0.3092],\n",
      "        [ 1.5024]]), tensor([[ 1.7047],\n",
      "        [ 2.3433],\n",
      "        [-2.2690],\n",
      "        ...,\n",
      "        [ 1.5160],\n",
      "        [-0.4408],\n",
      "        [ 2.3458]]), tensor([[ 2.7496e-01],\n",
      "        [ 2.3736e+00],\n",
      "        [-2.1712e+00],\n",
      "        ...,\n",
      "        [ 2.2869e+00],\n",
      "        [-1.2590e-03],\n",
      "        [ 1.9918e+00]]), tensor([[ 1.5423],\n",
      "        [ 2.3739],\n",
      "        [-2.2948],\n",
      "        ...,\n",
      "        [ 1.5668],\n",
      "        [-0.2425],\n",
      "        [ 2.8261]]), tensor([[ 2.0751],\n",
      "        [ 2.4038],\n",
      "        [-2.4352],\n",
      "        ...,\n",
      "        [ 2.2973],\n",
      "        [ 0.1060],\n",
      "        [ 1.5941]]), tensor([[-1.5852],\n",
      "        [ 0.2216],\n",
      "        [ 1.6454],\n",
      "        ...,\n",
      "        [ 2.3591],\n",
      "        [ 2.3228],\n",
      "        [-2.4934]]), tensor([[ 1.4983],\n",
      "        [ 2.4390],\n",
      "        [-2.1963],\n",
      "        ...,\n",
      "        [ 2.3016],\n",
      "        [-0.3755],\n",
      "        [ 1.7988]]), tensor([[ 2.0977],\n",
      "        [ 2.4871],\n",
      "        [-2.3709],\n",
      "        ...,\n",
      "        [ 2.2271],\n",
      "        [ 0.0331],\n",
      "        [ 1.7602]]), tensor([[ 1.7286],\n",
      "        [ 2.2661],\n",
      "        [-2.2845],\n",
      "        ...,\n",
      "        [ 2.0810],\n",
      "        [ 0.1135],\n",
      "        [ 2.4264]]), tensor([[ 1.8699],\n",
      "        [ 2.4009],\n",
      "        [-2.3153],\n",
      "        ...,\n",
      "        [ 2.2141],\n",
      "        [ 0.0258],\n",
      "        [ 2.6718]]), tensor([[-1.6519],\n",
      "        [ 0.2644],\n",
      "        [ 0.7808],\n",
      "        ...,\n",
      "        [ 2.0524],\n",
      "        [ 2.1838],\n",
      "        [-2.5445]]), tensor([[-1.5651],\n",
      "        [ 0.2397],\n",
      "        [ 1.6607],\n",
      "        ...,\n",
      "        [ 1.6808],\n",
      "        [ 2.3904],\n",
      "        [-2.4326]]), tensor([[-0.0330],\n",
      "        [-0.8023],\n",
      "        [-0.3988],\n",
      "        ...,\n",
      "        [ 2.5133],\n",
      "        [ 1.9487],\n",
      "        [-2.8163]]), tensor([[ 0.8613],\n",
      "        [ 2.2767],\n",
      "        [-2.3201],\n",
      "        ...,\n",
      "        [ 2.3322],\n",
      "        [ 0.2884],\n",
      "        [ 1.8753]]), tensor([[ 1.2441],\n",
      "        [ 2.3467],\n",
      "        [-2.2110],\n",
      "        ...,\n",
      "        [ 2.1063],\n",
      "        [ 0.3179],\n",
      "        [ 2.6118]]), tensor([[ 1.8435],\n",
      "        [ 2.4250],\n",
      "        [-2.3975],\n",
      "        ...,\n",
      "        [ 2.2264],\n",
      "        [-0.5217],\n",
      "        [ 2.0623]]), tensor([[-0.8992],\n",
      "        [ 1.3058],\n",
      "        [ 2.5609],\n",
      "        ...,\n",
      "        [ 1.0476],\n",
      "        [ 2.1076],\n",
      "        [-2.3802]]), tensor([[ 1.8901],\n",
      "        [ 2.2828],\n",
      "        [-2.3272],\n",
      "        ...,\n",
      "        [ 2.2586],\n",
      "        [-0.0470],\n",
      "        [ 2.4584]]), tensor([[ 2.0736],\n",
      "        [ 2.3448],\n",
      "        [-2.2916],\n",
      "        ...,\n",
      "        [ 1.8484],\n",
      "        [ 0.0424],\n",
      "        [ 1.9805]]), tensor([[-0.6591],\n",
      "        [ 0.1706],\n",
      "        [ 1.7692],\n",
      "        ...,\n",
      "        [ 3.1256],\n",
      "        [ 2.3000],\n",
      "        [-2.2801]]), tensor([[-1.4179],\n",
      "        [ 1.1935],\n",
      "        [ 0.1997],\n",
      "        ...,\n",
      "        [ 2.1707],\n",
      "        [ 1.8586],\n",
      "        [-2.5172]]), tensor([[ 1.9492],\n",
      "        [ 2.3669],\n",
      "        [-2.2774],\n",
      "        ...,\n",
      "        [ 2.2263],\n",
      "        [ 0.0368],\n",
      "        [ 1.8121]]), tensor([[ 1.5888],\n",
      "        [ 2.3224],\n",
      "        [-2.3424],\n",
      "        ...,\n",
      "        [ 1.7321],\n",
      "        [-0.3880],\n",
      "        [ 1.8048]]), tensor([[ 1.2707],\n",
      "        [ 2.2989],\n",
      "        [-2.3739],\n",
      "        ...,\n",
      "        [ 2.1406],\n",
      "        [-0.4417],\n",
      "        [ 2.2524]]), tensor([[-0.9678],\n",
      "        [-0.8377],\n",
      "        [ 1.7794],\n",
      "        ...,\n",
      "        [ 2.2406],\n",
      "        [ 2.3819],\n",
      "        [-2.2931]]), tensor([[-1.1925],\n",
      "        [ 2.2144],\n",
      "        [ 0.3812],\n",
      "        ...,\n",
      "        [ 2.1786],\n",
      "        [ 2.5060],\n",
      "        [-2.5078]]), tensor([[ 1.4626],\n",
      "        [ 2.2011],\n",
      "        [-2.3470],\n",
      "        ...,\n",
      "        [ 1.8720],\n",
      "        [-0.8993],\n",
      "        [ 2.1639]]), tensor([[ 2.0463],\n",
      "        [ 2.4536],\n",
      "        [-2.3167],\n",
      "        ...,\n",
      "        [ 2.1244],\n",
      "        [-0.2659],\n",
      "        [ 2.2871]]), tensor([[-1.4538],\n",
      "        [ 0.2822],\n",
      "        [-0.9538],\n",
      "        ...,\n",
      "        [ 2.4250],\n",
      "        [ 1.7280],\n",
      "        [-2.4304]]), tensor([[-1.3391],\n",
      "        [-0.9280],\n",
      "        [ 1.8922],\n",
      "        ...,\n",
      "        [ 2.2324],\n",
      "        [ 2.4232],\n",
      "        [-2.3996]]), tensor([[-0.2694],\n",
      "        [ 2.5318],\n",
      "        [-2.3329],\n",
      "        ...,\n",
      "        [ 2.1714],\n",
      "        [ 0.2679],\n",
      "        [ 1.9708]]), tensor([[-1.1593],\n",
      "        [ 0.3344],\n",
      "        [ 1.7251],\n",
      "        ...,\n",
      "        [-0.2681],\n",
      "        [ 2.4786],\n",
      "        [-2.1218]]), tensor([[ 1.3863],\n",
      "        [ 2.2904],\n",
      "        [-2.4231],\n",
      "        ...,\n",
      "        [ 2.2918],\n",
      "        [ 0.2371],\n",
      "        [ 1.8600]]), tensor([[-1.0690],\n",
      "        [ 0.1340],\n",
      "        [ 1.3525],\n",
      "        ...,\n",
      "        [ 2.0438],\n",
      "        [ 1.7096],\n",
      "        [-2.3203]]), tensor([[-1.6609],\n",
      "        [ 1.6818],\n",
      "        [ 1.6198],\n",
      "        ...,\n",
      "        [ 2.2774],\n",
      "        [ 2.5229],\n",
      "        [-2.3981]]), tensor([[ 1.6166],\n",
      "        [ 2.3202],\n",
      "        [-2.4202],\n",
      "        ...,\n",
      "        [ 2.1459],\n",
      "        [ 0.2922],\n",
      "        [ 1.8888]]), tensor([[ 2.0179],\n",
      "        [ 2.3614],\n",
      "        [-2.3740],\n",
      "        ...,\n",
      "        [ 1.9696],\n",
      "        [ 1.5855],\n",
      "        [ 1.1956]]), tensor([[-1.3680],\n",
      "        [ 0.4558],\n",
      "        [ 1.5561],\n",
      "        ...,\n",
      "        [ 2.0092],\n",
      "        [ 2.1402],\n",
      "        [-2.4183]]), tensor([[-0.6053],\n",
      "        [ 2.3011],\n",
      "        [-2.2796],\n",
      "        ...,\n",
      "        [ 2.2644],\n",
      "        [-0.3546],\n",
      "        [ 2.2445]]), tensor([[ 2.1207],\n",
      "        [ 2.3602],\n",
      "        [-2.3636],\n",
      "        ...,\n",
      "        [ 2.2793],\n",
      "        [ 1.1768],\n",
      "        [ 2.6829]]), tensor([[ 1.6087],\n",
      "        [ 2.3326],\n",
      "        [-2.2140],\n",
      "        ...,\n",
      "        [ 1.9675],\n",
      "        [-1.3539],\n",
      "        [ 2.0564]]), tensor([[ 0.5132],\n",
      "        [ 2.4477],\n",
      "        [-2.4303],\n",
      "        ...,\n",
      "        [ 2.2192],\n",
      "        [-0.0197],\n",
      "        [ 1.6468]]), tensor([[ 1.4791],\n",
      "        [ 2.3944],\n",
      "        [-2.3231],\n",
      "        ...,\n",
      "        [ 2.2175],\n",
      "        [ 0.5278],\n",
      "        [ 1.6386]]), tensor([[ 2.0250],\n",
      "        [ 2.2957],\n",
      "        [-2.3134],\n",
      "        ...,\n",
      "        [ 2.1460],\n",
      "        [ 0.0442],\n",
      "        [ 2.1374]]), tensor([[ 1.8444],\n",
      "        [ 2.3197],\n",
      "        [-2.2927],\n",
      "        ...,\n",
      "        [ 2.2551],\n",
      "        [ 0.3340],\n",
      "        [ 2.0799]]), tensor([[-0.4712],\n",
      "        [-0.7848],\n",
      "        [ 1.9347],\n",
      "        ...,\n",
      "        [ 1.5497],\n",
      "        [ 2.4043],\n",
      "        [-2.4280]]), tensor([[-1.4084],\n",
      "        [ 0.7941],\n",
      "        [ 1.5499],\n",
      "        ...,\n",
      "        [ 2.2028],\n",
      "        [ 2.2641],\n",
      "        [-2.3861]]), tensor([[ 0.7643],\n",
      "        [ 2.3670],\n",
      "        [-2.2760],\n",
      "        ...,\n",
      "        [ 2.3275],\n",
      "        [ 0.4378],\n",
      "        [ 1.7032]]), tensor([[ 0.6001],\n",
      "        [ 2.2935],\n",
      "        [-2.4052],\n",
      "        ...,\n",
      "        [ 2.2454],\n",
      "        [ 0.7463],\n",
      "        [ 1.7992]]), tensor([[ 2.1080],\n",
      "        [ 2.4334],\n",
      "        [-2.3251],\n",
      "        ...,\n",
      "        [ 1.8819],\n",
      "        [ 0.0542],\n",
      "        [ 2.3355]]), tensor([[-1.4805],\n",
      "        [-0.4578],\n",
      "        [ 2.1353],\n",
      "        ...,\n",
      "        [-1.7058],\n",
      "        [ 2.4847],\n",
      "        [-2.5020]]), tensor([[ 1.5328],\n",
      "        [ 2.2212],\n",
      "        [-2.2331],\n",
      "        ...,\n",
      "        [ 2.5013],\n",
      "        [ 0.1146],\n",
      "        [ 1.5481]]), tensor([[ 1.9179],\n",
      "        [ 2.3487],\n",
      "        [-2.3856],\n",
      "        ...,\n",
      "        [ 2.3836],\n",
      "        [ 0.5710],\n",
      "        [ 2.2398]]), tensor([[-0.0489],\n",
      "        [ 2.5030],\n",
      "        [-2.2426],\n",
      "        ...,\n",
      "        [ 2.3390],\n",
      "        [ 0.3320],\n",
      "        [ 2.1114]]), tensor([[ 0.7971],\n",
      "        [ 0.6144],\n",
      "        [ 0.3148],\n",
      "        ...,\n",
      "        [-1.7771],\n",
      "        [ 2.2653],\n",
      "        [-2.4184]]), tensor([[ 1.5354],\n",
      "        [ 2.3632],\n",
      "        [-1.7333],\n",
      "        ...,\n",
      "        [ 2.3170],\n",
      "        [ 0.0139],\n",
      "        [ 1.9428]]), tensor([[ 0.4561],\n",
      "        [ 2.3461],\n",
      "        [-2.3557],\n",
      "        ...,\n",
      "        [ 2.2085],\n",
      "        [ 0.4104],\n",
      "        [ 2.3891]]), tensor([[ 1.7834],\n",
      "        [ 2.3058],\n",
      "        [-2.3001],\n",
      "        ...,\n",
      "        [ 2.2278],\n",
      "        [-0.7052],\n",
      "        [ 2.4877]]), tensor([[-0.2778],\n",
      "        [-0.1517],\n",
      "        [-0.5415],\n",
      "        ...,\n",
      "        [ 1.9895],\n",
      "        [ 2.0217],\n",
      "        [-2.0584]]), tensor([[ 1.6543],\n",
      "        [ 2.2825],\n",
      "        [-2.3558],\n",
      "        ...,\n",
      "        [ 2.2713],\n",
      "        [ 0.4824],\n",
      "        [ 2.0770]]), tensor([[-1.4434],\n",
      "        [ 0.4506],\n",
      "        [ 0.7621],\n",
      "        ...,\n",
      "        [ 1.9960],\n",
      "        [ 2.4720],\n",
      "        [-2.5239]]), tensor([[-1.4000],\n",
      "        [ 0.5557],\n",
      "        [ 1.2089],\n",
      "        ...,\n",
      "        [ 2.2477],\n",
      "        [ 2.6118],\n",
      "        [-2.3768]]), tensor([[ 1.5937],\n",
      "        [ 2.4153],\n",
      "        [-2.3604],\n",
      "        ...,\n",
      "        [ 2.2572],\n",
      "        [-0.4471],\n",
      "        [ 1.4566]]), tensor([[ 1.8627],\n",
      "        [ 2.3266],\n",
      "        [-2.3532],\n",
      "        ...,\n",
      "        [ 2.1962],\n",
      "        [-0.2115],\n",
      "        [ 1.5532]]), tensor([[-1.6982],\n",
      "        [ 0.5990],\n",
      "        [ 1.6318],\n",
      "        ...,\n",
      "        [ 2.3754],\n",
      "        [ 2.5265],\n",
      "        [-2.3650]]), tensor([[-0.7145],\n",
      "        [ 2.4130],\n",
      "        [-2.2721],\n",
      "        ...,\n",
      "        [ 2.0478],\n",
      "        [ 0.5482],\n",
      "        [ 1.9015]]), tensor([[ 1.6289],\n",
      "        [ 2.4126],\n",
      "        [-2.3294],\n",
      "        ...,\n",
      "        [ 1.8731],\n",
      "        [-0.8858],\n",
      "        [ 1.6415]]), tensor([[-0.5243],\n",
      "        [-0.6897],\n",
      "        [ 1.3144],\n",
      "        ...,\n",
      "        [ 2.1151],\n",
      "        [ 1.9834],\n",
      "        [-2.3993]]), tensor([[ 2.1020],\n",
      "        [ 2.3890],\n",
      "        [-2.4519],\n",
      "        ...,\n",
      "        [ 1.9551],\n",
      "        [-0.1426],\n",
      "        [ 2.3260]]), tensor([[ 0.5518],\n",
      "        [ 2.3011],\n",
      "        [-2.2082],\n",
      "        ...,\n",
      "        [ 2.3108],\n",
      "        [ 0.2720],\n",
      "        [ 2.3922]]), tensor([[-1.3702],\n",
      "        [ 0.0179],\n",
      "        [ 1.4620],\n",
      "        ...,\n",
      "        [ 2.1087],\n",
      "        [ 2.5182],\n",
      "        [-2.3854]]), tensor([[-0.5213],\n",
      "        [-0.3864],\n",
      "        [ 1.3641],\n",
      "        ...,\n",
      "        [ 0.9047],\n",
      "        [ 2.4164],\n",
      "        [-2.5094]]), tensor([[-0.6446],\n",
      "        [-0.3839],\n",
      "        [-0.9665],\n",
      "        ...,\n",
      "        [ 1.9280],\n",
      "        [ 1.6951],\n",
      "        [-2.7458]]), tensor([[-1.5059],\n",
      "        [ 1.1530],\n",
      "        [ 1.2770],\n",
      "        ...,\n",
      "        [ 1.8991],\n",
      "        [ 2.4243],\n",
      "        [-2.3183]]), tensor([[-1.2773],\n",
      "        [ 2.3936],\n",
      "        [-2.2766],\n",
      "        ...,\n",
      "        [ 2.1465],\n",
      "        [-0.1587],\n",
      "        [ 1.9524]]), tensor([[-1.7923],\n",
      "        [-1.0833],\n",
      "        [ 1.6581],\n",
      "        ...,\n",
      "        [ 2.2219],\n",
      "        [ 2.3420],\n",
      "        [-2.4786]]), tensor([[-1.5073],\n",
      "        [ 0.2017],\n",
      "        [ 1.7903],\n",
      "        ...,\n",
      "        [ 2.0801],\n",
      "        [ 2.3777],\n",
      "        [-2.4737]])]\n",
      "Explainer::Iteration 9 of 10\n",
      "[tensor([[ 1.6934],\n",
      "        [ 2.3823],\n",
      "        [-2.3790],\n",
      "        ...,\n",
      "        [ 2.1310],\n",
      "        [ 0.4663],\n",
      "        [ 2.2570]]), tensor([[-1.6327],\n",
      "        [ 0.2951],\n",
      "        [ 2.1060],\n",
      "        ...,\n",
      "        [ 2.2903],\n",
      "        [ 2.5022],\n",
      "        [-2.4368]]), tensor([[ 0.3788],\n",
      "        [ 2.4053],\n",
      "        [-2.3768],\n",
      "        ...,\n",
      "        [ 2.2525],\n",
      "        [ 0.1347],\n",
      "        [ 2.0853]]), tensor([[ 2.1056],\n",
      "        [ 2.3626],\n",
      "        [-2.2579],\n",
      "        ...,\n",
      "        [ 2.2480],\n",
      "        [ 0.2091],\n",
      "        [ 1.5464]]), tensor([[ 1.7029],\n",
      "        [ 2.4447],\n",
      "        [-2.3282],\n",
      "        ...,\n",
      "        [ 1.4759],\n",
      "        [-0.4345],\n",
      "        [ 1.4914]]), tensor([[ 0.3003],\n",
      "        [ 2.4078],\n",
      "        [-2.3098],\n",
      "        ...,\n",
      "        [ 2.2414],\n",
      "        [-0.0174],\n",
      "        [ 1.8663]]), tensor([[ 1.6694],\n",
      "        [ 2.4236],\n",
      "        [-2.2633],\n",
      "        ...,\n",
      "        [ 1.6620],\n",
      "        [-0.2689],\n",
      "        [ 2.8129]]), tensor([[ 2.1640],\n",
      "        [ 2.3450],\n",
      "        [-2.2921],\n",
      "        ...,\n",
      "        [ 2.2847],\n",
      "        [ 0.2275],\n",
      "        [ 1.5505]]), tensor([[-1.8080],\n",
      "        [ 0.2103],\n",
      "        [ 1.7036],\n",
      "        ...,\n",
      "        [ 2.3150],\n",
      "        [ 2.3985],\n",
      "        [-2.1558]]), tensor([[ 1.5193],\n",
      "        [ 2.3918],\n",
      "        [-2.2828],\n",
      "        ...,\n",
      "        [ 2.2339],\n",
      "        [-0.2937],\n",
      "        [ 1.9479]]), tensor([[ 2.1092],\n",
      "        [ 2.2146],\n",
      "        [-2.4122],\n",
      "        ...,\n",
      "        [ 2.1479],\n",
      "        [ 0.1301],\n",
      "        [ 1.6931]]), tensor([[ 1.7158],\n",
      "        [ 2.3385],\n",
      "        [-2.3720],\n",
      "        ...,\n",
      "        [ 2.0830],\n",
      "        [ 0.1622],\n",
      "        [ 2.4331]]), tensor([[ 1.8467],\n",
      "        [ 2.3209],\n",
      "        [-2.2510],\n",
      "        ...,\n",
      "        [ 2.1839],\n",
      "        [-0.0235],\n",
      "        [ 2.7359]]), tensor([[-1.6758],\n",
      "        [ 0.2791],\n",
      "        [ 0.9996],\n",
      "        ...,\n",
      "        [ 2.0341],\n",
      "        [ 2.1674],\n",
      "        [-2.3756]]), tensor([[-1.6988],\n",
      "        [ 0.2415],\n",
      "        [ 1.7586],\n",
      "        ...,\n",
      "        [ 1.8130],\n",
      "        [ 2.3538],\n",
      "        [-2.5164]]), tensor([[ 0.0598],\n",
      "        [-0.8374],\n",
      "        [-0.2767],\n",
      "        ...,\n",
      "        [ 1.8948],\n",
      "        [ 1.9498],\n",
      "        [-2.8410]]), tensor([[ 0.9455],\n",
      "        [ 2.3991],\n",
      "        [-2.3412],\n",
      "        ...,\n",
      "        [ 2.3089],\n",
      "        [ 0.2173],\n",
      "        [ 1.7485]]), tensor([[ 1.2911],\n",
      "        [ 2.3715],\n",
      "        [-2.4350],\n",
      "        ...,\n",
      "        [ 2.2623],\n",
      "        [ 0.2473],\n",
      "        [ 2.3893]]), tensor([[ 1.7382],\n",
      "        [ 2.4052],\n",
      "        [-2.4367],\n",
      "        ...,\n",
      "        [ 2.0842],\n",
      "        [-0.7433],\n",
      "        [ 2.0406]]), tensor([[-0.9455],\n",
      "        [ 1.3292],\n",
      "        [ 2.5443],\n",
      "        ...,\n",
      "        [ 1.1115],\n",
      "        [ 2.0604],\n",
      "        [-2.4639]]), tensor([[ 1.9891],\n",
      "        [ 2.3829],\n",
      "        [-2.2210],\n",
      "        ...,\n",
      "        [ 2.1724],\n",
      "        [-0.0859],\n",
      "        [ 2.4627]]), tensor([[ 1.9333],\n",
      "        [ 2.3987],\n",
      "        [-2.2784],\n",
      "        ...,\n",
      "        [ 1.8211],\n",
      "        [-0.0949],\n",
      "        [ 2.1836]]), tensor([[-0.6562],\n",
      "        [ 0.1491],\n",
      "        [ 1.7727],\n",
      "        ...,\n",
      "        [ 2.9675],\n",
      "        [ 2.3642],\n",
      "        [-2.4642]]), tensor([[-1.5489],\n",
      "        [ 1.2034],\n",
      "        [ 0.2103],\n",
      "        ...,\n",
      "        [ 2.1828],\n",
      "        [ 1.9825],\n",
      "        [-2.6134]]), tensor([[ 1.9725],\n",
      "        [ 2.3348],\n",
      "        [-2.3067],\n",
      "        ...,\n",
      "        [ 2.3143],\n",
      "        [ 0.0795],\n",
      "        [ 1.8812]]), tensor([[ 1.5453],\n",
      "        [ 2.3420],\n",
      "        [-2.4144],\n",
      "        ...,\n",
      "        [ 1.7271],\n",
      "        [-0.3889],\n",
      "        [ 2.1886]]), tensor([[ 1.3161],\n",
      "        [ 2.2632],\n",
      "        [-2.3177],\n",
      "        ...,\n",
      "        [ 2.0180],\n",
      "        [-0.3975],\n",
      "        [ 2.0071]]), tensor([[-1.1801],\n",
      "        [-0.8331],\n",
      "        [ 1.8789],\n",
      "        ...,\n",
      "        [ 2.2728],\n",
      "        [ 2.3436],\n",
      "        [-2.2819]]), tensor([[-1.3343],\n",
      "        [ 2.2841],\n",
      "        [ 0.7233],\n",
      "        ...,\n",
      "        [ 2.1552],\n",
      "        [ 2.2897],\n",
      "        [-2.5643]]), tensor([[ 1.5085],\n",
      "        [ 2.2788],\n",
      "        [-2.3461],\n",
      "        ...,\n",
      "        [ 1.9351],\n",
      "        [-0.4572],\n",
      "        [ 2.0800]]), tensor([[ 1.8264],\n",
      "        [ 2.2094],\n",
      "        [-2.2159],\n",
      "        ...,\n",
      "        [ 2.0033],\n",
      "        [-0.2533],\n",
      "        [ 2.3068]]), tensor([[-1.3578],\n",
      "        [ 0.2770],\n",
      "        [-0.9158],\n",
      "        ...,\n",
      "        [ 2.3487],\n",
      "        [ 1.7558],\n",
      "        [-2.2818]]), tensor([[-1.3967],\n",
      "        [-0.9184],\n",
      "        [ 1.8911],\n",
      "        ...,\n",
      "        [ 2.0854],\n",
      "        [ 2.4611],\n",
      "        [-2.4179]]), tensor([[-0.2387],\n",
      "        [ 2.2861],\n",
      "        [-2.2639],\n",
      "        ...,\n",
      "        [ 2.0936],\n",
      "        [ 0.1390],\n",
      "        [ 2.0914]]), tensor([[-1.1060],\n",
      "        [ 0.3368],\n",
      "        [ 1.4119],\n",
      "        ...,\n",
      "        [-0.1100],\n",
      "        [ 2.4367],\n",
      "        [-2.1946]]), tensor([[ 1.3019],\n",
      "        [ 2.3458],\n",
      "        [-2.4877],\n",
      "        ...,\n",
      "        [ 2.2287],\n",
      "        [ 0.1664],\n",
      "        [ 2.0151]]), tensor([[-1.2446],\n",
      "        [ 0.1885],\n",
      "        [ 0.4321],\n",
      "        ...,\n",
      "        [ 2.1130],\n",
      "        [ 1.8184],\n",
      "        [-2.3685]]), tensor([[-1.0662],\n",
      "        [ 1.6613],\n",
      "        [ 1.7258],\n",
      "        ...,\n",
      "        [ 2.2219],\n",
      "        [ 2.3445],\n",
      "        [-2.5476]]), tensor([[ 1.5382],\n",
      "        [ 2.3048],\n",
      "        [-2.2801],\n",
      "        ...,\n",
      "        [ 2.3236],\n",
      "        [ 0.0771],\n",
      "        [ 2.0973]]), tensor([[ 1.9714],\n",
      "        [ 2.3858],\n",
      "        [-2.4623],\n",
      "        ...,\n",
      "        [ 1.9845],\n",
      "        [ 1.6710],\n",
      "        [ 1.1352]]), tensor([[-1.3705],\n",
      "        [ 0.4567],\n",
      "        [ 1.8046],\n",
      "        ...,\n",
      "        [ 1.9187],\n",
      "        [ 2.0893],\n",
      "        [-2.4856]]), tensor([[-0.6116],\n",
      "        [ 2.3414],\n",
      "        [-2.4330],\n",
      "        ...,\n",
      "        [ 2.2200],\n",
      "        [-0.2392],\n",
      "        [ 2.1977]]), tensor([[ 2.2166],\n",
      "        [ 2.3402],\n",
      "        [-2.1778],\n",
      "        ...,\n",
      "        [ 2.3436],\n",
      "        [ 1.4146],\n",
      "        [ 2.6394]]), tensor([[ 1.6461],\n",
      "        [ 2.3847],\n",
      "        [-2.3291],\n",
      "        ...,\n",
      "        [ 2.0782],\n",
      "        [-0.3387],\n",
      "        [ 2.1672]]), tensor([[ 0.4474],\n",
      "        [ 2.2815],\n",
      "        [-2.4051],\n",
      "        ...,\n",
      "        [ 2.1347],\n",
      "        [ 0.0441],\n",
      "        [ 1.6336]]), tensor([[ 1.4211],\n",
      "        [ 2.3602],\n",
      "        [-2.3980],\n",
      "        ...,\n",
      "        [ 2.2572],\n",
      "        [ 0.5969],\n",
      "        [ 1.6520]]), tensor([[ 1.9675],\n",
      "        [ 2.4477],\n",
      "        [-2.2766],\n",
      "        ...,\n",
      "        [ 2.2720],\n",
      "        [-0.2749],\n",
      "        [ 2.1819]]), tensor([[ 1.8553],\n",
      "        [ 2.3045],\n",
      "        [-2.4087],\n",
      "        ...,\n",
      "        [ 2.3463],\n",
      "        [ 0.1971],\n",
      "        [ 2.1484]]), tensor([[-0.4563],\n",
      "        [-0.8103],\n",
      "        [ 1.6957],\n",
      "        ...,\n",
      "        [ 1.5731],\n",
      "        [ 2.3749],\n",
      "        [-2.4457]]), tensor([[-1.4252],\n",
      "        [ 0.7943],\n",
      "        [ 1.3545],\n",
      "        ...,\n",
      "        [ 2.1687],\n",
      "        [ 2.3468],\n",
      "        [-2.2544]]), tensor([[ 0.9728],\n",
      "        [ 2.3625],\n",
      "        [-2.1470],\n",
      "        ...,\n",
      "        [ 2.2376],\n",
      "        [ 0.4249],\n",
      "        [ 2.0532]]), tensor([[ 0.4890],\n",
      "        [ 2.3355],\n",
      "        [-2.3968],\n",
      "        ...,\n",
      "        [ 2.0949],\n",
      "        [ 0.6919],\n",
      "        [ 1.9693]]), tensor([[ 1.7603],\n",
      "        [ 2.3612],\n",
      "        [-2.3658],\n",
      "        ...,\n",
      "        [ 1.8718],\n",
      "        [ 0.0177],\n",
      "        [ 2.0397]]), tensor([[-1.5121],\n",
      "        [-0.4565],\n",
      "        [ 2.0916],\n",
      "        ...,\n",
      "        [-1.7603],\n",
      "        [ 2.5141],\n",
      "        [-2.3957]]), tensor([[ 1.6986],\n",
      "        [ 2.4318],\n",
      "        [-2.3661],\n",
      "        ...,\n",
      "        [ 2.3766],\n",
      "        [ 0.2647],\n",
      "        [ 1.7433]]), tensor([[ 1.8869],\n",
      "        [ 2.3658],\n",
      "        [-2.4052],\n",
      "        ...,\n",
      "        [ 2.4361],\n",
      "        [ 0.4269],\n",
      "        [ 2.1805]]), tensor([[-0.0054],\n",
      "        [ 2.4307],\n",
      "        [-2.2197],\n",
      "        ...,\n",
      "        [ 2.2637],\n",
      "        [ 0.1861],\n",
      "        [ 1.9334]]), tensor([[ 1.0781],\n",
      "        [ 0.3357],\n",
      "        [ 0.5887],\n",
      "        ...,\n",
      "        [-1.5162],\n",
      "        [ 2.2707],\n",
      "        [-2.5019]]), tensor([[ 1.6017],\n",
      "        [ 2.3927],\n",
      "        [-1.9236],\n",
      "        ...,\n",
      "        [ 2.3264],\n",
      "        [-0.0445],\n",
      "        [ 2.0482]]), tensor([[ 0.3247],\n",
      "        [ 2.3507],\n",
      "        [-2.3349],\n",
      "        ...,\n",
      "        [ 2.3221],\n",
      "        [ 0.4467],\n",
      "        [ 2.2092]]), tensor([[ 1.7079],\n",
      "        [ 2.4164],\n",
      "        [-2.2868],\n",
      "        ...,\n",
      "        [ 2.1234],\n",
      "        [-0.4523],\n",
      "        [ 2.4806]]), tensor([[-0.3658],\n",
      "        [-0.1139],\n",
      "        [-0.5935],\n",
      "        ...,\n",
      "        [ 2.0092],\n",
      "        [ 1.9198],\n",
      "        [-2.0960]]), tensor([[ 1.5971],\n",
      "        [ 2.3430],\n",
      "        [-2.2861],\n",
      "        ...,\n",
      "        [ 2.1391],\n",
      "        [ 0.3848],\n",
      "        [ 1.6866]]), tensor([[-1.5239],\n",
      "        [ 0.4779],\n",
      "        [ 1.0938],\n",
      "        ...,\n",
      "        [ 2.0564],\n",
      "        [ 2.3499],\n",
      "        [-2.4879]]), tensor([[-1.5400],\n",
      "        [ 0.5365],\n",
      "        [ 1.4615],\n",
      "        ...,\n",
      "        [ 2.2377],\n",
      "        [ 2.5349],\n",
      "        [-2.4283]]), tensor([[ 1.6920],\n",
      "        [ 2.3950],\n",
      "        [-2.4728],\n",
      "        ...,\n",
      "        [ 2.2113],\n",
      "        [-0.3455],\n",
      "        [ 1.5029]]), tensor([[ 1.9283],\n",
      "        [ 2.3529],\n",
      "        [-2.4497],\n",
      "        ...,\n",
      "        [ 2.2856],\n",
      "        [-0.1615],\n",
      "        [ 2.1932]]), tensor([[-1.9215],\n",
      "        [ 0.6058],\n",
      "        [ 1.6476],\n",
      "        ...,\n",
      "        [ 2.4131],\n",
      "        [ 2.5447],\n",
      "        [-2.4842]]), tensor([[-0.7409],\n",
      "        [ 2.3440],\n",
      "        [-1.6229],\n",
      "        ...,\n",
      "        [ 2.1503],\n",
      "        [ 0.1418],\n",
      "        [ 1.9720]]), tensor([[ 1.6687],\n",
      "        [ 2.4117],\n",
      "        [-2.4260],\n",
      "        ...,\n",
      "        [ 1.7433],\n",
      "        [-0.4349],\n",
      "        [ 1.6272]]), tensor([[-0.6230],\n",
      "        [-0.6480],\n",
      "        [ 1.2616],\n",
      "        ...,\n",
      "        [ 2.0586],\n",
      "        [ 2.0941],\n",
      "        [-2.4558]]), tensor([[ 2.2250],\n",
      "        [ 2.4571],\n",
      "        [-2.3902],\n",
      "        ...,\n",
      "        [ 1.8157],\n",
      "        [-0.0995],\n",
      "        [ 2.2618]]), tensor([[ 0.6695],\n",
      "        [ 2.3881],\n",
      "        [-2.3922],\n",
      "        ...,\n",
      "        [ 2.3351],\n",
      "        [ 0.2849],\n",
      "        [ 2.2560]]), tensor([[-1.5263],\n",
      "        [ 0.0117],\n",
      "        [ 1.2279],\n",
      "        ...,\n",
      "        [ 2.0783],\n",
      "        [ 2.3881],\n",
      "        [-2.3515]]), tensor([[-0.3568],\n",
      "        [-0.3904],\n",
      "        [ 1.4431],\n",
      "        ...,\n",
      "        [ 0.8856],\n",
      "        [ 2.2951],\n",
      "        [-2.4154]]), tensor([[-0.7217],\n",
      "        [-0.4082],\n",
      "        [-0.9215],\n",
      "        ...,\n",
      "        [ 1.9276],\n",
      "        [ 1.9013],\n",
      "        [-2.6689]]), tensor([[-1.5602],\n",
      "        [ 1.1329],\n",
      "        [ 1.3983],\n",
      "        ...,\n",
      "        [ 1.9356],\n",
      "        [ 2.5112],\n",
      "        [-2.3716]]), tensor([[-1.5647],\n",
      "        [ 2.4169],\n",
      "        [-2.2566],\n",
      "        ...,\n",
      "        [ 2.1175],\n",
      "        [-0.2471],\n",
      "        [ 2.1044]]), tensor([[-1.6366],\n",
      "        [-1.0873],\n",
      "        [ 1.7072],\n",
      "        ...,\n",
      "        [ 2.2278],\n",
      "        [ 2.2942],\n",
      "        [-2.3469]]), tensor([[-1.4750],\n",
      "        [ 0.2017],\n",
      "        [ 2.0774],\n",
      "        ...,\n",
      "        [ 2.0948],\n",
      "        [ 2.4326],\n",
      "        [-2.4179]])]\n",
      "Explainer::Iteration 10 of 10\n",
      "[tensor([[ 1.7000],\n",
      "        [ 2.4155],\n",
      "        [-2.3103],\n",
      "        ...,\n",
      "        [ 2.1202],\n",
      "        [ 0.3785],\n",
      "        [ 2.4206]]), tensor([[-1.5188],\n",
      "        [ 0.3013],\n",
      "        [ 1.9553],\n",
      "        ...,\n",
      "        [ 2.2280],\n",
      "        [ 2.4116],\n",
      "        [-2.4225]]), tensor([[ 0.4593],\n",
      "        [ 2.3518],\n",
      "        [-2.3697],\n",
      "        ...,\n",
      "        [ 2.2538],\n",
      "        [ 0.2281],\n",
      "        [ 2.2270]]), tensor([[ 2.1650],\n",
      "        [ 2.3556],\n",
      "        [-2.2891],\n",
      "        ...,\n",
      "        [ 2.1640],\n",
      "        [ 0.2412],\n",
      "        [ 1.3798]]), tensor([[ 1.7341],\n",
      "        [ 2.3207],\n",
      "        [-2.4589],\n",
      "        ...,\n",
      "        [ 1.4163],\n",
      "        [-0.3187],\n",
      "        [ 1.6573]]), tensor([[ 0.5360],\n",
      "        [ 2.4363],\n",
      "        [-2.2801],\n",
      "        ...,\n",
      "        [ 2.2009],\n",
      "        [ 0.1040],\n",
      "        [ 1.7780]]), tensor([[ 1.6629],\n",
      "        [ 2.3222],\n",
      "        [-2.3123],\n",
      "        ...,\n",
      "        [ 1.6027],\n",
      "        [-0.3252],\n",
      "        [ 2.1351]]), tensor([[ 2.0491],\n",
      "        [ 2.2105],\n",
      "        [-2.2829],\n",
      "        ...,\n",
      "        [ 2.3006],\n",
      "        [ 0.2513],\n",
      "        [ 1.6203]]), tensor([[-1.6574],\n",
      "        [ 0.2190],\n",
      "        [ 1.7028],\n",
      "        ...,\n",
      "        [ 2.2792],\n",
      "        [ 2.3752],\n",
      "        [-2.4348]]), tensor([[ 1.5837],\n",
      "        [ 2.3367],\n",
      "        [-2.4532],\n",
      "        ...,\n",
      "        [ 2.2730],\n",
      "        [ 0.1975],\n",
      "        [ 1.7722]]), tensor([[ 2.0317],\n",
      "        [ 2.4345],\n",
      "        [-2.3260],\n",
      "        ...,\n",
      "        [ 2.3405],\n",
      "        [ 0.2711],\n",
      "        [ 1.7063]]), tensor([[ 1.6622],\n",
      "        [ 2.3964],\n",
      "        [-2.2363],\n",
      "        ...,\n",
      "        [ 2.0953],\n",
      "        [-0.0276],\n",
      "        [ 1.8440]]), tensor([[ 1.9083],\n",
      "        [ 2.2914],\n",
      "        [-2.3143],\n",
      "        ...,\n",
      "        [ 2.1779],\n",
      "        [-0.0562],\n",
      "        [ 2.7001]]), tensor([[-1.6029],\n",
      "        [ 0.2644],\n",
      "        [ 0.8100],\n",
      "        ...,\n",
      "        [ 1.9837],\n",
      "        [ 2.1862],\n",
      "        [-2.4453]]), tensor([[-1.5995],\n",
      "        [ 0.2379],\n",
      "        [ 1.6911],\n",
      "        ...,\n",
      "        [ 1.5629],\n",
      "        [ 2.3533],\n",
      "        [-2.3362]]), tensor([[-0.1181],\n",
      "        [-0.8331],\n",
      "        [ 1.0296],\n",
      "        ...,\n",
      "        [ 2.5823],\n",
      "        [ 1.9568],\n",
      "        [-2.9493]]), tensor([[ 0.9602],\n",
      "        [ 2.3425],\n",
      "        [-2.4476],\n",
      "        ...,\n",
      "        [ 2.3138],\n",
      "        [ 0.1516],\n",
      "        [ 1.7092]]), tensor([[ 1.2745],\n",
      "        [ 2.4103],\n",
      "        [-2.3401],\n",
      "        ...,\n",
      "        [ 2.2297],\n",
      "        [-0.1304],\n",
      "        [ 2.4521]]), tensor([[ 1.7475],\n",
      "        [ 2.5317],\n",
      "        [-2.3431],\n",
      "        ...,\n",
      "        [ 2.0884],\n",
      "        [-0.5018],\n",
      "        [ 2.2068]]), tensor([[-0.8490],\n",
      "        [ 1.1931],\n",
      "        [ 2.6494],\n",
      "        ...,\n",
      "        [ 0.9241],\n",
      "        [ 2.1911],\n",
      "        [-2.4923]]), tensor([[ 1.9509],\n",
      "        [ 2.3330],\n",
      "        [-2.2793],\n",
      "        ...,\n",
      "        [ 2.1680],\n",
      "        [-0.1321],\n",
      "        [ 2.2315]]), tensor([[ 1.9128],\n",
      "        [ 2.3372],\n",
      "        [-2.3803],\n",
      "        ...,\n",
      "        [ 1.8922],\n",
      "        [ 0.0224],\n",
      "        [ 2.3710]]), tensor([[-0.7396],\n",
      "        [ 0.1560],\n",
      "        [ 1.6306],\n",
      "        ...,\n",
      "        [ 3.1542],\n",
      "        [ 2.3517],\n",
      "        [-2.3477]]), tensor([[-1.4674],\n",
      "        [ 1.1989],\n",
      "        [ 0.2250],\n",
      "        ...,\n",
      "        [ 2.2485],\n",
      "        [ 1.9869],\n",
      "        [-2.5853]]), tensor([[ 1.8611],\n",
      "        [ 2.4346],\n",
      "        [-2.3198],\n",
      "        ...,\n",
      "        [ 2.2418],\n",
      "        [-0.0084],\n",
      "        [ 1.8694]]), tensor([[ 1.6891],\n",
      "        [ 2.3699],\n",
      "        [-2.1795],\n",
      "        ...,\n",
      "        [ 1.7991],\n",
      "        [-0.3176],\n",
      "        [ 1.8121]]), tensor([[ 1.5139],\n",
      "        [ 2.2684],\n",
      "        [-2.3328],\n",
      "        ...,\n",
      "        [ 2.1170],\n",
      "        [-0.4729],\n",
      "        [ 2.0755]]), tensor([[-1.1179],\n",
      "        [-0.8284],\n",
      "        [ 2.0082],\n",
      "        ...,\n",
      "        [ 2.2929],\n",
      "        [ 2.4651],\n",
      "        [-2.4453]]), tensor([[-1.5008],\n",
      "        [ 2.1765],\n",
      "        [ 0.6376],\n",
      "        ...,\n",
      "        [ 2.2024],\n",
      "        [ 2.5654],\n",
      "        [-2.4642]]), tensor([[ 1.5683],\n",
      "        [ 2.4079],\n",
      "        [-2.3838],\n",
      "        ...,\n",
      "        [ 1.9367],\n",
      "        [-0.5645],\n",
      "        [ 2.0662]]), tensor([[ 1.8404],\n",
      "        [ 2.3473],\n",
      "        [-2.2579],\n",
      "        ...,\n",
      "        [ 2.2112],\n",
      "        [-0.2103],\n",
      "        [ 2.3622]]), tensor([[-1.3536],\n",
      "        [ 0.2911],\n",
      "        [-1.1543],\n",
      "        ...,\n",
      "        [ 2.4665],\n",
      "        [ 1.6461],\n",
      "        [-2.4060]]), tensor([[-1.3997],\n",
      "        [-0.9178],\n",
      "        [ 1.9507],\n",
      "        ...,\n",
      "        [ 2.1086],\n",
      "        [ 2.3003],\n",
      "        [-2.3674]]), tensor([[-0.2669],\n",
      "        [ 2.2682],\n",
      "        [-2.3257],\n",
      "        ...,\n",
      "        [ 2.2952],\n",
      "        [-0.6436],\n",
      "        [ 1.9069]]), tensor([[-1.2794],\n",
      "        [ 0.3517],\n",
      "        [ 1.9242],\n",
      "        ...,\n",
      "        [-0.1414],\n",
      "        [ 2.4402],\n",
      "        [-2.2261]]), tensor([[ 1.4801],\n",
      "        [ 2.3362],\n",
      "        [-2.2805],\n",
      "        ...,\n",
      "        [ 2.2250],\n",
      "        [ 0.2571],\n",
      "        [ 2.0185]]), tensor([[-1.2059],\n",
      "        [ 0.1875],\n",
      "        [ 0.5518],\n",
      "        ...,\n",
      "        [ 2.2084],\n",
      "        [ 1.7493],\n",
      "        [-2.2916]]), tensor([[-0.9555],\n",
      "        [ 1.6787],\n",
      "        [ 1.9743],\n",
      "        ...,\n",
      "        [ 2.2649],\n",
      "        [ 2.4241],\n",
      "        [-2.4991]]), tensor([[ 1.5957],\n",
      "        [ 2.3799],\n",
      "        [-2.2577],\n",
      "        ...,\n",
      "        [ 2.2345],\n",
      "        [ 0.3763],\n",
      "        [ 2.0346]]), tensor([[ 1.9677],\n",
      "        [ 2.3196],\n",
      "        [-2.3030],\n",
      "        ...,\n",
      "        [ 2.0574],\n",
      "        [ 1.5396],\n",
      "        [ 1.0953]]), tensor([[-1.4039],\n",
      "        [ 0.4434],\n",
      "        [ 1.5568],\n",
      "        ...,\n",
      "        [ 1.9889],\n",
      "        [ 2.1164],\n",
      "        [-2.5748]]), tensor([[-0.4475],\n",
      "        [ 2.3337],\n",
      "        [-2.2965],\n",
      "        ...,\n",
      "        [ 2.2376],\n",
      "        [-0.1863],\n",
      "        [ 2.3385]]), tensor([[ 2.1767],\n",
      "        [ 2.3486],\n",
      "        [-2.2279],\n",
      "        ...,\n",
      "        [ 2.3068],\n",
      "        [ 1.2423],\n",
      "        [ 2.6701]]), tensor([[ 1.6445],\n",
      "        [ 2.3957],\n",
      "        [-2.1637],\n",
      "        ...,\n",
      "        [ 2.0463],\n",
      "        [-0.3900],\n",
      "        [ 2.3892]]), tensor([[ 0.3362],\n",
      "        [ 2.2478],\n",
      "        [-2.3190],\n",
      "        ...,\n",
      "        [ 2.1334],\n",
      "        [-0.0183],\n",
      "        [ 1.7537]]), tensor([[ 1.4375],\n",
      "        [ 2.3045],\n",
      "        [-2.2987],\n",
      "        ...,\n",
      "        [ 2.3175],\n",
      "        [ 0.2797],\n",
      "        [ 1.5954]]), tensor([[ 2.0338],\n",
      "        [ 2.3891],\n",
      "        [-2.3134],\n",
      "        ...,\n",
      "        [ 2.2607],\n",
      "        [-0.2735],\n",
      "        [ 2.0932]]), tensor([[ 1.8065],\n",
      "        [ 2.4012],\n",
      "        [-2.2502],\n",
      "        ...,\n",
      "        [ 2.3935],\n",
      "        [ 0.2766],\n",
      "        [ 2.2533]]), tensor([[-0.4995],\n",
      "        [-0.7913],\n",
      "        [ 1.7929],\n",
      "        ...,\n",
      "        [ 1.5457],\n",
      "        [ 2.3566],\n",
      "        [-2.4280]]), tensor([[-1.5256],\n",
      "        [ 0.8026],\n",
      "        [ 1.5412],\n",
      "        ...,\n",
      "        [ 2.3203],\n",
      "        [ 2.3405],\n",
      "        [-2.3830]]), tensor([[ 0.7833],\n",
      "        [ 2.3413],\n",
      "        [-2.3022],\n",
      "        ...,\n",
      "        [ 2.1004],\n",
      "        [ 0.4916],\n",
      "        [ 1.5439]]), tensor([[ 0.5679],\n",
      "        [ 2.2557],\n",
      "        [-2.2714],\n",
      "        ...,\n",
      "        [ 2.2442],\n",
      "        [ 0.4555],\n",
      "        [ 1.9881]]), tensor([[ 1.7875],\n",
      "        [ 2.4910],\n",
      "        [-2.2884],\n",
      "        ...,\n",
      "        [ 1.9433],\n",
      "        [-0.0703],\n",
      "        [ 2.1743]]), tensor([[-1.4574],\n",
      "        [-0.4626],\n",
      "        [ 2.2365],\n",
      "        ...,\n",
      "        [-1.8255],\n",
      "        [ 2.5641],\n",
      "        [-2.4819]]), tensor([[ 1.5402],\n",
      "        [ 2.3605],\n",
      "        [-2.3233],\n",
      "        ...,\n",
      "        [ 2.2705],\n",
      "        [ 0.2220],\n",
      "        [ 1.5441]]), tensor([[ 1.8718],\n",
      "        [ 2.4436],\n",
      "        [-2.4498],\n",
      "        ...,\n",
      "        [ 2.2811],\n",
      "        [ 0.7224],\n",
      "        [ 2.0159]]), tensor([[ 0.2151],\n",
      "        [ 2.4457],\n",
      "        [-2.2048],\n",
      "        ...,\n",
      "        [ 2.2480],\n",
      "        [ 0.4402],\n",
      "        [ 2.0885]]), tensor([[ 0.6231],\n",
      "        [ 0.2165],\n",
      "        [ 0.3547],\n",
      "        ...,\n",
      "        [-1.8708],\n",
      "        [ 2.1974],\n",
      "        [-2.6367]]), tensor([[ 1.7213],\n",
      "        [ 2.3313],\n",
      "        [-1.8464],\n",
      "        ...,\n",
      "        [ 2.1360],\n",
      "        [ 0.6599],\n",
      "        [ 2.1622]]), tensor([[ 0.3851],\n",
      "        [ 2.3673],\n",
      "        [-2.3380],\n",
      "        ...,\n",
      "        [ 2.3475],\n",
      "        [ 0.4390],\n",
      "        [ 2.1386]]), tensor([[ 1.6544],\n",
      "        [ 2.4585],\n",
      "        [-2.3486],\n",
      "        ...,\n",
      "        [ 2.0834],\n",
      "        [-0.5075],\n",
      "        [ 2.4030]]), tensor([[-0.4314],\n",
      "        [-0.1230],\n",
      "        [-0.2051],\n",
      "        ...,\n",
      "        [ 1.9291],\n",
      "        [ 1.8570],\n",
      "        [-2.0615]]), tensor([[ 1.7506],\n",
      "        [ 2.4974],\n",
      "        [-2.3675],\n",
      "        ...,\n",
      "        [ 2.3266],\n",
      "        [-1.0743],\n",
      "        [ 1.8314]]), tensor([[-1.3391],\n",
      "        [ 0.4666],\n",
      "        [ 0.7884],\n",
      "        ...,\n",
      "        [ 1.7582],\n",
      "        [ 2.5048],\n",
      "        [-2.5458]]), tensor([[-1.4653],\n",
      "        [ 0.5478],\n",
      "        [ 1.0660],\n",
      "        ...,\n",
      "        [ 2.2377],\n",
      "        [ 2.4491],\n",
      "        [-2.3218]]), tensor([[ 1.5342],\n",
      "        [ 2.3064],\n",
      "        [-2.3179],\n",
      "        ...,\n",
      "        [ 2.1623],\n",
      "        [-0.4076],\n",
      "        [ 1.6401]]), tensor([[ 1.9229],\n",
      "        [ 2.4457],\n",
      "        [-2.2431],\n",
      "        ...,\n",
      "        [ 2.2344],\n",
      "        [-0.4336],\n",
      "        [ 1.5961]]), tensor([[-1.6632],\n",
      "        [ 0.5430],\n",
      "        [ 1.5342],\n",
      "        ...,\n",
      "        [ 2.3263],\n",
      "        [ 2.5152],\n",
      "        [-2.3322]]), tensor([[-0.6978],\n",
      "        [ 2.2989],\n",
      "        [-1.7220],\n",
      "        ...,\n",
      "        [ 2.1813],\n",
      "        [ 0.1818],\n",
      "        [ 2.0113]]), tensor([[ 1.5475],\n",
      "        [ 2.3367],\n",
      "        [-2.2331],\n",
      "        ...,\n",
      "        [ 1.8733],\n",
      "        [-0.4121],\n",
      "        [ 1.6192]]), tensor([[-0.5027],\n",
      "        [-0.6739],\n",
      "        [ 1.1438],\n",
      "        ...,\n",
      "        [ 2.0440],\n",
      "        [ 2.0816],\n",
      "        [-2.5328]]), tensor([[ 2.2277],\n",
      "        [ 2.3664],\n",
      "        [-2.2858],\n",
      "        ...,\n",
      "        [ 1.9287],\n",
      "        [-0.0676],\n",
      "        [ 2.1184]]), tensor([[ 0.5243],\n",
      "        [ 2.3420],\n",
      "        [-2.3013],\n",
      "        ...,\n",
      "        [ 2.2964],\n",
      "        [ 0.2678],\n",
      "        [ 2.3881]]), tensor([[-1.3726],\n",
      "        [ 0.0093],\n",
      "        [ 1.3952],\n",
      "        ...,\n",
      "        [ 2.0524],\n",
      "        [ 2.4963],\n",
      "        [-2.4031]]), tensor([[-0.6595],\n",
      "        [-0.3734],\n",
      "        [ 1.3517],\n",
      "        ...,\n",
      "        [ 0.9932],\n",
      "        [ 2.4048],\n",
      "        [-2.4842]]), tensor([[-0.7086],\n",
      "        [-0.3908],\n",
      "        [-0.9660],\n",
      "        ...,\n",
      "        [ 1.9447],\n",
      "        [ 1.6504],\n",
      "        [-2.7663]]), tensor([[-1.5582],\n",
      "        [ 1.1458],\n",
      "        [ 1.1450],\n",
      "        ...,\n",
      "        [ 1.9882],\n",
      "        [ 2.4822],\n",
      "        [-2.3734]]), tensor([[-1.1127],\n",
      "        [ 2.3988],\n",
      "        [-2.3560],\n",
      "        ...,\n",
      "        [ 2.1321],\n",
      "        [-0.1873],\n",
      "        [ 2.0691]]), tensor([[-1.6319],\n",
      "        [-1.0811],\n",
      "        [ 1.6553],\n",
      "        ...,\n",
      "        [ 2.2569],\n",
      "        [ 2.4396],\n",
      "        [-2.3858]]), tensor([[-1.5983],\n",
      "        [ 0.2088],\n",
      "        [ 1.9267],\n",
      "        ...,\n",
      "        [ 2.1581],\n",
      "        [ 2.5184],\n",
      "        [-2.4101]])]\n"
     ]
    }
   ],
   "source": [
    "g.explain(10, gnn_subnet=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[[0,\n  8,\n  9,\n  17,\n  52,\n  53,\n  54,\n  55,\n  56,\n  57,\n  58,\n  59,\n  61,\n  62,\n  70,\n  71,\n  76,\n  123,\n  124,\n  125,\n  126,\n  127,\n  128,\n  198,\n  226,\n  227,\n  229,\n  231,\n  232,\n  233,\n  234,\n  235,\n  236,\n  237,\n  270,\n  297,\n  334,\n  355,\n  357,\n  358,\n  396,\n  397,\n  398,\n  405,\n  406,\n  429,\n  511,\n  512,\n  535,\n  570,\n  619,\n  620,\n  650,\n  656,\n  685,\n  686,\n  717,\n  731,\n  732,\n  733,\n  734,\n  751,\n  752,\n  753,\n  768,\n  769,\n  835,\n  847,\n  850,\n  934,\n  953,\n  954,\n  995,\n  1018,\n  1023,\n  1033,\n  1039,\n  1043,\n  1046,\n  1049,\n  1110,\n  1129,\n  1152,\n  1303,\n  1304,\n  1327,\n  1333,\n  1334,\n  1335,\n  1346,\n  1401,\n  1418,\n  1420,\n  1434,\n  1468,\n  1469,\n  1481,\n  1482,\n  1533,\n  1562,\n  1563,\n  1570,\n  1660,\n  1665,\n  1666,\n  1667,\n  1669,\n  1694,\n  1695,\n  1696,\n  1733,\n  1806,\n  1842,\n  1846,\n  1914,\n  1981],\n [1,\n  14,\n  15,\n  19,\n  20,\n  21,\n  22,\n  23,\n  24,\n  25,\n  26,\n  27,\n  28,\n  68,\n  85,\n  86,\n  166,\n  167,\n  169,\n  170,\n  177,\n  220,\n  404,\n  407,\n  408,\n  414,\n  545,\n  632,\n  647,\n  648,\n  701,\n  707,\n  708,\n  712,\n  713,\n  736,\n  748,\n  749,\n  779,\n  781,\n  782,\n  815,\n  816,\n  817,\n  818,\n  819,\n  821,\n  822,\n  823,\n  836,\n  855,\n  941,\n  962,\n  1036,\n  1082,\n  1083,\n  1114,\n  1226,\n  1301,\n  1308,\n  1322,\n  1324,\n  1325,\n  1326,\n  1338,\n  1339,\n  1342,\n  1343,\n  1354,\n  1355,\n  1356,\n  1357,\n  1358,\n  1359,\n  1365,\n  1391,\n  1518,\n  1519,\n  1520,\n  1691,\n  1692,\n  1693,\n  1759,\n  1860,\n  1866,\n  1942],\n [2,\n  3,\n  186,\n  187,\n  188,\n  265,\n  281,\n  282,\n  283,\n  449,\n  583,\n  629,\n  630,\n  631,\n  853,\n  854,\n  1076,\n  1122,\n  1521,\n  1536,\n  1537,\n  1619,\n  1819,\n  2025],\n [4,\n  63,\n  82,\n  83,\n  84,\n  95,\n  96,\n  152,\n  163,\n  250,\n  369,\n  370,\n  371,\n  399,\n  671,\n  687,\n  688,\n  699,\n  705,\n  706,\n  727,\n  728,\n  730,\n  737,\n  738,\n  739,\n  741,\n  883,\n  1047,\n  1145,\n  1146,\n  1147,\n  1149,\n  1150,\n  1353,\n  1442,\n  1443,\n  1444,\n  1445,\n  1446,\n  1512,\n  1513,\n  1515,\n  1566,\n  1569,\n  1690,\n  1700,\n  1721,\n  1786,\n  1787,\n  1788,\n  1789,\n  1790,\n  1798,\n  1804,\n  1868,\n  1924,\n  1950,\n  1951,\n  1990,\n  1991],\n [5,\n  7,\n  64,\n  74,\n  147,\n  148,\n  155,\n  156,\n  165,\n  179,\n  181,\n  185,\n  196,\n  217,\n  238,\n  239,\n  254,\n  255,\n  256,\n  264,\n  273,\n  292,\n  338,\n  339,\n  340,\n  403,\n  410,\n  434,\n  459,\n  499,\n  500,\n  501,\n  532,\n  536,\n  543,\n  572,\n  599,\n  600,\n  601,\n  602,\n  616,\n  617,\n  623,\n  669,\n  700,\n  785,\n  786,\n  787,\n  788,\n  789,\n  798,\n  801,\n  803,\n  804,\n  805,\n  806,\n  807,\n  808,\n  809,\n  810,\n  811,\n  812,\n  824,\n  947,\n  949,\n  952,\n  957,\n  958,\n  959,\n  1079,\n  1080,\n  1092,\n  1098,\n  1099,\n  1100,\n  1101,\n  1102,\n  1103,\n  1104,\n  1105,\n  1143,\n  1144,\n  1163,\n  1168,\n  1169,\n  1200,\n  1201,\n  1202,\n  1203,\n  1204,\n  1205,\n  1206,\n  1214,\n  1218,\n  1219,\n  1250,\n  1262,\n  1263,\n  1264,\n  1266,\n  1268,\n  1272,\n  1320,\n  1348,\n  1360,\n  1361,\n  1362,\n  1363,\n  1364,\n  1392,\n  1406,\n  1437,\n  1438,\n  1439,\n  1440,\n  1441,\n  1457,\n  1458,\n  1461,\n  1534,\n  1535,\n  1556,\n  1610,\n  1615,\n  1670,\n  1687,\n  1725,\n  1810,\n  1827,\n  1828,\n  1843,\n  1844,\n  1853,\n  1854,\n  1862,\n  1899,\n  1934,\n  1940,\n  1947,\n  2032],\n [6,\n  117,\n  122,\n  158,\n  164,\n  171,\n  172,\n  178,\n  180,\n  182,\n  193,\n  203,\n  210,\n  211,\n  213,\n  216,\n  257,\n  303,\n  309,\n  311,\n  342,\n  353,\n  395,\n  431,\n  451,\n  453,\n  454,\n  456,\n  458,\n  472,\n  491,\n  502,\n  530,\n  531,\n  546,\n  547,\n  590,\n  591,\n  592,\n  593,\n  594,\n  605,\n  625,\n  626,\n  627,\n  637,\n  641,\n  777,\n  780,\n  792,\n  800,\n  802,\n  910,\n  948,\n  1024,\n  1025,\n  1085,\n  1086,\n  1088,\n  1089,\n  1090,\n  1093,\n  1095,\n  1096,\n  1123,\n  1124,\n  1130,\n  1137,\n  1138,\n  1139,\n  1140,\n  1141,\n  1158,\n  1160,\n  1277,\n  1313,\n  1316,\n  1321,\n  1407,\n  1416,\n  1417,\n  1422,\n  1423,\n  1424,\n  1425,\n  1426,\n  1427,\n  1436,\n  1451,\n  1452,\n  1460,\n  1462,\n  1476,\n  1522,\n  1525,\n  1526,\n  1527,\n  1545,\n  1560,\n  1561,\n  1568,\n  1576,\n  1603,\n  1607,\n  1728,\n  1747,\n  1857,\n  1885,\n  1886,\n  1887,\n  1888,\n  1901,\n  1903,\n  1959,\n  1961,\n  1966,\n  2000,\n  2011,\n  2019,\n  2020,\n  2021,\n  2022,\n  2035,\n  2037,\n  2038,\n  2039,\n  2040,\n  2042],\n [10,\n  157,\n  305,\n  313,\n  360,\n  361,\n  362,\n  363,\n  364,\n  465,\n  492,\n  493,\n  494,\n  496,\n  508,\n  537,\n  538,\n  539,\n  548,\n  549,\n  550,\n  551,\n  552,\n  553,\n  554,\n  555,\n  556,\n  557,\n  558,\n  559,\n  595,\n  697,\n  837,\n  838,\n  839,\n  840,\n  841,\n  842,\n  843,\n  844,\n  846,\n  1053,\n  1265,\n  1331,\n  1340,\n  1388,\n  1389,\n  1390,\n  1593,\n  1594,\n  1647,\n  1648,\n  1649,\n  1763,\n  1785,\n  1831,\n  1832,\n  1833,\n  1834,\n  1835,\n  1873,\n  1953],\n [11,\n  12,\n  30,\n  31,\n  39,\n  66,\n  107,\n  108,\n  109,\n  110,\n  111,\n  112,\n  113,\n  114,\n  115,\n  116,\n  149,\n  197,\n  240,\n  354,\n  437,\n  438,\n  495,\n  497,\n  498,\n  504,\n  505,\n  564,\n  567,\n  579,\n  581,\n  584,\n  665,\n  678,\n  698,\n  799,\n  863,\n  939,\n  940,\n  1197,\n  1198,\n  1230,\n  1309,\n  1571,\n  1583,\n  1676,\n  1681,\n  1722,\n  1729,\n  1734,\n  1761,\n  1762,\n  1784,\n  1800,\n  1801,\n  1802,\n  1803,\n  1962,\n  1995,\n  1996,\n  1997,\n  1998],\n [13,\n  207,\n  452,\n  460,\n  462,\n  464,\n  480,\n  481,\n  503,\n  534,\n  597,\n  613,\n  634,\n  674,\n  735,\n  791,\n  1132,\n  1164,\n  1189,\n  1199,\n  1239,\n  1243,\n  1244,\n  1245,\n  1246,\n  1247,\n  1319,\n  1330,\n  1352,\n  1372,\n  1428,\n  1517,\n  1549,\n  1604,\n  1605,\n  1606,\n  1689,\n  1823,\n  1915,\n  1968,\n  1969,\n  2002,\n  2005,\n  2023,\n  2030,\n  2031],\n [16,\n  29,\n  34,\n  35,\n  36,\n  37,\n  45,\n  46,\n  47,\n  48,\n  49,\n  50,\n  69,\n  92,\n  100,\n  101,\n  119,\n  151,\n  189,\n  190,\n  204,\n  372,\n  373,\n  374,\n  375,\n  376,\n  377,\n  378,\n  379,\n  380,\n  381,\n  382,\n  383,\n  384,\n  385,\n  386,\n  387,\n  388,\n  389,\n  390,\n  391,\n  392,\n  422,\n  425,\n  507,\n  521,\n  565,\n  568,\n  614,\n  615,\n  635,\n  660,\n  668,\n  676,\n  722,\n  742,\n  745,\n  746,\n  747,\n  755,\n  797,\n  833,\n  834,\n  845,\n  914,\n  915,\n  916,\n  917,\n  918,\n  919,\n  920,\n  921,\n  922,\n  923,\n  924,\n  925,\n  926,\n  928,\n  930,\n  931,\n  932,\n  933,\n  1004,\n  1005,\n  1006,\n  1007,\n  1008,\n  1009,\n  1010,\n  1011,\n  1012,\n  1013,\n  1014,\n  1017,\n  1030,\n  1037,\n  1038,\n  1040,\n  1042,\n  1077,\n  1126,\n  1127,\n  1159,\n  1166,\n  1167,\n  1172,\n  1174,\n  1175,\n  1176,\n  1177,\n  1191,\n  1208,\n  1209,\n  1213,\n  1227,\n  1228,\n  1255,\n  1261,\n  1318,\n  1368,\n  1369,\n  1384,\n  1385,\n  1386,\n  1397,\n  1398,\n  1421,\n  1464,\n  1504,\n  1532,\n  1611,\n  1635,\n  1668,\n  1680,\n  1732,\n  1737,\n  1739,\n  1742,\n  1839,\n  1841,\n  1852,\n  1858,\n  1864,\n  1869,\n  1875,\n  1876,\n  1878,\n  1881,\n  1905,\n  1917,\n  1970,\n  1972,\n  1977,\n  1978,\n  1979,\n  1992,\n  1993],\n [18,\n  60,\n  73,\n  129,\n  183,\n  191,\n  219,\n  259,\n  266,\n  306,\n  307,\n  308,\n  337,\n  341,\n  343,\n  400,\n  401,\n  402,\n  413,\n  416,\n  417,\n  423,\n  426,\n  435,\n  450,\n  461,\n  463,\n  467,\n  468,\n  469,\n  471,\n  473,\n  474,\n  476,\n  477,\n  479,\n  540,\n  560,\n  582,\n  585,\n  603,\n  624,\n  649,\n  659,\n  677,\n  692,\n  704,\n  710,\n  711,\n  744,\n  772,\n  790,\n  820,\n  825,\n  826,\n  827,\n  828,\n  829,\n  849,\n  882,\n  901,\n  902,\n  903,\n  951,\n  963,\n  970,\n  991,\n  998,\n  1001,\n  1081,\n  1097,\n  1112,\n  1186,\n  1312,\n  1314,\n  1317,\n  1323,\n  1341,\n  1393,\n  1419,\n  1459,\n  1483,\n  1484,\n  1485,\n  1486,\n  1487,\n  1488,\n  1489,\n  1498,\n  1523,\n  1544,\n  1547,\n  1548,\n  1550,\n  1551,\n  1552,\n  1618,\n  1620,\n  1623,\n  1634,\n  1671,\n  1672,\n  1673,\n  1674,\n  1685,\n  1697,\n  1704,\n  1714,\n  1715,\n  1716,\n  1717,\n  1726,\n  1727,\n  1764,\n  1765,\n  1767,\n  1797,\n  1799,\n  1822,\n  1826,\n  1845,\n  1877,\n  1918,\n  1919,\n  1952,\n  1956,\n  1957,\n  1986,\n  1999,\n  2003,\n  2015,\n  2024,\n  2026,\n  2041,\n  2044],\n [32,\n  77,\n  94,\n  130,\n  132,\n  133,\n  134,\n  135,\n  136,\n  137,\n  138,\n  139,\n  140,\n  141,\n  143,\n  144,\n  145,\n  251,\n  294,\n  347,\n  445,\n  448,\n  455,\n  482,\n  515,\n  576,\n  577,\n  719,\n  729,\n  852,\n  889,\n  950,\n  1015,\n  1028,\n  1029,\n  1032,\n  1034,\n  1054,\n  1084,\n  1170,\n  1171,\n  1173,\n  1178,\n  1179,\n  1180,\n  1183,\n  1216,\n  1225,\n  1311,\n  1394,\n  1405,\n  1412,\n  1413,\n  1449,\n  1450,\n  1465,\n  1564,\n  1574,\n  1584,\n  1585,\n  1586,\n  1587,\n  1608,\n  1609,\n  1656,\n  1657,\n  1699,\n  1760,\n  1783,\n  1856,\n  1882,\n  1904,\n  1954,\n  1955,\n  2012],\n [33,\n  65,\n  146,\n  184,\n  212,\n  218,\n  279,\n  310,\n  314,\n  315,\n  318,\n  421,\n  427,\n  561,\n  562,\n  563,\n  892,\n  893,\n  894,\n  895,\n  896,\n  897,\n  898,\n  899,\n  942,\n  1019,\n  1187,\n  1215,\n  1429,\n  1453,\n  1454,\n  1455,\n  1456,\n  1480,\n  1577,\n  1580,\n  1590,\n  1596,\n  1705,\n  1706,\n  1707,\n  1708,\n  1749,\n  1766,\n  1768,\n  1791,\n  1792,\n  1793,\n  1825,\n  1994,\n  2034,\n  2043,\n  2045],\n [38,\n  200,\n  351,\n  356,\n  411,\n  457,\n  525,\n  526,\n  527,\n  528,\n  658,\n  858,\n  859,\n  860,\n  861,\n  906,\n  907,\n  966,\n  967,\n  968,\n  974,\n  976,\n  977,\n  979,\n  980,\n  981,\n  983,\n  990,\n  1741,\n  1891,\n  1916,\n  2001,\n  2004],\n [40, 214, 571, 574, 575, 887, 1224, 1811, 1812, 1813, 1814, 1815, 1910],\n [41,\n  42,\n  43,\n  173,\n  205,\n  206,\n  208,\n  275,\n  278,\n  335,\n  344,\n  430,\n  432,\n  433,\n  446,\n  569,\n  621,\n  622,\n  636,\n  638,\n  639,\n  640,\n  642,\n  643,\n  673,\n  709,\n  724,\n  725,\n  726,\n  813,\n  885,\n  886,\n  982,\n  1035,\n  1142,\n  1151,\n  1182,\n  1185,\n  1212,\n  1260,\n  1299,\n  1306,\n  1332,\n  1491,\n  1492,\n  1493,\n  1494,\n  1495,\n  1496,\n  1497,\n  1499,\n  1509,\n  1558,\n  1559,\n  1575,\n  1650,\n  1701,\n  1702,\n  1703,\n  1718,\n  1719,\n  1720,\n  1730,\n  1748,\n  1774,\n  1775,\n  1847,\n  1848,\n  1849,\n  1850,\n  1863,\n  1913,\n  1925,\n  1927,\n  1929,\n  1930,\n  1931,\n  1932,\n  1933,\n  1935,\n  1936,\n  1937,\n  1938,\n  1939,\n  1941,\n  1960,\n  1965,\n  1980,\n  1982,\n  1983,\n  1984,\n  1985,\n  1987,\n  1988,\n  1989,\n  2013,\n  2014,\n  2033],\n [44,\n  80,\n  81,\n  87,\n  93,\n  160,\n  161,\n  162,\n  176,\n  195,\n  202,\n  209,\n  230,\n  271,\n  272,\n  280,\n  284,\n  285,\n  286,\n  287,\n  288,\n  289,\n  290,\n  291,\n  293,\n  295,\n  296,\n  298,\n  299,\n  300,\n  301,\n  312,\n  359,\n  418,\n  419,\n  420,\n  436,\n  447,\n  490,\n  506,\n  541,\n  542,\n  566,\n  578,\n  586,\n  587,\n  588,\n  644,\n  645,\n  646,\n  651,\n  652,\n  653,\n  654,\n  655,\n  657,\n  662,\n  663,\n  664,\n  672,\n  684,\n  693,\n  714,\n  715,\n  716,\n  718,\n  743,\n  750,\n  754,\n  756,\n  862,\n  866,\n  867,\n  868,\n  869,\n  873,\n  874,\n  875,\n  876,\n  877,\n  878,\n  879,\n  880,\n  881,\n  888,\n  890,\n  891,\n  912,\n  927,\n  929,\n  935,\n  944,\n  945,\n  946,\n  960,\n  961,\n  964,\n  985,\n  987,\n  988,\n  989,\n  994,\n  1000,\n  1002,\n  1003,\n  1020,\n  1026,\n  1027,\n  1041,\n  1050,\n  1059,\n  1060,\n  1064,\n  1065,\n  1071,\n  1073,\n  1111,\n  1113,\n  1115,\n  1116,\n  1117,\n  1118,\n  1125,\n  1128,\n  1134,\n  1135,\n  1148,\n  1190,\n  1211,\n  1221,\n  1249,\n  1269,\n  1270,\n  1271,\n  1274,\n  1278,\n  1279,\n  1280,\n  1302,\n  1305,\n  1310,\n  1336,\n  1337,\n  1366,\n  1367,\n  1370,\n  1373,\n  1374,\n  1375,\n  1376,\n  1377,\n  1378,\n  1379,\n  1380,\n  1381,\n  1382,\n  1383,\n  1387,\n  1402,\n  1403,\n  1467,\n  1470,\n  1473,\n  1479,\n  1505,\n  1506,\n  1507,\n  1508,\n  1510,\n  1511,\n  1514,\n  1528,\n  1538,\n  1540,\n  1541,\n  1543,\n  1557,\n  1565,\n  1567,\n  1581,\n  1597,\n  1598,\n  1600,\n  1601,\n  1602,\n  1616,\n  1651,\n  1677,\n  1678,\n  1679,\n  1683,\n  1684,\n  1686,\n  1698,\n  1731,\n  1735,\n  1736,\n  1745,\n  1750,\n  1758,\n  1771,\n  1776,\n  1778,\n  1779,\n  1780,\n  1781,\n  1796,\n  1816,\n  1817,\n  1821,\n  1838,\n  1840,\n  1855,\n  1896,\n  1907,\n  1911,\n  1912,\n  1926,\n  1948,\n  1949,\n  1967,\n  1971,\n  1974,\n  1975,\n  1976,\n  2007,\n  2027,\n  2029],\n [51,\n  75,\n  159,\n  192,\n  194,\n  201,\n  260,\n  261,\n  262,\n  263,\n  267,\n  268,\n  269,\n  346,\n  409,\n  470,\n  475,\n  524,\n  589,\n  703,\n  793,\n  794,\n  857,\n  864,\n  865,\n  870,\n  871,\n  872,\n  908,\n  909,\n  911,\n  1055,\n  1061,\n  1062,\n  1063,\n  1066,\n  1067,\n  1068,\n  1069,\n  1072,\n  1078,\n  1106,\n  1161,\n  1162,\n  1220,\n  1222,\n  1223,\n  1234,\n  1235,\n  1236,\n  1237,\n  1238,\n  1242,\n  1295,\n  1296,\n  1297,\n  1298,\n  1307,\n  1347,\n  1472,\n  1475,\n  1554,\n  1555,\n  1572,\n  1573,\n  1578,\n  1579,\n  1599,\n  1617,\n  1621,\n  1777,\n  1820,\n  1865,\n  1870,\n  1871,\n  1890,\n  1892,\n  1893,\n  1900,\n  1928,\n  1964,\n  2028,\n  2047],\n [67,\n  118,\n  153,\n  168,\n  241,\n  242,\n  243,\n  244,\n  245,\n  246,\n  247,\n  248,\n  249,\n  252,\n  253,\n  345,\n  483,\n  484,\n  485,\n  486,\n  487,\n  573,\n  757,\n  758,\n  759,\n  760,\n  761,\n  762,\n  763,\n  764,\n  765,\n  766,\n  767,\n  770,\n  848,\n  1048,\n  1074,\n  1075,\n  1094,\n  1232,\n  1233,\n  1248,\n  1275,\n  1276,\n  1371,\n  1404,\n  1471,\n  1474,\n  1539,\n  1612,\n  1613,\n  1614,\n  1682,\n  1805,\n  1897],\n [72,\n  79,\n  88,\n  228,\n  274,\n  317,\n  322,\n  324,\n  325,\n  326,\n  327,\n  328,\n  329,\n  330,\n  331,\n  332,\n  633,\n  783,\n  784,\n  900,\n  904,\n  973,\n  1210,\n  1229,\n  1240,\n  1257,\n  1258,\n  1282,\n  1300,\n  1328,\n  1329,\n  1408,\n  1591,\n  1592,\n  1622,\n  1625,\n  1636,\n  1675,\n  1830,\n  1867,\n  1920,\n  1921,\n  1922,\n  1923],\n [78,\n  97,\n  98,\n  99,\n  105,\n  154,\n  222,\n  223,\n  224,\n  276,\n  277,\n  304,\n  316,\n  319,\n  320,\n  321,\n  323,\n  348,\n  349,\n  350,\n  424,\n  488,\n  519,\n  529,\n  533,\n  596,\n  598,\n  670,\n  814,\n  884,\n  965,\n  969,\n  971,\n  972,\n  975,\n  978,\n  984,\n  996,\n  1031,\n  1051,\n  1052,\n  1091,\n  1109,\n  1121,\n  1165,\n  1192,\n  1193,\n  1194,\n  1195,\n  1196,\n  1207,\n  1231,\n  1281,\n  1293,\n  1344,\n  1345,\n  1524,\n  1542,\n  1546,\n  1688,\n  1709,\n  1710,\n  1711,\n  1712,\n  1713,\n  1740,\n  1772,\n  1773,\n  1794,\n  1795,\n  1807,\n  1808,\n  1809,\n  1883,\n  1884,\n  1902,\n  1963,\n  2036,\n  2048],\n [89, 90, 91, 1501, 1502, 1503, 1824],\n [102,\n  103,\n  104,\n  365,\n  366,\n  367,\n  368,\n  851,\n  936,\n  937,\n  938,\n  955,\n  956,\n  1136,\n  1217,\n  1267,\n  1399,\n  1400,\n  1477,\n  1478,\n  1516,\n  1626,\n  1627,\n  1628,\n  1629,\n  1630,\n  1631,\n  1632,\n  1751,\n  1752,\n  1753,\n  1754,\n  1755,\n  1756,\n  1757,\n  1782,\n  1906,\n  1908],\n [106,\n  150,\n  333,\n  428,\n  439,\n  440,\n  441,\n  442,\n  443,\n  444,\n  580,\n  666,\n  667,\n  675,\n  721,\n  771,\n  778,\n  795,\n  1016,\n  1058,\n  1133,\n  1447,\n  1943,\n  1944,\n  1945,\n  1946],\n [120,\n  121,\n  174,\n  175,\n  412,\n  489,\n  509,\n  510,\n  522,\n  523,\n  628,\n  679,\n  680,\n  681,\n  682,\n  683,\n  796,\n  913,\n  943,\n  1021,\n  1022,\n  1044,\n  1045,\n  1056,\n  1057,\n  1120,\n  1251,\n  1252,\n  1253,\n  1254,\n  1273,\n  1283,\n  1409,\n  1410,\n  1411,\n  1414,\n  1466,\n  1490,\n  1500,\n  1582,\n  1588,\n  1589,\n  1633,\n  1652,\n  1653,\n  1654,\n  1655,\n  1658,\n  1659,\n  1743,\n  1744,\n  1829,\n  1861,\n  1872,\n  1874,\n  1973,\n  2006,\n  2008,\n  2009,\n  2010,\n  2046],\n [131,\n  258,\n  302,\n  393,\n  394,\n  466,\n  702,\n  723,\n  740,\n  856,\n  997,\n  999,\n  1070,\n  1087,\n  1119,\n  1284,\n  1285,\n  1286,\n  1287,\n  1288,\n  1289,\n  1290,\n  1291,\n  1292,\n  1294,\n  1415,\n  1433,\n  1463,\n  1529,\n  1530,\n  1531,\n  1553,\n  1624,\n  1637,\n  1638,\n  1639,\n  1640,\n  1641,\n  1642,\n  1643,\n  1644,\n  1645,\n  1646,\n  1738,\n  1889,\n  1894,\n  1895,\n  1898,\n  1958,\n  2016,\n  2018],\n [142,\n  336,\n  606,\n  607,\n  608,\n  609,\n  610,\n  611,\n  612,\n  618,\n  720,\n  905,\n  986,\n  1181,\n  1184,\n  1259,\n  1315,\n  1661,\n  1662,\n  1663,\n  1664,\n  1859,\n  1909],\n [199, 215, 773, 774, 775, 776, 1430, 1431, 1432, 1723, 1724],\n [221,\n  513,\n  514,\n  516,\n  517,\n  518,\n  520,\n  604,\n  661,\n  992,\n  993,\n  1395,\n  1396,\n  1448,\n  1746,\n  1769,\n  1851],\n [225, 689, 690, 691, 694, 695, 696, 1153, 1154, 1155, 1156, 1157, 1770],\n [352, 415, 1188, 1241, 1256, 1349, 1350, 1351],\n [478, 1131, 1435, 1595, 1818, 1879, 1880, 2017],\n [544, 830, 831, 832, 1107, 1108, 1836, 1837]]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_new_alg = read_communities(\"TCGA/communities.txt\")\n",
    "communities_new_alg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.736,\n 0.651,\n 0.504,\n 0.591,\n 0.589,\n 0.509,\n 0.518,\n 0.498,\n 0.648,\n 0.686,\n 0.6,\n 0.662,\n 0.42,\n 0.449,\n 0.723,\n 0.521,\n 0.602,\n 0.501,\n 0.724,\n 0.465,\n 0.57,\n 0.795,\n 0.749,\n 0.792,\n 0.628,\n 0.552,\n 0.583,\n 0.482,\n 0.72,\n 0.68,\n 0.582,\n 0.678,\n 0.805]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_importance_new_alg = read_community_importances(\"TCGA/communities_scores.txt\")\n",
    "comm_importance_new_alg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['EGR2', 'HOXA2', 'HOXB13', 'HOXB2', 'MEIS1', 'MEIS2', 'TEAD1',\n       'TEAD4'], dtype=object)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sorted_indices = np.argsort(comm_importance_new_alg)[::-1]\n",
    "\n",
    "sorted_communities_new_alg = []\n",
    "\n",
    "# Loop through sorted indices and assign cluster memberships\n",
    "for index in sorted_indices:\n",
    "  sorted_communities_new_alg.append(communities_new_alg[index])\n",
    "\n",
    "# The gene names of the community ranked highest by gnn-subnet\n",
    "g.gene_names[sorted_communities_new_alg[0]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
